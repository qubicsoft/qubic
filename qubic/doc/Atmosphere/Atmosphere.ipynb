{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49102ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.linalg import cholesky\n",
    "import scipy.special as sci_spe\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f9dfdca",
   "metadata": {},
   "source": [
    "3D simulation of water vapor density with correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c710d988",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kolmogorov_correlation(r, r0=300):\n",
    "    '''\n",
    "    Correlation function of water vapor as a function of distance r (Kolmogorov model).\n",
    "    Due to the modified Bessel function, this function is very costly to compute.\n",
    "    '''\n",
    "    return np.where(r==0, 1, 2**(2/3)/sci_spe.gamma(1/3)*(r/r0)**(1/3)*sci_spe.kv(1/3, r/r0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368fad8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = np.arange(0, 4, 0.01)\n",
    "corr = kolmogorov_correlation(r, r0=1)\n",
    "fit_parameters = np.polyfit(r, corr, 12)\n",
    "fit_list = np.polyval(fit_parameters, r)\n",
    "plt.plot(r, corr, label='Kolmogorov')\n",
    "plt.plot(r, fit_list, label='fit')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf87422",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlation_function(r, r0=300):\n",
    "    '''\n",
    "    Polynomial approximation of Kolmogorov's correlation. Computation is much faster.\n",
    "    '''\n",
    "    return np.where(r>4*r0, 0, np.polyval(fit_parameters, r/r0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109c0da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "r0 = 300 #m\n",
    "\n",
    "N=20\n",
    "# Generate grid points in 3D space \n",
    "x = np.linspace(1, r0, N)\n",
    "y = np.linspace(1, r0, N)\n",
    "z = np.linspace(1, r0, N)\n",
    "\n",
    "# Create meshgrid\n",
    "X, Y, Z = np.meshgrid(x, y, z, indexing='ij')\n",
    "\n",
    "# Reshape the grid into a list of 3D coordinates\n",
    "grid_points = np.column_stack([X.flatten(), Y.flatten(), Z.flatten()])\n",
    "\n",
    "step0=time()\n",
    "# Compute pairwise distances between grid points\n",
    "distances = np.linalg.norm(grid_points[:, None] - grid_points, axis=-1)\n",
    "print(np.shape(distances))\n",
    "step1=time()\n",
    "print(f'distances {step1-step0}')\n",
    "\n",
    "# Evaluate the 3D correlation function at these distances\n",
    "correlation_values = correlation_function(distances, r0)\n",
    "correlation_values=np.nan_to_num(correlation_values, nan=1.0)\n",
    "step2=time()\n",
    "print(f'correlation {step2-step1}')\n",
    "\n",
    "# Create the covariance matrix using the correlation values\n",
    "covariance_matrix = np.reshape(correlation_values, (len(x)*len(y)*len(z), len(x)*len(y)*len(z)))\n",
    "\n",
    "# Perform Cholesky decomposition\n",
    "L = cholesky(covariance_matrix, lower=True)\n",
    "step3=time()\n",
    "print(f'cholesky {step3-step2}')\n",
    "\n",
    "# Generate uncorrelated noise samples\n",
    "uncorrelated_samples = np.random.randn(len(x)*len(y)*len(z))\n",
    "step4=time()\n",
    "print(f'random {step4-step3}')\n",
    "\n",
    "# Transform uncorrelated samples to correlated samples using Cholesky decomposition\n",
    "correlated_samples = np.dot(L, uncorrelated_samples)\n",
    "\n",
    "# Reshape correlated samples back to 3D\n",
    "correlated_samples_3d = np.reshape(correlated_samples, (len(x), len(y), len(z)))\n",
    "\n",
    "rho=correlated_samples_3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd176959",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3d plot of the fluctuations\n",
    "fig = plt.figure(figsize = (10,8))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "X, Y, Z = np.meshgrid(x, y, z)\n",
    "\n",
    "kw = {'vmin': rho.min(),\n",
    "    'vmax': rho.max(),\n",
    "    'levels': np.linspace(rho.min(), rho.max(), 30)}\n",
    "\n",
    "# Plot contour surfaces\n",
    "ax.contourf(X[:, :, -1], Y[:, :, -1], rho[:, :, -1], zdir='z', offset=Z.max(), cmap='jet', **kw)\n",
    "ax.contourf(X[0, :, :], rho[0, :, :], Z[0, :, :], zdir='y', offset=Y.min(), cmap='jet', **kw)\n",
    "C = ax.contourf(rho[:, -1, :], Y[:, -1, :], Z[:, -1, :], zdir='x', offset=X.max(), cmap='jet', **kw)\n",
    "\n",
    "# Set limits of the plot from coord limits\n",
    "xmin, xmax = X.min(), X.max()\n",
    "ymin, ymax = Y.min(), Y.max()\n",
    "zmin, zmax = Z.min(), Z.max()\n",
    "ax.set(xlim=[xmin, xmax], ylim=[ymin, ymax], zlim=[zmin, zmax])\n",
    "\n",
    "# Plot edges\n",
    "edges_kw = dict(color='0.4', linewidth=1, zorder=1e3)\n",
    "ax.plot([xmax, xmax], [ymin, ymax], zmax, **edges_kw)\n",
    "ax.plot([xmin, xmax], [ymin, ymin], zmax, **edges_kw)\n",
    "ax.plot([xmax, xmax], [ymin, ymin], [zmin, zmax], **edges_kw)\n",
    "\n",
    "# Set labels\n",
    "ax.set_xlabel('X (m)')\n",
    "ax.set_ylabel('Y (m)')\n",
    "ax.set_zlabel('Z (m)')\n",
    "ax.set_title('3D Water Vapor Distribution')\n",
    "cbar = fig.colorbar(C, ax=ax, location='left')\n",
    "#cbar = fig.colorbar(scatter, ax=ax, location='left')\n",
    "cbar.set_label('Water Vapor density (g/m3)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c96ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (10,8))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "X, Y, Z = np.meshgrid(x, y, z)\n",
    "\n",
    "scatter = ax.scatter(X, Y, Z, c=correlated_samples_3d, cmap='jet')\n",
    "\n",
    "# Set labels\n",
    "ax.set_xlabel('X (m)')\n",
    "ax.set_ylabel('Y (m)')\n",
    "ax.set_zlabel('Z (m)')\n",
    "ax.set_title('3D Water Vapor Distribution')\n",
    "cbar = fig.colorbar(scatter, ax=ax, format = '%.5f', location='left')\n",
    "#cbar.set_label('Water Vapor density (g/m3)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df7512b2",
   "metadata": {},
   "source": [
    "# Useful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb7d9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def water_vapor_density(z, rho_0=1, h0=1000):\n",
    "    '''\n",
    "    Water vapor density as a function of geopotential height h\n",
    "    rho_0: Reference mean density of water vapor in g/m³\n",
    "    h0: The half height for water vapor in m\n",
    "    '''\n",
    "    return rho_0 * np.exp(-np.log(2) * (z - 5190) / h0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb567eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def P_2d(k, r0=300):\n",
    "    '''\n",
    "    Proportionnal to the probability distribution of water vapor in 2 dimensions\n",
    "    k: wavenumber\n",
    "    '''\n",
    "    return (1/r0**2+k**2)**(-5/3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce5d021",
   "metadata": {},
   "outputs": [],
   "source": [
    "def P_3d(k, r0=300):\n",
    "    '''\n",
    "    Proportionnal to the probability distribution of water vapor in 3 dimensions\n",
    "    k: wavenumber\n",
    "    '''\n",
    "    return (1/r0**2+k**2)**(-11/3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3bd793d",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "def correlation_function_3d(r, r0=300):\n",
    "    '''\n",
    "    Fonction de correlation de la vapor d'eau en fonction de la distance r\n",
    "    '''\n",
    "    return 2**(2/3)/sci_spe.gamma(1/3)*(r/r0)**(1/3)*sci_spe.kv(1/3, r/r0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3796e40",
   "metadata": {},
   "source": [
    "# Mean water vapor density as a function of height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a55066b",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = np.linspace(5190, 10000)\n",
    "rho_0 = 1\n",
    "h0 = 1000 \n",
    "plt.plot(water_vapor_density(z, rho_0, h0), z, label=r'$\\rho_0$ =' + f'{rho_0} g/m³ , ' + r'$h_0$ = ' + f'{h0} m')\n",
    "plt.xlabel('Water vapor density (g/m³)')\n",
    "plt.ylabel('Geopopential height (m)')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c383c06",
   "metadata": {},
   "source": [
    "# 2D simulation of water vapor density with correlation using the Cholesky decomposition of the correlation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ea5a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "\n",
    "start = time()\n",
    "N=70\n",
    "# Generate grid points in 3D space \n",
    "x = np.linspace(1, 600, N)\n",
    "y = np.linspace(1, 600, N)\n",
    "\n",
    "# Create meshgrid\n",
    "X, Y = np.meshgrid(x, y, indexing='ij')\n",
    "\n",
    "# Reshape the grid into a list of 3D coordinates\n",
    "grid_points = np.column_stack([X.flatten(), Y.flatten()])\n",
    "print('initial')\n",
    "step1 = time()\n",
    "print(step1-start)\n",
    "\n",
    "# Compute distances to the origin\n",
    "distances = np.linalg.norm(grid_points[1:]-[1,1], axis=-1)\n",
    "print('distances')\n",
    "step2 = time()\n",
    "print(step2-step1)\n",
    "\n",
    "# Evaluate the 3D correlation function in an effective way by using the symmetries in distances between points in a 2D grid\n",
    "corr = correlation_function_3d(distances)\n",
    "corr=np.concatenate(([1.0], corr))\n",
    "\n",
    "l=[corr]\n",
    "for i in range(1,N):\n",
    "    for j in range(0,N):\n",
    "        l.append(corr[j*N:j*N+i+1][::-1])\n",
    "        l.append(corr[j*N+1:(j+1)*N-i])\n",
    "corr = np.concatenate(l)\n",
    "\n",
    "l=[corr]\n",
    "corr = np.reshape(corr, (N**2, N))\n",
    "for k in range(1,N):\n",
    "    for i in range(0,N):\n",
    "        l.append(corr[i*N:i*N+k+1][::-1].flatten())\n",
    "        l.append(corr[i*N+1:(i+1)*N-k].flatten())\n",
    "correlation_values = np.concatenate(l)\n",
    "\n",
    "\n",
    "\n",
    "# Create the covariance matrix using the correlation values\n",
    "covariance_matrix = np.reshape(correlation_values, (len(x)*len(y), len(x)*len(y)))\n",
    "print('correlation_matrix')\n",
    "step3 = time()\n",
    "print(step3-step2)\n",
    "\n",
    "# Perform Cholesky decomposition\n",
    "L = cholesky(covariance_matrix, lower=True)\n",
    "\n",
    "print('cholesky')\n",
    "step4 = time()\n",
    "print(step4-step3)\n",
    "\n",
    "# Generate uncorrelated noise samples\n",
    "uncorrelated_samples = np.random.randn(len(x)*len(y))\n",
    "print(uncorrelated_samples)\n",
    "\n",
    "# Transform uncorrelated samples to correlated samples using Cholesky decomposition\n",
    "correlated_samples = np.dot(L, uncorrelated_samples)\n",
    "\n",
    "# Reshape correlated samples back to 3D\n",
    "correlated_samples_2d = np.reshape(correlated_samples, (len(x), len(y)))\n",
    "\n",
    "h = 4869 # Geopotential height for QUBIC + 1km (m)\n",
    "rho_correlated = water_vapor_density(h) * 1 + (correlated_samples_2d - np.mean(correlated_samples_2d))\n",
    "\n",
    "print('correlated_samples')\n",
    "step5 = time()\n",
    "print(step5-step4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3e4320",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure()\n",
    "plt.imshow(rho_correlated, cmap='jet', extent=(1,x.max(),y.max(),1))\n",
    "plt.colorbar(label='Water Vapor density (g/m3)')\n",
    "plt.title('Water vapor distribution 1 km over Qubic')\n",
    "plt.xlabel('X (m)')\n",
    "plt.ylabel('Y (m)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20179c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rho2 = []\n",
    "for r in range(1, N):\n",
    "    rho_r = []\n",
    "    for j in range(0, N):\n",
    "        rho_r.append(np.mean(rho_correlated[j][0:N-r]*rho_correlated[j][r:N]))\n",
    "    rho2.append(np.mean(rho_r))\n",
    "rho2 = np.array(rho2)\n",
    "\n",
    "rho_corr_transposed = np.transpose(rho_correlated)\n",
    "rho2_t = []\n",
    "for r in range(1, N):\n",
    "    rho_r = []\n",
    "    for j in range(0, N):\n",
    "        rho_r.append(np.mean(rho_correlated[j][0:N-r]*rho_correlated[j][r:N]))\n",
    "    rho2_t.append(np.mean(rho_r))\n",
    "rho2_t = np.array(rho2_t)\n",
    "\n",
    "D = ((rho2+rho2_t)/2 - np.mean(rho_correlated)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd7ef8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure()\n",
    "plt.plot(x[:-1], D)\n",
    "plt.plot(x[:-1], correlation_function(x[:-1]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa89da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rotation matrix\n",
    "def rotation_matrix(r_i):\n",
    "    rx, ry, rz = r_i\n",
    "    sqrt = np.sqrt((ry**2 + rz**2)**2 + (rx*ry)**2 + (rx*rz)**2)\n",
    "    return np.array([[(ry**2+rz**2)/sqrt, 0, rx], [-rx*ry/sqrt, rz/np.sqrt(ry**2+rz**2), ry], [-rx*rz/sqrt, -ry/np.sqrt(ry**2+rz**2), rz]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364af1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions to compute boundaries of integration\n",
    "def boundaries_xi(yi, zi, r_i, freq):\n",
    "    sqrt = np.sqrt(gaussian_beam_width(zi, freq)**2 - (yi - zi*r_i[1]/r_i[2])**2)\n",
    "    offset = zi*r_i[0]/r_i[2]\n",
    "    return (-sqrt+offset, sqrt+offset)\n",
    "\n",
    "def boundaries_yi(zi, r_i, freq):\n",
    "    wz = gaussian_beam_width(zi, freq)\n",
    "    offset = zi*r_i[1]/r_i[2]\n",
    "    return (-wz+offset, wz+offset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e636b981",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bounds(z_min, z_max, r_i, freq):\n",
    "    wz = gaussian_beam_width(z_max, freq)\n",
    "    l_bounds = []\n",
    "    u_bounds = []\n",
    "    l_bounds.append(-wz-z_max*np.abs(r_i[0]/r_i[2])) # xi\n",
    "    u_bounds.append(wz+z_max*np.abs(r_i[0]/r_i[2]))\n",
    "    l_bounds.append(-wz-z_max*np.abs(r_i[1]/r_i[2])) # yi\n",
    "    u_bounds.append(wz+z_max*np.abs(r_i[1]/r_i[2]))\n",
    "    l_bounds.append(z_min) # zi\n",
    "    u_bounds.append(z_max)\n",
    "    return l_bounds, u_bounds\n",
    "\n",
    "def is_in_the_beam(arr, r_i, freq):\n",
    "    xi, yi, zi = arr\n",
    "    xi_min, xi_max = boundaries_xi(yi, zi, r_i, freq)\n",
    "    if xi >= xi_min and xi <= xi_max:\n",
    "        yi_min, yi_max = boundaries_yi(zi, r_i, freq)\n",
    "        if yi >= yi_min and yi <= yi_max:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "# Function to generate integration points within variable-dependent bounds\n",
    "def integration_points(h_min, h_max, r_i, r_j, el, freq, n):\n",
    "    '''\n",
    "    Number of points is 2**n\n",
    "    '''\n",
    "    \n",
    "    sampler_i = qmc.Sobol(d=3, scramble=False)\n",
    "    points_i = sampler_i.random_base2(m=n)\n",
    "    sampler_j = qmc.Sobol(d=3, scramble=False)\n",
    "    points_j = sampler_j.random_base2(m=n)\n",
    "    print(points_j)\n",
    "    \n",
    "    z_min = (h_min - h) / np.sin(el)\n",
    "    z_max = (h_max - h) / np.sin(el)\n",
    "\n",
    "    l_bounds_i, u_bounds_i = bounds(z_min, z_max, (0,0,1), freq) ##\n",
    "    scaled_points_i = qmc.scale(points_i, l_bounds_i, u_bounds_i)\n",
    "    l_bounds_j, u_bounds_j = bounds(z_min, z_max, (0,0,1), freq) ##\n",
    "    scaled_points_j = qmc.scale(points_j, l_bounds_j, u_bounds_j)\n",
    "\n",
    "    # Mask the points not in the beams\n",
    "    masked_points_i = []\n",
    "    for arr in scaled_points_i:\n",
    "        if is_in_the_beam(arr.tolist(), (0,0,1), freq): ##\n",
    "            masked_points_i.append(arr.tolist())\n",
    "    random.shuffle(masked_points_i)\n",
    "    masked_points_j = []\n",
    "    for arr in scaled_points_j:\n",
    "        #print(arr)\n",
    "        if is_in_the_beam(arr.tolist(), (0,0,1), freq): ##\n",
    "            masked_points_j.append(arr.tolist())\n",
    "    random.shuffle(masked_points_j)\n",
    "\n",
    "    masked_points_i = np.transpose(rotation_matrix(r_i) @ np.transpose(np.array(masked_points_i))).tolist() ##\n",
    "    masked_points_j = np.transpose(rotation_matrix(r_j) @ np.transpose(np.array(masked_points_j))).tolist() ##\n",
    "    \n",
    "    masked_points = []\n",
    "    scaled_points = []########\n",
    "    for k in range(min(len(masked_points_i), len(masked_points_j))):\n",
    "        masked_points.append(masked_points_i[k] + masked_points_j[k])\n",
    "    for k in range(2**n):\n",
    "        scaled_points.append(scaled_points_i[k].tolist() + scaled_points_j[k].tolist())\n",
    "    \n",
    "    print(len(masked_points))\n",
    "\n",
    "    return np.array(masked_points)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef13b187",
   "metadata": {},
   "outputs": [],
   "source": [
    "def atm_correlations_gaussian_qmc(h_min, h_max, r_i, r_j, el, freq, n):\n",
    "    points = integration_points(h_min, h_max, r_i, r_j, el, freq, n)\n",
    "\n",
    "    int = 0\n",
    "    for arr in points:\n",
    "        int += integrand_correlations_gaussian(arr, r_i, r_j, el, freq)\n",
    "\n",
    "    #volume = (pi * integrale(wz)**2)**2 The second square is because there are two beams\n",
    "    volume = (np.pi * scipy.integrate.quad(lambda z, freq : gaussian_beam_width(z, freq)**2, h_min-h, h_max-h, args=freq)[0])**2\n",
    "    \n",
    "    return np.shape(points)[0], molecular_absorption_coeff**2 * int / np.shape(points)[0] * volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fef5b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_in_the_beam(arr, r_i, freq):\n",
    "    xi, yi, zi = arr\n",
    "    xi_min, xi_max = boundaries_xi(yi, zi, r_i, freq)\n",
    "    if xi >= xi_min and xi <= xi_max:\n",
    "        yi_min, yi_max = boundaries_yi(zi, r_i, freq)\n",
    "        if yi >= yi_min and yi <= yi_max:\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97927759",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rotation matrix in six dimensions (two idependant 3D rotations, one for each beam)\n",
    "def rotation_matrix_six(r_i, r_j):\n",
    "    rxi, ryi, rzi = r_i\n",
    "    rxj, ryj, rzj = r_j\n",
    "    sqrt_i = np.sqrt((ryi**2 + rzi**2)**2 + (rxi*ryi)**2 + (rxi*rzi)**2)\n",
    "    sqrt_j = np.sqrt((ryj**2 + rzj**2)**2 + (rxj*ryj)**2 + (rxj*rzj)**2)\n",
    "\n",
    "    L1 = [(ryi**2+rzi**2)/sqrt_i, -rxi*ryi/sqrt_i, -rxi*rzi/sqrt_i, 0, 0, 0]\n",
    "    L2 = [0, rzi/np.sqrt(ryi**2+rzi**2), -ryi/np.sqrt(ryi**2+rzi**2), 0, 0, 0]\n",
    "    L3 = [rxi, ryi, rzi, 0, 0, 0]\n",
    "    L4 = [0, 0, 0, (ryj**2+rzj**2)/sqrt_j, -rxj*ryj/sqrt_j, -rxj*rzj/sqrt_j]\n",
    "    L5 = [0, 0, 0, 0, rzj/np.sqrt(ryj**2+rzj**2), -ryj/np.sqrt(ryj**2+rzj**2)]\n",
    "    L6 = [0, 0, 0, rxj, ryj, rzj]\n",
    "    Rxy = np.array([L1, L2, L3, L4, L5, L6])\n",
    "    return Rxy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b25e866",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
