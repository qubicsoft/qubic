---
jupyter:
  jupytext:
    text_representation:
      extension: .Rmd
      format_name: rmarkdown
      format_version: '1.2'
      jupytext_version: 1.16.1
  kernelspec:
    display_name: Python 3 (ipykernel)
    language: python
    name: python3
---

```{python}
import qubic
import numpy as np
import matplotlib.pyplot as plt
import scipy
import random
import scipy.special as sci_spe
from scipy.stats import qmc
from time import time
```

```{python}
h = 4869 # altitude of Qubic
h_atm = 3000 # height of the atmosphere
min_el_qubic = np.radians(30) # minimal elevation of Qubic
c = scipy.constants.c # speed of light
P = 20 # Number of pupils
delta_h = 14e-3 # distance between horns

z_atm = 40000 # (m), typical height that depends on the observation site, on the order of ~10⁴ m
T_ground = 280 # (K), average ground temperature on the observation site

# I need to find measurement of the coefficient to adjust its value
k_H2O = 3e-27 # in m², around 200 GHz
m_H2O = 2.987e-22 # in g
molecular_absorption_coeff = k_H2O / m_H2O
```

## Mean water vapor density

```{python}
def water_vapor_density(z, rho_0=1, h0=1000):
    '''
    Water vapor density as a function of geopotential height h
    rho_0: Reference mean density of water vapor in g/m³
    h0: The half height for water vapor in m
    '''
    return rho_0 * np.exp(-np.log(2) * (z - 5190) / h0)

water_vapor_0 = water_vapor_density(h, 1, 1000)
```

## Temperature

```{python}
# Temperature of the atmosphere as a function of geopotential height
def atm_temp(z):
    return T_ground * (1 - (z-h)/z_atm)
```

## Correlation function

```{python}
def kolmogorov_correlation(r, r0=300):
    '''
    Correlation function of water vapor as a function of distance r (Kolmogorov model).
    Due to the modified Bessel function, this function is very costly to compute.
    '''
    return np.where(r==0, 1, 2**(2/3)/sci_spe.gamma(1/3)*(r/r0)**(1/3)*sci_spe.kv(1/3, r/r0))
```

```{python}
r = np.arange(0, 4, 0.01)
corr = kolmogorov_correlation(r, r0=1)
fit_parameters = np.polyfit(r, corr, 12)
fit_list = np.polyval(fit_parameters, r)
plt.plot(r, corr, label='Kolmogorov')
plt.plot(r, fit_list, label='fit')
plt.legend()
plt.show()
```

```{python}
def correlation_function(r, r0=300):
    return np.where(r>4*r0, 0, np.polyval(fit_parameters, r/r0))
```

## Points for quasi Monte Carlo integration

```{python}
dictname = 'pipeline_demo.dict'

thisd = qubic.qubicdict.qubicDict()
thisd.read_from_file(dictname)
thisd['nside'] = 1024
thisd['synthbeam_kmax'] = 3
thisd['synthbeam_fraction'] = 0.95 # Peaks will be considered until the sum of their value is 95% the total value.
```

```{python}
def qubic_beam(i, freq):
    '''
    Returns the coordinates and value of the peaks of the detector i at frequency freq
    '''
    thisd['filter_nu'] = freq
    thisq = qubic.QubicInstrument(thisd)
    s = qubic.QubicScene(thisd)
    theta, phi, val = thisq._peak_angles(s, thisd['filter_nu'], 
                                     np.reshape(thisq.detector.center[i,:], (1,3)), 
                                     thisq.synthbeam, thisq.horn, thisq.primary_beam)
    return np.array([theta[0], phi[0], val[0]/np.sum(val[0])])
```

```{python}
# Scales a sample to go from a 6D hypercube to two cones, one for each detector
def scaling_function(arr, z_max, freq, r0):
    zi = arr[:,2]*r0-r0/2 + arr[:,5]*z_max
    zj = -(arr[:,2]*r0-r0/2) + arr[:,5]*z_max

    zi = np.where(zi<0, -zi, zi)
    zi = np.where(zi>z_max, 2*z_max-zi, zi)
    zj = np.where(zj<0, -zj, zj)
    zj = np.where(zj>z_max, 2*z_max-zj, zj)
 
    radius = c / ((P-1) * delta_h * freq) / np.sqrt(2/np.log(2))

    cylindrical = np.empty(np.shape(arr))

    cylindrical[:] = np.array([arr[:,0]*2*np.pi, radius*zi * np.sqrt(arr[:,1]), zi, 
                            arr[:,3]*2*np.pi, radius*zj * np.sqrt(arr[:,4]), zj]).T

    scaled_arr = cylindrical.copy()
    scaled_arr[:,0] = cylindrical[:,1] * np.cos(cylindrical[:,0])
    scaled_arr[:,1] = cylindrical[:,1] * np.sin(cylindrical[:,0])
    scaled_arr[:,3] = cylindrical[:,4] * np.cos(cylindrical[:,3])
    scaled_arr[:,4] = cylindrical[:,4] * np.sin(cylindrical[:,3])

    return scaled_arr

```

```{python}
# Function to generate integration points within variable-dependent bounds
def monte_carlo_points(freq, n, r0=300, h=h, h_atm=h_atm, min_el_qubic=min_el_qubic):
    '''
    Returns a sample of points that are in the two beams (so in 6 dimensions). 
    This is done using a Sobol' sequence to have a uniform distribution in the 6D space.
    The number of points generated is roughly 2**n /2
    '''

    # Generates the points in 6D space
    sampler = qmc.Sobol(d=6, scramble=True)#, optimization='random-cd')
    points = sampler.random_base2(m=n)

    z_max = h_atm / np.sin(min_el_qubic)

    # Scales the points aproximatly in the beams.
    # We want the distance between zi and zj to be less than r0.
    # For (xi, yi), we scale the points in a circle of radius growing with zi.
    scaled_points = scaling_function(points, z_max, freq, r0)

    return np.split(scaled_points, 2, axis=1)
```

```{python}
def rotated_points(points, list_peaks):
    '''
    Rotates the points of the peak of each detector 
    '''
    theta, phi, _ = list_peaks

    c_the = np.cos(theta); s_the = np.sin(theta)
    c_phi = np.cos(phi); s_phi = np.sin(phi)

    L1 = np.array([c_phi**2*(1-c_the)+c_the, c_phi*s_phi*(1-c_the), -s_phi*s_the])
    L2 = np.array([c_phi*s_phi*(1-c_the), s_phi**2*(1-c_the)+c_the, c_phi*s_the])
    L3 = np.array([s_phi*s_the, -c_phi*s_the, c_the])

    R_k = np.transpose(np.array([L1, L2, L3]), axes=(2,0,1))

    return points @ R_k

```

```{python}
list_peaks_i = qubic_beam(231, 150e9)
list_peaks_j = qubic_beam(0, 150e9)

n = 8

points = monte_carlo_points(150e9, n, r0=300)
points_i = rotated_points(points[0], list_peaks_i)
points_j = rotated_points(points[1], list_peaks_j)

fig = plt.figure(figsize = (10,8))
ax = fig.add_subplot(111, projection='3d')

scatter = ax.scatter(points_i[..., 0], points_i[..., 1], points_i[..., 2], label='beam of the first detector', c='tab:blue')
scatter = ax.scatter(points_j[..., 0], points_j[..., 1], points_j[..., 2], label='beam of the second detector', c='tab:orange')

# Set labels
ax.set_xlabel('x (m)')
ax.set_ylabel('y (m)')
ax.set_zlabel('z (m)')
ax.set_title('Points distribution on beams, z axis is aligned with the central detector')
limit = np.max((np.max(np.abs(points_i[..., 0])), np.max(np.abs(points_i[..., 1])), 
                np.max(np.abs(points_j[..., 0])), np.max(np.abs(points_j[..., 1]))))
ax.set_xlim(-limit,limit)
ax.set_ylim(-limit,limit)
plt.legend()
plt.show()

'''
plt.scatter(scaled_points[:, 2], scaled_points[:, 5], c='tab:green')
plt.xlabel(r'$z_i$'+' (m)')
plt.ylabel(r'$z_j$'+' (m)')
plt.title('Points distribution in the '+r'$(z_i, z_j)$'+' plane. We have '+r'$\vert z_i-z_j\vert < r_0.$')
plt.show()

plt.figure(figsize = (17,10))

plt.subplot(2,3,1)
plt.scatter(scaled_points[:, 0], scaled_points[:, 2], c='tab:blue')
plt.xlabel(r'$x_i$'+' (m)')
plt.ylabel(r'$z_i$'+' (m)')
plt.title('First beam in the '+r'$(x_i, z_i)$'+' plane')

plt.subplot(2,3,2)
plt.scatter(scaled_points[:, 1], scaled_points[:, 2], c='tab:blue')
plt.xlabel(r'$y_i$'+' (m)')
plt.ylabel(r'$z_i$'+' (m)')
plt.title('First beam in the '+r'$(y_i, z_i)$'+' plane')

plt.subplot(2,3,3)
plt.scatter(scaled_points[:, 0], scaled_points[:, 1], c='tab:blue')
plt.xlabel(r'$x_i$'+' (m)')
plt.ylabel(r'$y_i$'+' (m)')
plt.title('First beam in the '+r'$(x_i, y_i)$'+' plane')

plt.subplot(2,3,4)
plt.scatter(scaled_points[:, 3], scaled_points[:, 5], c='tab:orange')
plt.xlabel(r'$x_j$'+' (m)')
plt.ylabel(r'$z_j$'+' (m)')
plt.title('Second beam in the '+r'$(x_j, z_j)$'+' plane')

plt.subplot(2,3,5)
plt.scatter(scaled_points[:, 4], scaled_points[:, 5], c='tab:orange')
plt.xlabel(r'$y_j$'+' (m)')
plt.ylabel(r'$z_j$'+' (m)')
plt.title('Second beam in the '+r'$(y_j, z_j)$'+' plane')

plt.subplot(2,3,6)
plt.scatter(scaled_points[:, 3], scaled_points[:, 4], c='tab:orange')
plt.xlabel(r'$x_j$'+' (m)')
plt.ylabel(r'$y_j$'+' (m)')
plt.title('Second beam in the '+r'$(x_j, y_j)$'+' plane')
plt.show()
'''
```

## Computation of the correlation between two detectors

```{python}
def xyz_to_NWZ(x, y, z, az, el):
    '''
    Transform the coordinates in the frame of the detector to the coordinates system (North, West, Zenith)
    '''
    N = x*np.sin(az) - y*np.sin(el)*np.cos(az) + z*np.cos(el)*np.cos(az)
    W = x*np.cos(az) + y*np.sin(el)*np.sin(az) - z*np.cos(el)*np.sin(az)
    Z = y*np.cos(el) + z*np.sin(el)
    return N, W, Z
```

```{python}
def qubic_beam_value(x, y, z, theta, phi, val, freq):
    '''
    Beam profile, integral over x,y normalized.
    '''
    coef = np.pi * delta_h * freq / c
    X = coef * (x/z - theta * np.sin(phi))
    Y = coef * (y/z + theta * np.cos(phi))
    return val * (np.sinc(P * X / np.pi) * np.sinc(P * Y / np.pi))**2 / (c * z / (P*delta_h * freq))**2
```

```{python}
z = 1000
freq = 150e9
angle = c / ((P-1) * delta_h * freq) / np.sqrt(2/np.log(2))
print(angle)
x = np.linspace(-angle*z, angle*z, 100)
plt.plot(x, qubic_beam_value(x, 0, z, 0, 0, 1, 150e9))
plt.plot(x, [np.max(qubic_beam_value(x, 0, z, 0, 0, 1, 150e9))/np.exp(2)]*len(x))
plt.ylim(0)
#plt.plot(x, np.exp(-2*x**2/(angle*z)**2)/52)
```

Checking that the integral over x and y is the same, for every z, frequency, or detector.

```{python}
freq = 150e9
theta, phi, val = qubic_beam(317, freq)
angle = c / (freq * (P-1) * delta_h)
for z in [100, 200, 300, 2000]:
    int = 0
    for i in range (len(theta)):
        X = theta[i] * np.sin(phi[i]) * z
        Y = -theta[i] * np.cos(phi[i]) * z
        int += scipy.integrate.dblquad(lambda x,y: qubic_beam_value(x, y, z, theta[i], phi[i], val[i], freq), Y-2*angle*z, Y+2*angle*z, X-2*angle*z, X+2*angle*z)[0]
    print(int)

```

```{python}
def integrand_one_beam(coords, list_peaks, el, freq):
    '''

    '''
    x = coords[...,0]; y = coords[...,1]; z = coords[...,2]
    theta, phi, val = list_peaks

    # Geopotential height
    height = h + z*np.sin(el) + y*np.cos(el)

    # To compute the integral we need to weight by the surface at each height zi or zj 
    # to take into account that the density of points changes with height
    radius = c / ((P-1) * delta_h * freq) / np.sqrt(2/np.log(2))
    
    return water_vapor_density(height) * atm_temp(height) * radius**2 * z**2 * np.pi * qubic_beam_value(x, y, z, theta[:,None], phi[:,None], val[:,None], freq)

```

```{python}
def integrand_correlations_qubic(coords_i, coords_j, beam_i, beam_j, ti, az_ti, el_ti, tj, az_tj, el_tj, W, phi_W, freq, r0=300):
    '''
    Integrand for the correlation function.
    coords is the list of the 6 dimensions coordinates of a pair of points.
    peak_i is the coordinate and value of the peak we are considering.
    ti and tj are the moment of observation for detector i and j
    az_ti and el_tj is the azimuth and the elevation of the central detector at time ti
    W the norm of the speed of the wind
    phi_W the azimuth of the wind
    freq the frequence
    '''
    xi = coords_i[...,0]; yi = coords_i[...,1]; zi = coords_i[...,2]
    xj = coords_j[...,0]; yj = coords_j[...,1]; zj = coords_j[...,2]

    # Distance between the two points in the sky taking into account the wind
    Ni, Wi, Zi = xyz_to_NWZ(xi, yi, zi, az_ti, el_ti)
    Nj, Wj, Zj = xyz_to_NWZ(xj, yj, zj, az_tj, el_tj)
    N_wind, W_wind = np.cos(phi_W)*W*(tj-ti), -np.sin(phi_W)*W*(tj-ti) # Spatial shift due to the wind
    
    r_ij = np.sqrt((Nj[None, ...]-Ni[:, None, ...]-N_wind)**2 + (Wj[None, ...]-Wi[:, None, ...]-W_wind)**2 + (Nj[None, ...]-Ni[:, None, ...])**2)

    return correlation_function(r_ij, r0=r0) * beam_i[:, None, ...] * beam_j[None, ...]
    
```

```{python}
def atm_correlations_qubic(points, list_peaks_i, list_peaks_j, ti, az_ti, el_ti, tj, az_tj, el_tj, W, phi_W, freq, r0=300):
    
    rot_points_i = rotated_points(points[0], list_peaks_i)
    rot_points_j = rotated_points(points[1], list_peaks_j)

    beam_i = integrand_one_beam(rot_points_i, list_peaks_i, el_ti, freq)
    beam_j = integrand_one_beam(rot_points_j, list_peaks_j, el_tj, freq)

    int = np.sum(integrand_correlations_qubic(rot_points_i, rot_points_j, beam_i, beam_j,
                                ti, az_ti, el_ti, tj, az_tj, el_tj, W, phi_W, freq, r0=r0))

    # Surface in the (zi,zj) plane
    z_max = h_atm / np.sin(min_el_qubic)
    Sz = z_max**2 - (z_max-r0)**2
    

    return molecular_absorption_coeff**2 * int / np.shape(points)[1] * Sz
    
```

## Time of execution

```{python}
freq = 150e9
list_peaks_i = qubic_beam(231, freq) #np.array([[0], [0], [1]]) #qubic_beam(231, freq)
list_peaks_j = qubic_beam(0, freq) #np.array([[np.radians(10)], [0], [1]]) #qubic_beam(231, freq)
points = monte_carlo_points(freq, 9)
# %timeit atm_correlations_qubic(points, list_peaks_i, list_peaks_j, 0, 0, np.radians(45), 0, 0, np.radians(45), 0, 0, freq)
```

```{python}
points = monte_carlo_points(freq, 9)
list_peaks_i = qubic_beam(231, freq)
list_peaks_j = qubic_beam(0, freq)
atm_correlations_qubic(points, list_peaks_i, list_peaks_j, 0, 0, np.radians(45), 0, 0, np.radians(45), 0, 0, freq)
```

## Convergence

```{python}
n_list = np.arange(4, 13)
freq = 150e9
list_peaks_i = qubic_beam(231, freq) #np.array([[0], [0], [1]]) #qubic_beam(231, freq)
list_peaks_j = qubic_beam(231, freq) #np.array([[np.radians(10)], [0], [1]]) #qubic_beam(231, freq)
for i in range(10):
    corr=[]
    for n in n_list:
        points = monte_carlo_points(freq, n)
        corr.append(atm_correlations_qubic(points, list_peaks_i, list_peaks_j, 0, 0, np.radians(45), 0, 0, np.radians(45), 0, 0, freq))
    plt.plot(2**n_list, corr/corr[-1])
    print(corr/corr[-1])
    print(corr[-1])
plt.xlabel('Number of points')
plt.ylim(0.5, 1.5)
plt.show()
```

Only $2^9=512$ points are needed to get a convergence up to a few percent.


## Correlations between detectors

```{python}
corr=[]
freq = 150e9
points = monte_carlo_points(freq, 9)
list_peaks_i = qubic_beam(231, freq)
det_list = np.arange(231, 248, 1)
for det in det_list:
    list_peaks_j = qubic_beam(det, freq)
    corr.append(atm_correlations_qubic(points, list_peaks_i, list_peaks_j, 0, 0, np.radians(45), 0, 0, np.radians(45), 0, 0, 150e9))
plt.plot(det_list, corr)
plt.xlabel('Detectors\' number, going from the center to the edge, following a line')
plt.ylabel('Correlation with the the detector at the center '+r'$[K^2]$')
plt.ylim(0, np.max(corr)*1.1)
plt.show()
```

```{python}
corr=[]
freq = 150e9
points = monte_carlo_points(freq, 9)
list_peaks_i = qubic_beam(231, freq)
det_list = [231, 215, 199, 183, 167, 151, 135, 119, 104, 90, 76, 63]
for det in det_list:
    list_peaks_j = qubic_beam(det, freq)
    corr.append(atm_correlations_qubic(points, list_peaks_i, list_peaks_j, 0, 0, np.radians(45), 0, 0, np.radians(45), 0, 0, 150e9))
plt.plot(det_list, corr)
plt.xlabel('Detectors\' number, going from the center to the edge, following a diagonal')
plt.ylabel('Correlation with the the detector at the center '+r'$[K^2]$')
plt.ylim(0, np.max(corr)*1.1)
plt.show()
```

We observe that the detectors are higly correlated. 
We can understand this easily: after ~8° of rotation, all the peaks of the second beam will have rotate and met an other peak of the first beam. So we expect the same result. 
In between, ~4°, the peaks ar still highly correlated. Indeed the distance in the sky at 4° for z = 2 km is 140 m, less than r0 ~ 300m.
To confirm this hypothesis, we can redo the calculation of the first graph with r0 = 15 m. We also change the frequency to 220 GHz, that way the peaks are nearer and we can observe the point were all peaks meet again.

```{python}
corr=[]
freq = 220e9
r0 = 15
points = monte_carlo_points(freq, 9, r0=r0)
list_peaks_i = qubic_beam(231, freq)
det_list = np.arange(231, 248, 1)
for det in det_list:
    list_peaks_j = qubic_beam(det, freq)
    corr.append(atm_correlations_qubic(points, list_peaks_i, list_peaks_j, 0, 0, np.radians(45), 0, 0, np.radians(45), 0, 0, 150e9, r0=r0))
plt.plot(det_list, corr)
plt.xlabel('Detectors\' number, going from the center to the edge, following a line')
plt.ylabel('Correlation with the the detector at the center '+r'$[K^2]$')
plt.ylim(0, np.max(corr)*1.1)
plt.show()
```

## Scanning

```{python}
W = 0                        # Speed of the wind (m s^-1)
phi_W = 0                    # Azimuth of the wind (rad)
delta_az = np.radians(40)     # Angular size of the scan in the azimuth direction (rad)
ss = np.radians(5)           # Scanning speed (rad s^-1)
f_scan = ss/(2*delta_az)      # Scan frequency (Hz)
freq = 150e9
r0 = 300
list_peaks = qubic_beam(231, freq)
```

```{python}
time_list = np.linspace(0, 40, 201)
azimuth_list = delta_az / 2 * np.sin(2*np.pi * f_scan * time_list)

plt.plot(time_list, azimuth_list)
plt.xlabel('Time (s)')
plt.ylabel('Azimuthal direction')
plt.show()
```

```{python}
r0_list = [10, 70, 300, 1000]

for r0 in r0_list:
    points = monte_carlo_points(freq, 9, r0=r0)
    corr = []
    for t in range(len(time_list)):
        time = time_list[t]
        azimuth = azimuth_list[t]
        corr.append(atm_correlations_qubic(points, list_peaks, list_peaks, ti=0, az_ti=azimuth_list[0], 
                                           el_ti=np.radians(45), tj=time, az_tj=azimuth, 
                                           el_tj=np.radians(45), W=W, phi_W=phi_W, freq=freq, r0=r0))
    plt.plot(time_list, corr/corr[0], label='r0 = '+str(r0)+' m')

plt.xlabel('Time (s)')
plt.ylabel('Correlations '+r'$(K^2)$')
plt.title('Varying r0. '+r'$ss = 5°s^{-1},\, \Delta az = 40°,\, W = 0 m.s^{-1},\, \phi_W = 0°$')
plt.legend()
plt.show()
```

```{python}
W_list = [1, 5, 15, 30]

for Wind in W_list:
    points = monte_carlo_points(freq, 9, r0=r0)
    corr = []
    for t in range(len(time_list)):
        time = time_list[t]
        azimuth = azimuth_list[t]
        corr.append(atm_correlations_qubic(points, list_peaks, list_peaks, ti=0, az_ti=azimuth_list[0], 
                                           el_ti=np.radians(45), tj=time, az_tj=azimuth, 
                                           el_tj=np.radians(45), W=Wind, phi_W=phi_W, freq=freq, r0=r0))
    plt.plot(time_list, corr/corr[0], label='W = '+str(Wind)+r' $m.s^{-1}$')

plt.xlabel('Time (s)')
plt.ylabel('Correlations '+r'$(K^2)$')
plt.title('Varying wind speed W. '+r'$r0 = 300 m,\, ss = 5°s^{-1},\, \Delta az = 40°,\, \phi_W = 0°$')
plt.legend()
plt.show()
```

```{python}
phi_W_list = [-90, -45, 0, 45, 90]

for phi_Wind in phi_W_list:
    points = monte_carlo_points(freq, 9, r0=r0)
    corr = []
    for t in range(len(time_list)):
        time = time_list[t]
        azimuth = azimuth_list[t]
        corr.append(atm_correlations_qubic(points, list_peaks, list_peaks, ti=0, az_ti=azimuth_list[0], 
                                           el_ti=np.radians(45), tj=time, az_tj=azimuth, 
                                           el_tj=np.radians(45), W=10, phi_W=np.radians(phi_Wind), freq=freq, r0=r0))
    plt.plot(time_list, corr/corr[0], label=r'$\phi_W =$'+str(phi_Wind)+'°')

plt.xlabel('Time (s)')
plt.ylabel('Correlations '+r'$(K^2)$')
plt.title('Varying wind azimuth '+r'$\phi_W.\. r0 = 300 m,\, ss = 5°s^{-1},\, \Delta az = 40°,\, W = 10 m.s^{-1}$')
plt.legend()
plt.show()
```

```{python}

```
