{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b003f6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qubic.lib.Qdictionary import qubicDict\n",
    "from qubic.lib.Instrument.Qinstrument import QubicInstrument, compute_freq\n",
    "from qubic.lib.Qscene import QubicScene\n",
    "from qubic.data import PATH as data_dir\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import random\n",
    "import scipy.special as sci_spe\n",
    "from scipy.stats import qmc\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f9e301",
   "metadata": {},
   "outputs": [],
   "source": [
    "h = 4869 # altitude of Qubic\n",
    "h_atm = 3000 # height of the atmosphere\n",
    "min_el_qubic = np.radians(30) # minimal elevation of Qubic\n",
    "c = scipy.constants.c # speed of light\n",
    "P = 20 # Number of horns along one axis\n",
    "delta_h = 14e-3 # distance between horns\n",
    "\n",
    "z_atm = 40000 # (m), typical height that depends on the observation site, on the order of ~10⁴ m\n",
    "T_ground = 280 # (K), average ground temperature on the observation site\n",
    "\n",
    "n_air = 1.423e25 # (m^-3), density of air\n",
    "m_H2O = 2.992e-23 # (g) mass of H2O molecule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ebbdc30",
   "metadata": {},
   "outputs": [],
   "source": [
    "dictname = 'pipeline_demo.dict'\n",
    "\n",
    "thisd = qubicDict()\n",
    "thisd.read_from_file(dictname)\n",
    "thisd['nside'] = 1024\n",
    "thisd['synthbeam_kmax'] = 3 # We select peaks from the (2 * kmax + 1)**2 = 49 peaks centered on the primary peak\n",
    "thisd['synthbeam_fraction'] = 0.95 # Peaks will be considered until the sum of their value is 95% the total value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae2f10bd",
   "metadata": {},
   "source": [
    "## Molecular absorption coefficient\n",
    "To get this information, we use the am atmospheric model developped by Paine (Paine, S. 2018, The am atmospheric model).\n",
    "The absorption coefficient has two origins: the line-by-line absorption which reprensents the spectral lines, and a continuum absorption coming from collisions between molecules, either $H_2O-H_2O$ collisions (self-induced continuum), or collisions between $H_2O$ and the air (air_induced).\n",
    "\n",
    "So the coefficient $\\alpha_b(\\nu)$ [$m^2g^{-1}$] is defined by:\n",
    "$$\\alpha_b(\\nu) = \\frac{1}{m_{H_2O}} \\left(k_{lines}(\\nu) + n_{H_2O}k_{self}(\\nu) + n_{air}k_{air}(\\nu)\\right)$$\n",
    "with $m_{H_2O}= 2.992\\times 10^{-23} g$ the mass of a $H_2O$ molecule, $k_{lines}$ [$m^2$] the line-by-line absorption coefficient, $k_{self}$ and $k_{air}$ [$m^5$] the self- and air-induced continua, $n_{H_2O}$ and $n_{air}$ [$m^{-3}$] the densities of water vapor and air.\n",
    "\n",
    "Spectras for the line-by-line absorption-coefficient were produced using .amc files that looks like that:\n",
    "\n",
    "f 130 GHz  250 GHz  0.005 GHz\\\n",
    "output f  k\n",
    "\n",
    "layer\\\n",
    "P 500 hPa\\\n",
    "T 280 K\\\n",
    "column h2o_lines 1 mm_pwv\n",
    "\n",
    "And for the continuum absorption:\n",
    "\n",
    "f 130 GHz  250 GHz  0.005 GHz\\\n",
    "output f  k\n",
    "\n",
    "layer\\\n",
    "P 550 hPa\\\n",
    "T 280 K\\\n",
    "h 3000 m\\\n",
    "column h2o_self_continuum 1 mm_pwv\n",
    "\n",
    "Then we only need to execute a command line like: am file_name.amc > file_name.out\n",
    "\n",
    "The file 'file_name.out' is created and contains two colomns, one for the frequency, and one for the absorption coefficient. Be careful, results are in cm and not in m.\n",
    "\n",
    "See the am documentation for more details: https://zenodo.org/records/8161272"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c6e6dd",
   "metadata": {},
   "source": [
    "Let's first consider the line-by-line absorption coefficient and its dependance on temperature and pressure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1793fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "frequencies = []\n",
    "_550hPa_280K_1mm = []\n",
    "\n",
    "coeffs_dir = os.path.join(data_dir,'Atmosphere')\n",
    "with open(os.path.join(coeffs_dir,'h2o_lines_550hPa_280K_1mm.out'), 'r') as file:\n",
    "    for line in file:\n",
    "        parts = line.split() # Split the line into two parts based on whitespace\n",
    "        frequencies.append(float(parts[0]))\n",
    "        _550hPa_280K_1mm.append(float(parts[1]))\n",
    "        \n",
    "frequencies = np.array(frequencies)        \n",
    "\n",
    "name_dict = {} \n",
    "name_dict['_500hPa_280K_1mm'] = []\n",
    "name_dict['_600hPa_280K_1mm'] = []\n",
    "name_dict['_550hPa_260K_1mm'] = []\n",
    "name_dict['_550hPa_300K_1mm'] = []\n",
    "\n",
    "for name, list in name_dict.items():\n",
    "    filename = os.path.join(coeffs_dir,'h2o_lines'+name+'.out')\n",
    "    with open(filename, 'r') as file:\n",
    "        for line in file:\n",
    "            parts = line.split() # Split the line into two parts based on whitespace\n",
    "            list.append(float(parts[1]))\n",
    "\n",
    "name_dict['_550hPa_280K_1mm'] = _550hPa_280K_1mm\n",
    "\n",
    "for name, list in name_dict.items():\n",
    "    name_dict[name] = np.array(list)*(1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0543c6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_max = 2.5e-27\n",
    "\n",
    "plt.figure(figsize=(12,12))\n",
    "\n",
    "plt.subplot(2,1,1)\n",
    "plt.plot(frequencies, name_dict['_500hPa_280K_1mm'], label='P = 500 hPa')\n",
    "plt.plot(frequencies, name_dict['_550hPa_280K_1mm'], label='P = 550 hPa')\n",
    "plt.plot(frequencies, name_dict['_600hPa_280K_1mm'], label='P = 600 hPa')\n",
    "\n",
    "plt.ylim(0, y_max)\n",
    "plt.vlines(131, 0, y_max, 'black', 'dashed', label='frequency range of qubic')\n",
    "plt.vlines(169, 0, y_max, 'black', 'dashed')\n",
    "plt.vlines(192.5, 0, y_max, 'black', 'dashed')\n",
    "plt.vlines(247.5, 0, y_max, 'black', 'dashed')\n",
    "plt.xlabel('Frequency [GHz]')\n",
    "plt.ylabel(r'Molecular absorption coefficient $k_{lines}$ [$m^2$]')\n",
    "plt.title('Line-by-line absorption. T = 280 K')\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "plt.subplot(2,1,2)\n",
    "plt.plot(frequencies, name_dict['_550hPa_260K_1mm'], label='T = 260 K')\n",
    "plt.plot(frequencies, name_dict['_550hPa_280K_1mm'], label='T = 280 K')\n",
    "plt.plot(frequencies, name_dict['_550hPa_300K_1mm'], label='T = 300 K')\n",
    "\n",
    "plt.ylim(0, y_max)\n",
    "plt.vlines(131, 0, y_max, 'black', 'dashed', label='frequency range of qubic')\n",
    "plt.vlines(169, 0, y_max, 'black', 'dashed')\n",
    "plt.vlines(192.5, 0, y_max, 'black', 'dashed')\n",
    "plt.vlines(247.5, 0, y_max, 'black', 'dashed')\n",
    "plt.xlabel('Frequency [GHz]')\n",
    "plt.ylabel(r'Molecular absorption coefficient $k_{lines}$ [$m^2$]')\n",
    "plt.title('Line-by-line absorption. P = 550 hPa')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe72064",
   "metadata": {},
   "source": [
    "Now, lets consider the self- and air-induces continua. The self-induce absorption coefficient is much lower than the air-induced absorption coefficient, so we will ignore it for the rest of the notebook. Note that the self-induced continuum depends on $n_{H_2O}$ (or equivalently $\\rho_{H_2O}$), so it would be harder to take it into account as we are interested in spatail variations of the water vapor density."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e5be35",
   "metadata": {},
   "outputs": [],
   "source": [
    "h2o_self = []\n",
    "h2o_air = []\n",
    "\n",
    "with open(os.path.join(coeffs_dir,'h2o_self_continuum.out'), 'r') as file:\n",
    "    for line in file:\n",
    "        parts = line.split() # Split the line into two parts based on whitespace\n",
    "        h2o_self.append(float(parts[1]))\n",
    "\n",
    "with open(os.path.join(coeffs_dir,'h2o_air_continuum.out'), 'r') as file:\n",
    "    for line in file:\n",
    "        parts = line.split() # Split the line into two parts based on whitespace\n",
    "        h2o_air.append(float(parts[1]))\n",
    "h2o_self = np.array(h2o_self)\n",
    "h2o_air = np.array(h2o_air)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6492ce21",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(frequencies, np.array(h2o_self)*(1e-10*3.34*1e22), label=r'$n_{H_2O}k_{self}$')\n",
    "plt.plot(frequencies, np.array(h2o_air)*(1e-10*n_air), label=r'$n_{air}k_{air}$')\n",
    "\n",
    "plt.ylim(0)\n",
    "plt.xlabel('Frequency [GHz]')\n",
    "plt.ylabel(r'Molecular absorption coefficient [$m^2$]')\n",
    "plt.title('Self-induced and air-induced continuum absorption. \\n' \n",
    "          r'$n_{H_2O} = 3.34 \\cdot{} 10^{22} m^{-3}\\, (\\rho_{H_2O} = 1 g.m^{-3}),\\, n_{air} = 1.423\\cdot{}10^{25} m^{-3}$')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2400eba9",
   "metadata": {},
   "source": [
    "We can now plot the parameter $\\alpha_b(\\nu)$ [$m^2g^{-1}$]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da683d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "absorption_coeff_mass = (name_dict['_550hPa_280K_1mm'] + np.array(h2o_air)*(1e-10*n_air)) / m_H2O\n",
    "print(absorption_coeff_mass.shape)\n",
    "print(frequencies.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a154640e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "\n",
    "plt.plot(frequencies, absorption_coeff_mass)\n",
    "\n",
    "y_max = 1e-4\n",
    "plt.ylim(0, y_max)\n",
    "plt.vlines(131, 0, y_max, 'black', 'dashed', label='frequency range of qubic')\n",
    "plt.vlines(169, 0, y_max, 'black', 'dashed')\n",
    "plt.vlines(192.5, 0, y_max, 'black', 'dashed')\n",
    "plt.vlines(247.5, 0, y_max, 'black', 'dashed')\n",
    "plt.xlabel('Frequency [GHz]')\n",
    "plt.ylabel(r'$\\alpha_b$ [$m^2g^{-1}$]')\n",
    "plt.title('Line-by-line and air-induced absorption. \\n P = 550 hPa, T = 280 K, $n_{air} = 1.423\\cdot{}10^{25} m^{-3}$')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f6df8fb",
   "metadata": {},
   "source": [
    "Let's define a function that computes the integral over each frequency sub-band of the parameter $\\alpha_b(\\nu)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b7a015c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def absorption_coeff_integrated(band, Nfreq, relative_bandwidth):\n",
    "    '''\n",
    "    Returns the integral of the coefficient alpha_b over each freqency sub-band.\n",
    "    Band is 150 or 220 (GHz).\n",
    "    The result is a list of length Nfreq.\n",
    "    '''\n",
    "    freq_max = np.max(frequencies)\n",
    "    freq_min = np.min(frequencies)\n",
    "    freq_step = (freq_max - freq_min) / (len(frequencies) - 1)\n",
    "    \n",
    "    _, nus_edge, _, _, _, Nbbands = compute_freq(band, Nfreq, relative_bandwidth)\n",
    "\n",
    "    nus_edge_index = (nus_edge - freq_min) / freq_step\n",
    "    absorption_coeff = []\n",
    "    if Nbbands==1:\n",
    "        absorption_coeff.append(np.sum(absorption_coeff_mass) * \n",
    "                                (frequencies[-1] - frequencies[0])*1e9 / len(frequencies)\n",
    "                               )\n",
    "        return np.array(absorption_coeff)\n",
    "        \n",
    "    \n",
    "    for i in range(Nbbands):\n",
    "        index_inf = int(nus_edge_index[i])\n",
    "        index_sup = int(nus_edge_index[i+1])\n",
    "        absorption_coeff.append(np.sum(absorption_coeff_mass[index_inf:index_sup]) * \n",
    "                                (frequencies[index_sup] - frequencies[index_inf])*1e9 / (index_sup - index_inf))\n",
    "        \n",
    "    return np.array(absorption_coeff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde24965",
   "metadata": {},
   "outputs": [],
   "source": [
    "absorption_coeff_integrated(150, 10, thisd['filter_relative_bandwidth'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7355027e",
   "metadata": {},
   "source": [
    "## Mean water vapor density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39806dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def water_vapor_density(height, rho_0=1, h0=1000):\n",
    "    '''\n",
    "    Water vapor density as a function of geopotential height in m\n",
    "    rho_0: Reference mean density of water vapor in g/m³\n",
    "    h0: The half height for water vapor in m\n",
    "    '''\n",
    "    return rho_0 * np.exp(-np.log(2) * (height - 5190) / h0)\n",
    "\n",
    "water_vapor_0 = water_vapor_density(h, 1, 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "260213a1",
   "metadata": {},
   "source": [
    "## Temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df07793",
   "metadata": {},
   "outputs": [],
   "source": [
    "def atm_temp(height):\n",
    "    '''\n",
    "    Temperature of the atmosphere as a function of geopotential height in m\n",
    "    Returns temperature in Kelvin\n",
    "    '''\n",
    "    return T_ground * (1 - (height-h)/z_atm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41743f68",
   "metadata": {},
   "source": [
    "## Correlation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be0579d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kolmogorov_correlation(r, r0=300):\n",
    "    '''\n",
    "    Correlation function of water vapor as a function of distance r (Kolmogorov model).\n",
    "    Due to the modified Bessel function, this function is very costly to compute.\n",
    "    '''\n",
    "    return np.where(r==0, 1, 2**(2/3)/sci_spe.gamma(1/3)*(r/r0)**(1/3)*sci_spe.kv(1/3, r/r0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "667756dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = np.arange(0, 4, 0.01)\n",
    "corr = kolmogorov_correlation(r, r0=1)\n",
    "fit_parameters = np.polyfit(r, corr, 12)\n",
    "fit_list = np.polyval(fit_parameters, r)\n",
    "plt.plot(r, corr, label='Kolmogorov')\n",
    "plt.plot(r, fit_list, label='fit')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a89e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlation_function(r, r0=300):\n",
    "    '''\n",
    "    Polynomial approximation of Kolmogorov's correlation. Computation is much faster.\n",
    "    For distances greater than the fit, the value is set to 0 to avoid the divergence of the polynomial fit.\n",
    "    '''\n",
    "    return np.where(r>4*r0, 0, np.polyval(fit_parameters, r/r0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c8fd48",
   "metadata": {},
   "source": [
    "## Points for quasi Monte Carlo integration\n",
    "We will here generate a sample of Quasi-Monte Carlo points that will be used for the computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b3eda6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_detector_integration_operator(self):\n",
    "    \"\"\"\n",
    "    Integrate flux density in detector solid angles and take into account\n",
    "    the secondary beam transmission.\n",
    "    \"\"\"\n",
    "    position = self.detector.center\n",
    "    area = self.detector.area\n",
    "    secondary_beam = self.secondary_beam\n",
    "    theta = np.arctan2(\n",
    "        np.sqrt(np.sum(position[..., :2] ** 2, axis=-1)), position[..., 2])\n",
    "    phi = np.arctan2(position[..., 1], position[..., 0])\n",
    "    sr_det = -area / position[..., 2] ** 2 * np.cos(theta) ** 3\n",
    "    sr_beam = secondary_beam.solid_angle\n",
    "    sec = secondary_beam(theta, phi)\n",
    "    return sr_det / sr_beam * sec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d74ed61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def qubic_beam(i, freq):\n",
    "    '''\n",
    "    Returns the coordinates and value of the peaks of the detector i at frequency freq\n",
    "    '''\n",
    "    thisd['filter_nu'] = freq\n",
    "    thisq = QubicInstrument(thisd)\n",
    "    s = QubicScene(thisd)\n",
    "    integration = get_detector_integration_operator(thisq)[i]\n",
    "    theta, phi, val = thisq._peak_angles(s, thisd['filter_nu'], \n",
    "                                     np.reshape(thisq.detector.center[i,:], (1,3)), \n",
    "                                     thisq.synthbeam, thisq.horn, thisq.primary_beam)\n",
    "    return np.array([theta[0], phi[0], val[0]/np.sum(val[0])*integration])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9935072f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scales a sample to go from a 6D hypercube to two cones, one for each detector\n",
    "def scaling_function(arr, z_max, freq, r0):\n",
    "    '''\n",
    "    arr is a 6D hypercube. Here we shape it into two cones, one for each detector. \n",
    "    Each cone is representing only one peak, we will need to rotates thoses cones afterwards.\n",
    "    '''\n",
    "    zi = arr[:,2]*r0-r0/2 + arr[:,5]*z_max\n",
    "    zj = -(arr[:,2]*r0-r0/2) + arr[:,5]*z_max\n",
    "\n",
    "    zi = np.where(zi<0, -zi, zi)\n",
    "    zi = np.where(zi>z_max, 2*z_max-zi, zi)\n",
    "    zj = np.where(zj<0, -zj, zj)\n",
    "    zj = np.where(zj>z_max, 2*z_max-zj, zj)\n",
    " \n",
    "    radius = c / ((P-1) * delta_h * freq) / np.sqrt(2/np.log(2))\n",
    "\n",
    "    cylindrical = np.empty(np.shape(arr))\n",
    "\n",
    "    cylindrical[:] = np.array([arr[:,0]*2*np.pi, radius*zi * np.sqrt(arr[:,1]), zi, \n",
    "                            arr[:,3]*2*np.pi, radius*zj * np.sqrt(arr[:,4]), zj]).T\n",
    "\n",
    "    scaled_arr = cylindrical.copy()\n",
    "    scaled_arr[:,0] = cylindrical[:,1] * np.cos(cylindrical[:,0])\n",
    "    scaled_arr[:,1] = cylindrical[:,1] * np.sin(cylindrical[:,0])\n",
    "    scaled_arr[:,3] = cylindrical[:,4] * np.cos(cylindrical[:,3])\n",
    "    scaled_arr[:,4] = cylindrical[:,4] * np.sin(cylindrical[:,3])\n",
    "\n",
    "    return scaled_arr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "459bac1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate integration points within variable-dependent bounds\n",
    "def monte_carlo_points(freq, n, r0=300, h=h, h_atm=h_atm, min_el_qubic=min_el_qubic):\n",
    "    '''\n",
    "    Returns a sample of points that are in the two beams (so in 6 dimensions). \n",
    "    This is done using a Sobol' sequence to have a uniform distribution in the 6D space.\n",
    "    The number of points generated is 2**n\n",
    "    '''\n",
    "\n",
    "    # Generates the points in 6D space\n",
    "    sampler = qmc.Sobol(d=6, scramble=True)#, optimization='random-cd')\n",
    "    points = sampler.random_base2(m=n)\n",
    "\n",
    "    z_max = h_atm / np.sin(min_el_qubic)\n",
    "\n",
    "    # Scales the points aproximatly in the beams.\n",
    "    # We want the distance between zi and zj to be less than r0.\n",
    "    # For (xi, yi), we scale the points in a circle of radius growing with zi.\n",
    "    scaled_points = scaling_function(points, z_max, freq, r0)\n",
    "\n",
    "    return np.split(scaled_points, 2, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b0f64dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit monte_carlo_points(150e9, 15, r0=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c00bdbb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotated_points(points, list_peaks):\n",
    "    '''\n",
    "    Rotates the points of the peak of each detector \n",
    "    '''\n",
    "    theta, phi, _ = list_peaks\n",
    "\n",
    "    c_the = np.cos(theta); s_the = np.sin(theta)\n",
    "    c_phi = np.cos(phi); s_phi = np.sin(phi)\n",
    "\n",
    "    L1 = np.array([c_phi**2*(1-c_the)+c_the, c_phi*s_phi*(1-c_the), -s_phi*s_the])\n",
    "    L2 = np.array([c_phi*s_phi*(1-c_the), s_phi**2*(1-c_the)+c_the, c_phi*s_the])\n",
    "    L3 = np.array([s_phi*s_the, -c_phi*s_the, c_the])\n",
    "\n",
    "    R_k = np.transpose(np.array([L1, L2, L3]), axes=(2,0,1))\n",
    "\n",
    "    return points @ R_k\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3642fabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_peaks_i = qubic_beam(231, 150e9)\n",
    "list_peaks_j = qubic_beam(0, 150e9)\n",
    "\n",
    "n = 8\n",
    "\n",
    "points = monte_carlo_points(150e9, n, r0=300)\n",
    "points_i = rotated_points(points[0], list_peaks_i)\n",
    "points_j = rotated_points(points[1], list_peaks_j)\n",
    "\n",
    "fig = plt.figure(figsize = (10,8))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "scatter = ax.scatter(points_i[..., 0], points_i[..., 1], points_i[..., 2], label='beam of the first detector', c='tab:blue')\n",
    "scatter = ax.scatter(points_j[..., 0], points_j[..., 1], points_j[..., 2], label='beam of the second detector', c='tab:orange')\n",
    "\n",
    "# Set labels\n",
    "ax.set_xlabel('x (m)')\n",
    "ax.set_ylabel('y (m)')\n",
    "ax.set_zlabel('z (m)')\n",
    "ax.set_title('Points distribution on beams, z axis is aligned with the central detector')\n",
    "limit = np.max((np.max(np.abs(points_i[..., 0])), np.max(np.abs(points_i[..., 1])), \n",
    "                np.max(np.abs(points_j[..., 0])), np.max(np.abs(points_j[..., 1]))))\n",
    "ax.set_xlim(-limit,limit)\n",
    "ax.set_ylim(-limit,limit)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.scatter(points_i[0, :, 2], points_j[0, :, 2], c='tab:green')\n",
    "plt.xlabel(r'$z_i$'+' (m)')\n",
    "plt.ylabel(r'$z_j$'+' (m)')\n",
    "plt.title('Points distribution in the '+r'$(z_i, z_j)$'+' plane. We have '+r'$\\vert z_i-z_j\\vert < r_0.$')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize = (17,10))\n",
    "\n",
    "plt.subplot(2,3,1)\n",
    "plt.scatter(points_i[..., 0], points_i[..., 2], c='tab:blue')\n",
    "plt.xlabel(r'$x_i$'+' (m)')\n",
    "plt.ylabel(r'$z_i$'+' (m)')\n",
    "plt.title('First beam in the '+r'$(x_i, z_i)$'+' plane')\n",
    "\n",
    "plt.subplot(2,3,2)\n",
    "plt.scatter(points_i[..., 1], points_i[..., 2], c='tab:blue')\n",
    "plt.xlabel(r'$y_i$'+' (m)')\n",
    "plt.ylabel(r'$z_i$'+' (m)')\n",
    "plt.title('First beam in the '+r'$(y_i, z_i)$'+' plane')\n",
    "\n",
    "plt.subplot(2,3,3)\n",
    "plt.scatter(points_i[..., 0], points_i[..., 1], c='tab:blue')\n",
    "plt.xlabel(r'$x_i$'+' (m)')\n",
    "plt.ylabel(r'$y_i$'+' (m)')\n",
    "plt.title('First beam in the '+r'$(x_i, y_i)$'+' plane')\n",
    "\n",
    "plt.subplot(2,3,4)\n",
    "plt.scatter(points_j[..., 0], points_j[..., 2], c='tab:orange')\n",
    "plt.xlabel(r'$x_j$'+' (m)')\n",
    "plt.ylabel(r'$z_j$'+' (m)')\n",
    "plt.title('Second beam in the '+r'$(x_j, z_j)$'+' plane')\n",
    "\n",
    "plt.subplot(2,3,5)\n",
    "plt.scatter(points_j[..., 1], points_j[..., 2], c='tab:orange')\n",
    "plt.xlabel(r'$y_j$'+' (m)')\n",
    "plt.ylabel(r'$z_j$'+' (m)')\n",
    "plt.title('Second beam in the '+r'$(y_j, z_j)$'+' plane')\n",
    "\n",
    "plt.subplot(2,3,6)\n",
    "plt.scatter(points_j[..., 0], points_j[..., 1], c='tab:orange')\n",
    "plt.xlabel(r'$x_j$'+' (m)')\n",
    "plt.ylabel(r'$y_j$'+' (m)')\n",
    "plt.title('Second beam in the '+r'$(x_j, y_j)$'+' plane')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e9242b9",
   "metadata": {},
   "source": [
    "## Computation of the correlation between two detectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce52368",
   "metadata": {},
   "outputs": [],
   "source": [
    "def xyz_to_NWZ(x, y, z, az, el):\n",
    "    '''\n",
    "    Transform the coordinates in the frame of the detector to the coordinates system (North, West, Zenith)\n",
    "    '''\n",
    "    N = x*np.sin(az) - y*np.sin(el)*np.cos(az) + z*np.cos(el)*np.cos(az)\n",
    "    W = x*np.cos(az) + y*np.sin(el)*np.sin(az) - z*np.cos(el)*np.sin(az)\n",
    "    Z = y*np.cos(el) + z*np.sin(el)\n",
    "    return N, W, Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e0c0b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def qubic_beam_value(x, y, z, theta, phi, val, freq):\n",
    "    '''\n",
    "    Beam profile, integral over x,y normalized.\n",
    "    '''\n",
    "    coef = np.pi * delta_h * freq / c\n",
    "    X = coef * (x/z - theta * np.sin(phi))\n",
    "    Y = coef * (y/z + theta * np.cos(phi))\n",
    "    return val * (np.sinc(P * X / np.pi) * np.sinc(P * Y / np.pi))**2 / (c * z / (P*delta_h * freq))**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "977ca1c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = 1000\n",
    "freq = 150e9\n",
    "angle = c / ((P-1) * delta_h * freq) / np.sqrt(2/np.log(2))\n",
    "print(angle)\n",
    "x = np.linspace(-angle*z, angle*z, 100)\n",
    "plt.plot(x, qubic_beam_value(x, 0, z, 0, 0, 1, 150e9))\n",
    "plt.plot(x, [np.max(qubic_beam_value(x, 0, z, 0, 0, 1, 150e9))/np.exp(2)]*len(x))\n",
    "plt.ylim(0)\n",
    "#plt.plot(x, np.exp(-2*x**2/(angle*z)**2)/52)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a4fe16",
   "metadata": {},
   "source": [
    "Checking that the integral over x and y is the same, for every z, frequency, or detector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6bf2c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq = 150e9\n",
    "theta, phi, val = qubic_beam(317, freq)\n",
    "angle = c / (freq * (P-1) * delta_h)\n",
    "for z in [100, 200, 300, 2000]:\n",
    "    int = 0\n",
    "    for i in range (len(theta)):\n",
    "        X = theta[i] * np.sin(phi[i]) * z\n",
    "        Y = -theta[i] * np.cos(phi[i]) * z\n",
    "        int += scipy.integrate.dblquad(lambda x,y: qubic_beam_value(x, y, z, theta[i], phi[i], val[i], freq), Y-2*angle*z, Y+2*angle*z, X-2*angle*z, X+2*angle*z)[0]\n",
    "    print(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6afda2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def integrand_one_beam(coords, list_peaks, el, freq):\n",
    "    '''\n",
    "\n",
    "    '''\n",
    "    x = coords[...,0]; y = coords[...,1]; z = coords[...,2]\n",
    "    theta, phi, val = list_peaks\n",
    "\n",
    "    # Geopotential height\n",
    "    height = h + z*np.sin(el) + y*np.cos(el)\n",
    "\n",
    "    # To compute the integral we need to weight by the surface at each height zi or zj \n",
    "    # to take into account that the density of points changes with height\n",
    "    radius = c / ((P-1) * delta_h * freq) / np.sqrt(2/np.log(2))\n",
    "    \n",
    "    return water_vapor_density(height) * atm_temp(height) * radius**2 * z**2 * np.pi * qubic_beam_value(x, y, z, theta[:,None], phi[:,None], val[:,None], freq)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16aa1dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def integrand_correlations_qubic(coords_i, coords_j, beam_i, beam_j, ti, az_ti, el_ti, tj, az_tj, el_tj, W, phi_W, freq, r0=300):\n",
    "    '''\n",
    "    Integrand for the correlation function.\n",
    "    coords is the list of the 6 dimensions coordinates of a pair of points.\n",
    "    peak_i is the coordinate and value of the peak we are considering.\n",
    "    ti and tj are the moment of observation for detector i and j\n",
    "    az_ti and el_tj is the azimuth and the elevation of the central detector at time ti\n",
    "    W the norm of the speed of the wind\n",
    "    phi_W the azimuth of the wind\n",
    "    freq the frequence\n",
    "    '''\n",
    "    xi = coords_i[...,0]; yi = coords_i[...,1]; zi = coords_i[...,2]\n",
    "    xj = coords_j[...,0]; yj = coords_j[...,1]; zj = coords_j[...,2]\n",
    "\n",
    "    # Distance between the two points in the sky taking into account the wind\n",
    "    Ni, Wi, Zi = xyz_to_NWZ(xi, yi, zi, az_ti, el_ti)\n",
    "    Nj, Wj, Zj = xyz_to_NWZ(xj, yj, zj, az_tj, el_tj)\n",
    "    N_wind, W_wind = np.cos(phi_W)*W*(tj-ti), -np.sin(phi_W)*W*(tj-ti) # Spatial shift due to the wind\n",
    "    \n",
    "    r_ij = np.sqrt((Nj[None, ...]-Ni[:, None, ...]-N_wind)**2 + (Wj[None, ...]-Wi[:, None, ...]-W_wind)**2 + (Nj[None, ...]-Ni[:, None, ...])**2)\n",
    "    \n",
    "    return correlation_function(r_ij, r0=r0) * beam_i[:, None, ...] * beam_j[None, ...]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1b86b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def atm_correlations_qubic(points, list_peaks_i, list_peaks_j, ti, az_ti, el_ti, tj, az_tj, el_tj, W, phi_W, freq, r0=300):\n",
    "    \n",
    "    rot_points_i = rotated_points(points[0], list_peaks_i)\n",
    "    rot_points_j = rotated_points(points[1], list_peaks_j)\n",
    "\n",
    "    beam_i = integrand_one_beam(rot_points_i, list_peaks_i, el_ti, freq)\n",
    "    beam_j = integrand_one_beam(rot_points_j, list_peaks_j, el_tj, freq)\n",
    "\n",
    "    int = np.sum(integrand_correlations_qubic(rot_points_i, rot_points_j, beam_i, beam_j,\n",
    "                                ti, az_ti, el_ti, tj, az_tj, el_tj, W, phi_W, freq, r0=r0))\n",
    "\n",
    "    # Surface in the (zi,zj) plane\n",
    "    z_max = h_atm / np.sin(min_el_qubic)\n",
    "    Sz = z_max**2 - (z_max-r0)**2\n",
    "\n",
    "    if freq==150e9:\n",
    "        molecular_absorption_coeff = absorption_coeff_integrated(150, 1, thisd['filter_relative_bandwidth'])[0]\n",
    "    elif freq==220e9:\n",
    "        molecular_absorption_coeff = absorption_coeff_integrated(220, 1, thisd['filter_relative_bandwidth'])[0]\n",
    "    else:\n",
    "        raise Exception('freq should be 150e9 or 220e9')\n",
    "\n",
    "    return molecular_absorption_coeff**2 * int / np.shape(points)[1] * Sz\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b07975d2",
   "metadata": {},
   "source": [
    "## Time of execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7faf4b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq = 150e9\n",
    "list_peaks_i = qubic_beam(231, freq) #np.array([[0], [0], [1]]) #qubic_beam(231, freq)\n",
    "list_peaks_j = qubic_beam(0, freq) #np.array([[np.radians(10)], [0], [1]]) #qubic_beam(231, freq)\n",
    "points = monte_carlo_points(freq, 9)\n",
    "%timeit atm_correlations_qubic(points, list_peaks_i, list_peaks_j, 0, 0, np.radians(45), 0, 0, np.radians(45), 0, 0, freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d404b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "points = monte_carlo_points(freq, 9)\n",
    "list_peaks_i = qubic_beam(231, freq)\n",
    "list_peaks_j = qubic_beam(0, freq)\n",
    "atm_correlations_qubic(points, list_peaks_i, list_peaks_j, 0, 0, np.radians(45), 0, 0, np.radians(45), 0, 0, freq)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb7f7889",
   "metadata": {},
   "source": [
    "## Convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f127844",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_list = np.arange(4, 13)\n",
    "freq = 150e9\n",
    "list_peaks_i = qubic_beam(231, freq) #np.array([[0], [0], [1]]) #qubic_beam(231, freq)\n",
    "list_peaks_j = qubic_beam(231, freq) #np.array([[np.radians(10)], [0], [1]]) #qubic_beam(231, freq)\n",
    "for i in range(10):\n",
    "    corr=[]\n",
    "    for n in n_list:\n",
    "        points = monte_carlo_points(freq, n)\n",
    "        corr.append(atm_correlations_qubic(points, list_peaks_i, list_peaks_j, 0, 0, np.radians(45), 0, 0, np.radians(45), 0, 0, freq))\n",
    "    plt.plot(2**n_list, corr/corr[-1])\n",
    "    print(corr/corr[-1])\n",
    "    print(corr[-1])\n",
    "plt.xlabel('Number of points')\n",
    "plt.ylim(0.5, 1.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe8d2fd6",
   "metadata": {},
   "source": [
    "Only $2^9=512$ points are needed to get a convergence up to a few percent."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca8d9b5c",
   "metadata": {},
   "source": [
    "## Correlations between detectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78664d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr=[]\n",
    "freq = 150e9\n",
    "points = monte_carlo_points(freq, 9)\n",
    "list_peaks_i = qubic_beam(231, freq)\n",
    "det_list = np.arange(231, 248, 1)\n",
    "for det in det_list:\n",
    "    list_peaks_j = qubic_beam(det, freq)\n",
    "    corr.append(atm_correlations_qubic(points, list_peaks_i, list_peaks_j, 0, 0, np.radians(45), 0, 0, np.radians(45), 0, 0, 150e9))\n",
    "plt.figure(figsize = (8,6))\n",
    "plt.plot(det_list, corr/corr[0])\n",
    "plt.xlabel('Detectors\\' numbers, going from the center to the edge, following a line')\n",
    "plt.ylabel('Correlation with the the detector at the center '+r'$[K^2]$')\n",
    "plt.ylim(0, np.max(corr/corr[0])*1.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b37a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr=[]\n",
    "freq = 150e9\n",
    "points = monte_carlo_points(freq, 9)\n",
    "list_peaks_i = qubic_beam(231, freq)\n",
    "det_list = [231, 215, 199, 183, 167, 151, 135, 119, 104, 90, 76, 63]\n",
    "for det in det_list:\n",
    "    list_peaks_j = qubic_beam(det, freq)\n",
    "    corr.append(atm_correlations_qubic(points, list_peaks_i, list_peaks_j, 0, 0, np.radians(45), 0, 0, np.radians(45), 0, 0, 150e9))\n",
    "plt.figure(figsize = (8,6))\n",
    "plt.plot(det_list, corr/corr[0])\n",
    "plt.xlabel('Detectors\\' numbers, going from the center to the edge, following a diagonal')\n",
    "plt.ylabel('Correlation with the the detector at the center '+r'$[K^2]$')\n",
    "plt.gca().invert_xaxis()\n",
    "plt.ylim(0, np.max(corr/corr[0])*1.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cfe59d9",
   "metadata": {},
   "source": [
    "We observe that the detectors are higly correlated. \n",
    "We can understand this easily: after ~8° of rotation, all the peaks of the second beam will have rotate and met an other peak of the first beam. So we expect the same result. \n",
    "In between, ~4°, the peaks ar still highly correlated. Indeed the distance in the sky at 4° for z = 2 km is 140 m, less than r0 ~ 300m.\n",
    "To confirm this hypothesis, we can redo the calculation of the first graph with r0 = 15 m. We also change the frequency to 220 GHz, that way the peaks are nearer and we can observe the point were all peaks meet again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c5372d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr=[]\n",
    "freq = 220e9\n",
    "r0 = 10\n",
    "points = monte_carlo_points(freq, 9, r0=r0)\n",
    "list_peaks_i = qubic_beam(231, freq)\n",
    "det_list = np.arange(231, 248, 1)\n",
    "for det in det_list:\n",
    "    list_peaks_j = qubic_beam(det, freq)\n",
    "    corr.append(atm_correlations_qubic(points, list_peaks_i, list_peaks_j, 0, 0, np.radians(45), 0, 0, np.radians(45), 0, 0, 150e9, r0=r0))\n",
    "plt.figure(figsize = (8,6))\n",
    "plt.plot(det_list, corr/corr[0])\n",
    "plt.xlabel('Detectors\\' numbers, going from the center to the edge, following a line')\n",
    "plt.ylabel('Correlation with the the detector at the center '+r'$[K^2]$')\n",
    "plt.ylim(0, np.max(corr/corr[0])*1.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba0730d5",
   "metadata": {},
   "source": [
    "## Scanning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4794002",
   "metadata": {},
   "outputs": [],
   "source": [
    "W = 0                        # Speed of the wind (m s^-1)\n",
    "phi_W = 0                    # Azimuth of the wind (rad)\n",
    "delta_az = np.radians(40)     # Angular size of the scan in the azimuth direction (rad)\n",
    "ss = np.radians(5)           # Scanning speed (rad s^-1)\n",
    "f_scan = ss/(2*delta_az)      # Scan frequency (Hz)\n",
    "freq = 150e9\n",
    "r0 = 300\n",
    "list_peaks = qubic_beam(231, freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c50deb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_list = np.linspace(0, 40, 201)\n",
    "azimuth_list = delta_az / 2 * np.sin(2*np.pi * f_scan * time_list)\n",
    "\n",
    "plt.plot(time_list, azimuth_list)\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Azimuthal direction')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3511b929",
   "metadata": {},
   "outputs": [],
   "source": [
    "r0_list = [10, 70, 300, 1000]\n",
    "\n",
    "for r0 in r0_list:\n",
    "    points = monte_carlo_points(freq, 9, r0=r0)\n",
    "    \n",
    "    corr = []\n",
    "    for t in range(len(time_list)):\n",
    "        time = time_list[t]\n",
    "        azimuth = azimuth_list[t]\n",
    "        corr.append(atm_correlations_qubic(points, list_peaks, list_peaks, ti=0, az_ti=azimuth_list[0], \n",
    "                                           el_ti=np.radians(45), tj=time, az_tj=azimuth, \n",
    "                                           el_tj=np.radians(45), W=W, phi_W=phi_W, freq=freq, r0=r0))\n",
    "    plt.plot(time_list, corr/corr[0], label='r0 = '+str(r0)+' m')\n",
    "\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Correlations '+r'$(K^2)$')\n",
    "plt.title('Varying r0. '+r'$ss = 5°s^{-1},\\, \\Delta az = 40°,\\, W = 0 m.s^{-1},\\, \\phi_W = 0°$')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf3dbc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "W_list = [1, 5, 15, 30]\n",
    "\n",
    "for Wind in W_list:\n",
    "    points = monte_carlo_points(freq, 9, r0=r0)\n",
    "    corr = []\n",
    "    for t in range(len(time_list)):\n",
    "        time = time_list[t]\n",
    "        azimuth = azimuth_list[t]\n",
    "        corr.append(atm_correlations_qubic(points, list_peaks, list_peaks, ti=0, az_ti=azimuth_list[0], \n",
    "                                           el_ti=np.radians(45), tj=time, az_tj=azimuth, \n",
    "                                           el_tj=np.radians(45), W=Wind, phi_W=phi_W, freq=freq, r0=r0))\n",
    "    plt.plot(time_list, corr/corr[0], label='W = '+str(Wind)+r' $m.s^{-1}$')\n",
    "\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Correlations '+r'$(K^2)$')\n",
    "plt.title('Varying wind speed W. '+r'$r0 = 300 m,\\, ss = 5°s^{-1},\\, \\Delta az = 40°,\\, \\phi_W = 0°$')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7171d3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "phi_W_list = [-90, -45, 0, 45, 90]\n",
    "\n",
    "for phi_Wind in phi_W_list:\n",
    "    points = monte_carlo_points(freq, 9, r0=r0)\n",
    "    corr = []\n",
    "    for t in range(len(time_list)):\n",
    "        time = time_list[t]\n",
    "        azimuth = azimuth_list[t]\n",
    "        corr.append(atm_correlations_qubic(points, list_peaks, list_peaks, ti=0, az_ti=azimuth_list[0], \n",
    "                                           el_ti=np.radians(45), tj=time, az_tj=azimuth, \n",
    "                                           el_tj=np.radians(45), W=10, phi_W=np.radians(phi_Wind), freq=freq, r0=r0))\n",
    "    plt.plot(time_list, corr/corr[0], label=r'$\\phi_W =$'+str(phi_Wind)+'°')\n",
    "\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Correlations '+r'$(K^2)$')\n",
    "plt.title('Varying wind azimuth '+r'$\\phi_W.\\. r0 = 300 m,\\, ss = 5°s^{-1},\\, \\Delta az = 40°,\\, W = 10 m.s^{-1}$')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "044c39e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6b1539c1",
   "metadata": {},
   "source": [
    "Vectorization of the scanning, but is apparently slower, I don't understand why."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd39ab5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def integrand_correlations_qubic_scanning(coords_i, coords_j, beam_i, beam_j, ti, az_ti, el_ti, tj, az_tj, el_tj, W, phi_W, freq, r0=300):\n",
    "\n",
    "    xi = coords_i[...,0]; yi = coords_i[...,1]; zi = coords_i[...,2]\n",
    "    xj = coords_j[...,0]; yj = coords_j[...,1]; zj = coords_j[...,2]\n",
    "\n",
    "    # Distance between the two points in the sky taking into account the wind\n",
    "    Ni, Wi, Zi = xyz_to_NWZ(xi[None,...], yi[None,...], zi[None,...], az_ti[:, None, None], el_ti)\n",
    "    Nj, Wj, Zj = xyz_to_NWZ(xj[None,...], yj[None,...], zj[None,...], az_tj[:, None, None], el_tj)\n",
    "    N_wind, W_wind = np.cos(phi_W)*W*(tj-ti), -np.sin(phi_W)*W*(tj-ti) # Spatial shift due to the wind\n",
    "    \n",
    "    r_ij = np.sqrt((Nj[:, None, ...]-Ni[:, :, None, ...]-N_wind[:, None, None, None])**2 + \n",
    "                   (Wj[:, None, ...]-Wi[:, :, None, ...]-W_wind[:, None, None, None])**2 + \n",
    "                   (Nj[:, None, ...]-Ni[:, :, None, ...])**2)\n",
    "\n",
    "    return correlation_function(r_ij, r0=r0) * beam_i[None, :, None, ...] * beam_j[None, None, ...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d21edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def atm_correlations_qubic_scanning(points, list_peaks_i, list_peaks_j, ti, az_ti, el_ti, tj, az_tj, el_tj, W, phi_W, freq, r0=300):\n",
    "    \n",
    "    rot_points_i = rotated_points(points[0], list_peaks_i)\n",
    "    rot_points_j = rotated_points(points[1], list_peaks_j)\n",
    "\n",
    "    beam_i = integrand_one_beam(rot_points_i, list_peaks_i, el_ti, freq)\n",
    "    beam_j = integrand_one_beam(rot_points_j, list_peaks_j, el_tj, freq)\n",
    "\n",
    "    int = np.sum(integrand_correlations_qubic_scanning(rot_points_i, rot_points_j, beam_i, beam_j,\n",
    "                                ti, az_ti, el_ti, tj, az_tj, el_tj, W, phi_W, freq, r0=r0), axis=(1,2,3))\n",
    "\n",
    "    # Surface in the (zi,zj) plane\n",
    "    z_max = h_atm / np.sin(min_el_qubic)\n",
    "    Sz = z_max**2 - (z_max-r0)**2\n",
    "    \n",
    "    if freq==150e9:\n",
    "        molecular_absorption_coeff = absorption_coeff_integrated(150, 1, thisd['filter_relative_bandwidth'])[0]\n",
    "    elif freq==220e9:\n",
    "        molecular_absorption_coeff = absorption_coeff_integrated(220, 1, thisd['filter_relative_bandwidth'])[0]\n",
    "    else:\n",
    "        raise Exception('freq should be 150e9 or 220e9')\n",
    "\n",
    "    return molecular_absorption_coeff**2 * int / np.shape(points)[1] * Sz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cdb05f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 201\n",
    "time_list_i = np.array([0]*N)\n",
    "time_list_j = np.linspace(0, 40, N)\n",
    "azimuth_list_j = delta_az / 2 * np.sin(2*np.pi * f_scan * time_list_j)\n",
    "azimuth_list_i = np.array([azimuth_list_j[0]]*N)\n",
    "\n",
    "plt.plot(time_list_j, azimuth_list_j)\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Azimuthal direction')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba92aaaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "r0_list = [10, 70, 300, 1000]\n",
    "\n",
    "for r0 in r0_list:\n",
    "    points = monte_carlo_points(freq, 9, r0=r0)\n",
    "    corr = atm_correlations_qubic_scanning(points, list_peaks, list_peaks, ti=time_list_i, az_ti=azimuth_list_i, el_ti=np.radians(45), \n",
    "                               tj=time_list_j, az_tj=azimuth_list_j, el_tj=np.radians(45), W=W, phi_W=phi_W, freq=freq, r0=r0)\n",
    "    plt.plot(time_list, corr/corr[0], label='r0 = '+str(r0)+' m')\n",
    "\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Correlations '+r'$(K^2)$')\n",
    "plt.title('Varying r0. '+r'$ss = 5°s^{-1},\\, \\Delta az = 40°,\\, W = 0 m.s^{-1},\\, \\phi_W = 0°$')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ff9612",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "reorganized qubicsoft",
   "language": "python",
   "name": "qubic_reorg"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
