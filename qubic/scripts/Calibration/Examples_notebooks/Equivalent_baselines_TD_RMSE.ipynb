{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7d08850",
   "metadata": {},
   "source": [
    "### Step-by-step computation of equivalent baselines\n",
    "\n",
    "##### by Claudia\n",
    "\n",
    "Given an array of horns, there is a certain number of baselines you can define. Afterwards, you can partitionate the set in subsets of equivalent baselines.\n",
    "\n",
    "Let's work in a square array of $N=n \\times n$ horns (for example, $n=8$ horns in a side of the array. Total number of horns: $N=64$)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da531780",
   "metadata": {},
   "source": [
    "##### by James\n",
    "\n",
    "adding to this by finding the unique combinations of pairs of horns already identified and calculating the RMSE for each horn combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4833cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "from itertools import combinations\n",
    "import scipy.special\n",
    "import qubic\n",
    "from CSFPA_dataIO import calculate_intensity_4_baseline, IntegrateHornCombOnFP\n",
    "\n",
    "import os\n",
    "import re\n",
    "import multiprocessing\n",
    "from joblib import Parallel, delayed\n",
    "from tqdm import tqdm\n",
    "from timeit import default_timer as timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268959e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "n=8\n",
    "\n",
    "N= n*n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e005c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"n= \",n, \"N= \",N)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d454d2",
   "metadata": {},
   "source": [
    "### Let's define the coordinates of the horns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd9564c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which are the coordinates of these horns? In normalized units (unit= separation of two horns in one axis):\n",
    "\n",
    "Coordinates_horns = []\n",
    "\n",
    "count = 0\n",
    "for i in range(n):\n",
    "    for j in range(n):\n",
    "        a = (i,j)\n",
    "        print(\"Coordinates (x,y) are \", a)\n",
    "        \n",
    "        Coordinates_horns.append(a)\n",
    "        \n",
    "        count += 1\n",
    "\n",
    "print(\"count: \", count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e0f7654",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Coordinates_horns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e5c911",
   "metadata": {},
   "outputs": [],
   "source": [
    "Coordinates_horns = np.array(Coordinates_horns)\n",
    "Coordinates_horns.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e73cc3c",
   "metadata": {},
   "source": [
    "**Note**:  The $i$ horn has coordinates $(x_i,y_i)$, which are stored in the $x_i*n +y_i$ element of the **Coordinates_horns** array.\n",
    "\n",
    "For example, for the horn with coordinates $(2,3)$, the position in the array is:\n",
    "\n",
    "\n",
    "$2n +3 = 19$\n",
    "\n",
    "We can take this number as the label of the horn.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2afef72",
   "metadata": {},
   "source": [
    "### Now, let's compute the baselines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c20753",
   "metadata": {},
   "source": [
    "The number of baselines that you can construct with $N$ horns is ${N(N-1)} \\over{2}$.\n",
    "\n",
    "(This gives all posible combinations of two **different** horns, without repetition).\n",
    "\n",
    "If we think of a $N \\times N$ matrix with all the possible combinations, we would only take the upper (or lower) triangle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f11446",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_baselines = N*(N-1)/2\n",
    "\n",
    "print(N_baselines)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a21984ce",
   "metadata": {},
   "source": [
    " Each baseline can be thought of as a pseudo-vector, with a given length $L$ and a given orientation $\\alpha$ (i.e., an oriented segment). To be able to compute $L$ and $\\alpha$, we need to know the position of the horns that form the baseline.\n",
    "\n",
    "Let's label somehow the baselines, using the label of the horns that constitute them.\n",
    "\n",
    "If a baseline is formed with horns $i$ and $j$, let's take the upper triangle. Then if $i$ labels the row and $j$ labels the column, we will have: $j > i$.\n",
    "\n",
    "So we do a loop over $i$ values, from $0$ to $N-1$, and then a nested loop over $j$ from $i+1$ to $N-1$.\n",
    "\n",
    "For each, I have a baseline. I compute the $L^2$ and the $\\tan (\\alpha)$\n",
    "\n",
    "$L^2= (x_i - x_j)^2 + ( y_i - y_j)^2 $\n",
    "\n",
    "$\\tan (\\alpha) = (y_j - y_i)/(x_j - x_i)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04cc676",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check how many combinations we have:\n",
    "count = 0\n",
    "for i in range(N):\n",
    "    for j in range(i+1,N):\n",
    "        count = count +1\n",
    "        print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d983f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's test the coordinates of the horns that form a given baseline.\n",
    "\n",
    "for i in range(N):\n",
    "    for j in range(i+1,N):\n",
    "        print(\"for the horn\", i,\" the coordinates are: \", Coordinates_horns[i])\n",
    "        print(\"for the horn\", j,\" the coordinates are: \", Coordinates_horns[j])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61eee89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each baseline, let us compute L2 and tan_alpha:\n",
    "\n",
    "baseline = []   #array that will keep L2 and the angle\n",
    "\n",
    "baseline_v2 = []    #array that will keep the label of the horns that form the baseline, L2 and the angle\n",
    "\n",
    "for i in range(N):\n",
    "    x_i,y_i = Coordinates_horns[i]\n",
    "\n",
    "    for j in range(i+1,N):\n",
    "        \n",
    "        x_j,y_j = Coordinates_horns[j]        \n",
    "\n",
    "\n",
    "        L2 = (x_i - x_j)**2 + (y_i - y_j)**2\n",
    "        \n",
    "        tan_alpha = (y_j - y_i)/(x_j - x_i)\n",
    "        \n",
    "        angle= np.arctan(tan_alpha)\n",
    "        \n",
    "        baseline.append([L2, angle])\n",
    "        \n",
    "        baseline_v2.append([i,j, L2, angle])\n",
    "        \n",
    "\n",
    "baseline = np.array(baseline)\n",
    "\n",
    "baseline_v2 = np.array(baseline_v2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a89d0467",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I order following L2 and then following angle. Then, I will need to separate them in subgroups to count\n",
    "# how many there are in a given category.\n",
    "\n",
    "from operator import itemgetter\n",
    "\n",
    "ordered_baselines_v2 = sorted(baseline_v2, key= itemgetter(2,3))\n",
    "\n",
    "\n",
    "ordered_baselines_v2 = np.array(ordered_baselines_v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b46533",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21df4cb4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e21a648b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that we have an ordered array (and we have the explicit number of the horns)\n",
    "\n",
    "print(ordered_baselines_v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44977d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another check to see if I'm getting what I want:\n",
    "\n",
    "count = 0\n",
    "for i in range(N):\n",
    "\n",
    "    for j in range(i+1,N):      \n",
    "        \n",
    "        \n",
    "        print(i,j, ordered_baselines_v2[count])\n",
    "        \n",
    "        count += 1\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50668423",
   "metadata": {},
   "source": [
    " ### Intermediate computing.\n",
    "    \n",
    "In the following, we do some computations, to separate the baselines in categories according to the value of $L2$ and **angle**.\n",
    "\n",
    "\n",
    "This is inspired by the example in the next (commented) cell."
   ]
  },
  {
   "cell_type": "raw",
   "id": "56ac31b7",
   "metadata": {},
   "source": [
    "## useful example taken from:\n",
    "# https://stackoverflow.com/questions/31863083/python-split-numpy-array-based-on-values-in-the-array\n",
    "\n",
    "np.split(arr, np.where(np.diff(arr[:,1]))[0]+1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ff2167",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are the L2 values:\n",
    "ordered_baselines_v2[:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae171634",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I compute where the L2 value changes:\n",
    "np.diff(ordered_baselines_v2[:,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16239248",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(np.diff(ordered_baselines_v2[:,2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e174cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "xx = np.diff(ordered_baselines_v2[:,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3baeb32",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(xx)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228a3999",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are the indices where the L2 value changes \n",
    "np.where(xx)[0]+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "819a4e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I split the array in the positions where L2 changes:\n",
    "\n",
    "zz= np.split(ordered_baselines_v2, np.where(np.diff(ordered_baselines_v2[:,2]))[0]+1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9227315",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa7eeb1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check:\n",
    "np.shape(zz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5560d6d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, for each distinct value of L2, I split the array in different values of the angle.\n",
    "\n",
    "partitioned_baselines = []\n",
    "\n",
    "for i in range(len(zz)):\n",
    "\n",
    "    \n",
    "    aa = zz[i]\n",
    "    \n",
    "    bb = np.split(aa, np.where(np.diff(aa[:,3]))[0]+1)\n",
    "\n",
    "    bb = np.array(bb)\n",
    "    \n",
    "    partitioned_baselines.append(bb)\n",
    "    \n",
    "\n",
    "partitioned_baselines = np.array(partitioned_baselines)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad8282a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.shape(partitioned_baselines))\n",
    "\n",
    "print(len(partitioned_baselines), partitioned_baselines.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c60a96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each value of L2, how many different values of the angle we have:\n",
    "\n",
    "for i in range(len(partitioned_baselines)):\n",
    "    print(len(partitioned_baselines[i]), partitioned_baselines[i])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc77fb99",
   "metadata": {},
   "source": [
    "In the following cell, I compute each unique baseline (characterized by a given value of $L^2$ and an given angle), and compute how many equivalent baselines there are in each category. \n",
    "\n",
    "If we want to make tests using equivalent baselines, we can read the corresponding horns' labels from the $0$ and $1$ elements of the **partitioned_baselines** array, and make the appropriate selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ccc450",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now I compute the number of unique baselines, and for each of them, \n",
    "# I compute the number of equivalent baselines (i.e. how many elements there are in that category):\n",
    "\n",
    "N_unique = 0\n",
    "\n",
    "for i in range(len(partitioned_baselines)):\n",
    "\n",
    "    n_angles  = len(partitioned_baselines[i])\n",
    "    \n",
    "    for j in range(n_angles):\n",
    "\n",
    "        print(partitioned_baselines[i][j])\n",
    "         \n",
    "        print(\" \")\n",
    "        \n",
    "        N_eq = len(partitioned_baselines[i][j])\n",
    "\n",
    "        print(\" Number of equivalent baselines for this particular baseline: \", N_eq)\n",
    "        #print(\" Shape of equivalent baseline set\", partitioned_baselines[i][j].shape)\n",
    "        print(\" \")\n",
    "        \n",
    "        N_unique += 1\n",
    "\n",
    "        \n",
    "print(\"Number of unique baselines: \", N_unique)\n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "raw",
   "id": "ba2d5e51",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c27c6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"for each one of claudias baseline types\n",
    "save for a file\n",
    "produce auxilliary file\"\"\"\n",
    "\n",
    "claudiasbaselinerep = \"/home/james/mylibs/multifrequency/baseline_files/ClaudiasBaselines/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d6c856",
   "metadata": {},
   "outputs": [],
   "source": [
    "fmt = '%d', '%d', '%1.4f', '%1.4f'\n",
    "\n",
    "N_unique = 0\n",
    "\n",
    "for i in range(len(partitioned_baselines)):\n",
    "\n",
    "    n_angles  = len(partitioned_baselines[i])\n",
    "    \n",
    "    for j in range(n_angles):\n",
    "\n",
    "        print(partitioned_baselines[i][j])\n",
    "         \n",
    "        print(\" \")\n",
    "        \n",
    "        N_eq = len(partitioned_baselines[i][j])\n",
    "\n",
    "        print(\" Number of equivalent baselines for this particular baseline: \", N_eq)\n",
    "        print(\" Shape of equivalent baseline set\", partitioned_baselines[i][j].shape)\n",
    "        print(\" \")\n",
    "        \n",
    "        N_unique += 1\n",
    "        \n",
    "        index1_partitioned_baselines = partitioned_baselines[i][j][:,0:2] + 1\n",
    "        index2_partitioned_baselines = np.hstack((index1_partitioned_baselines, partitioned_baselines[i][j][:,2:4]))\n",
    "        print(index1_partitioned_baselines.shape, index2_partitioned_baselines)\n",
    "        file = open(claudiasbaselinerep+\"CBtype_\"+str(N_unique)+\".txt\", \"w\")\n",
    "        file.write(\"pairTDh1, pairTDh2, L2, angle\"+'\\n')\n",
    "        np.savetxt(file, index2_partitioned_baselines, delimiter=', ', fmt=fmt)\n",
    "        file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7daa38d4",
   "metadata": {},
   "source": [
    "test load the files just created\n",
    "and test outputting the unique combinations for each type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef66e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "cbfiles = glob.glob(claudiasbaselinerep+'*.txt')\n",
    "#print(len(cbfiles))\n",
    "\n",
    "for file in cbfiles:\n",
    "    print(file)\n",
    "    dat = np.loadtxt(file, delimiter=',', skiprows=1)\n",
    "    #print(len(dat.shape))\n",
    "    \n",
    "    if len(dat.shape) == 1:\n",
    "        print(\"break for baseline of 1\")\n",
    "        continue\n",
    "    \n",
    "    bi = np.linspace(0, len(dat[:,0])-1, len(dat[:,0]), dtype=int)\n",
    "    arsize = scipy.special.factorial(len(bi)) / ( scipy.special.factorial(2) * scipy.special.factorial(len(bi) - 2))\n",
    "    #print(\"file, dat, bi, arsize, \", file, dat.shape, bi, arsize)\n",
    "    comb = np.array(list(combinations(bi, 2)))\n",
    "    #print(comb[0])\n",
    "    \n",
    "    for i in range(len(comb[:,0])):\n",
    "        print(i, comb[i], comb[i,0], comb[i,1], \n",
    "              dat[comb[i,0], 0], dat[comb[i,0], 1], dat[comb[i,1], 0], dat[comb[i,1], 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9260463",
   "metadata": {},
   "source": [
    "use qubic libraries to relate TD numbers to FI numbers. This is because the optical simulation data is labelled by FI numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c5eca91",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"above relates TD unique combinations\n",
    "now setup FI numeric conversion\"\"\"\n",
    "FIhorns = np.linspace(1,400,400, dtype=int)\n",
    "\n",
    "d = qubic.qubicdict.qubicDict()\n",
    "d.read_from_file('/home/james/libraries/qubic/qubic/dicts/pipeline_demo.dict')\n",
    "d['config'] = 'FI'\n",
    "q = qubic.QubicInstrument(d)\n",
    "\n",
    "centers = q.horn.center[:, 0:2]\n",
    "col = q.horn.column\n",
    "row = q.horn.row\n",
    "\n",
    "instFI = qubic.QubicInstrument(d)\n",
    "hornsFI = instFI.horn.open\n",
    "\n",
    "hornsTD = (col >= 8) & (col <= 15) & (row >= 8) & (row <= 15)\n",
    "\n",
    "instTD = qubic.QubicInstrument(d)\n",
    "instTD.horn.open[~hornsTD] = False\n",
    "\n",
    "cnt = 1\n",
    "TDhornsFIconf = np.zeros(400)\n",
    "\n",
    "%matplotlib notebook\n",
    "plt.figure(figsize=(10,10))\n",
    "q.horn.plot()\n",
    "for i in range(len(centers)):\n",
    "    if hornsTD[i] == True:\n",
    "        #plt.text(centers[i,0]-0.006, centers[i,1], 'c{0:}'.format(col[i]), color='r',fontsize=8)\n",
    "        #plt.text(centers[i,0]+0.00001, centers[i,1], 'r{0:}'.format(row[i]), color='b',fontsize=8)\n",
    "        plt.text(centers[i,0]-0.005, centers[i,1]-0.004, 'h {0:}'.format(str(i+1)), color='g',fontsize=8)\n",
    "        plt.text(centers[i,0]-0.005, centers[i,1], 'td {0:}'.format(str(cnt)), color='r',fontsize=8)\n",
    "        \n",
    "        TDhornsFIconf[i] = cnt\n",
    "        \n",
    "        cnt+=1\n",
    "instTD.horn.plot()\n",
    "plt.ylabel('Horn GRF Y (m)')\n",
    "plt.xlabel('Horn GRF X (m)')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbfaeed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"now convert TD to FI and check\"\"\"\n",
    "for file in cbfiles:\n",
    "    print(file)\n",
    "    dat = np.loadtxt(file, delimiter=',', skiprows=1)\n",
    "    #print(len(dat.shape))\n",
    "    \n",
    "    if len(dat.shape) == 1:\n",
    "        print(\"break for baseline of 1\")\n",
    "        continue\n",
    "    \n",
    "    bi = np.linspace(0, len(dat[:,0])-1, len(dat[:,0]), dtype=int)\n",
    "    arsize = scipy.special.factorial(len(bi)) / ( scipy.special.factorial(2) * scipy.special.factorial(len(bi) - 2))\n",
    "    #print(\"file, dat, bi, arsize, \", file, dat.shape, bi, arsize)\n",
    "    comb = np.array(list(combinations(bi, 2)))\n",
    "    print(comb.shape)\n",
    "    \n",
    "    for i in range(len(comb[:,0])):\n",
    "        print(i, comb[i], comb[i,0], comb[i,1], \n",
    "              dat[comb[i,0], 0], dat[comb[i,0], 1], dat[comb[i,1], 0], dat[comb[i,1], 1],\n",
    "             int(FIhorns[np.where(TDhornsFIconf == dat[int(comb[i,0]),0])]),\n",
    "             int(FIhorns[np.where(TDhornsFIconf == dat[int(comb[i,0]),1])]),\n",
    "             int(FIhorns[np.where(TDhornsFIconf == dat[int(comb[i,1]),0])]),\n",
    "             int(FIhorns[np.where(TDhornsFIconf == dat[int(comb[i,1]),1])]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce2d4c89",
   "metadata": {},
   "source": [
    "testing qubic libs working and a function to get RMSE calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "089ffd20",
   "metadata": {},
   "outputs": [],
   "source": [
    "basedir='/home/james/libraries/qubic/qubic'\n",
    "#basedir = Qubic_DataDir(datafile='instrument.py', ) \n",
    "print('basedir : ', basedir)\n",
    "dictfilename = basedir + '/dicts/global_source_oneDet.dict'\n",
    "d = qubic.qubicdict.qubicDict()\n",
    "#d.read_from_file('../qubic/qubic/dicts/global_source_oneDet.dict')\n",
    "#change to moddded dictionary\n",
    "d.read_from_file('/home/james/libraries/qubic/qubic/dicts/global_source_oneDet.dict')\n",
    "d['config'] = 'FI'\n",
    "q = qubic.QubicMultibandInstrument(d)\n",
    "\n",
    "vtxs = q[0].detector.vertex\n",
    "vtxcounter = np.zeros(992)\n",
    "print(\"vertexes shape: \", vtxs.shape)\n",
    "\n",
    "def RMSEtested(v1,v2):\n",
    "    return np.sqrt(np.mean((v1-v2)**2)), mean_squared_error(v1, v2, squared=False)\n",
    "\n",
    "def RMSE(v1,v2):\n",
    "    return np.sqrt(np.mean((v1-v2)**2))\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "#just to check...\n",
    "#MSE = mean_squared_error(y_actual, y_predicted, squared=False)\n",
    " \n",
    "#RMSE = math.sqrt(MSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f275247",
   "metadata": {},
   "source": [
    "here is a directory to the simulation files, Here is a link - https://maynoothuniversity-my.sharepoint.com/:u:/g/personal/james_murphy_2018_mumail_ie/EWFWx6YTco5ChvdzA1-MWesBTpRqsv30ttpKVwOlI8Ue1w?e=nKWAP6\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6af9727",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"now calc RMSE for each baseline in combination\n",
    "use in loop above\"\"\"\n",
    "my150dat = '/media/james/DATA/GRASPdata/MyTabSourceFIModel/150GHz/MODALfiles/'\n",
    "#also need vtxs\n",
    "\n",
    "def RMSEcalc(file):\n",
    "\n",
    "    #print(i)\n",
    "    x, y, i1 = calculate_intensity_4_baseline((120, 146), my150dat)\n",
    "    x, y, i2 = calculate_intensity_4_baseline((121, 147), my150dat)\n",
    "    \n",
    "    rmse = RMSE(i1,i2)\n",
    "    print(rmse)\n",
    "    #px, py, pi = IntegrateHornCombOnFP(i, np.array([x, y]), vtxs)\n",
    "    #print(x.shape, i.shape, px.shape, pi.shape)\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c32c7c",
   "metadata": {},
   "source": [
    "test parralel code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233180f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"time to calc 1 horn pair as FP baseline and then integrat on dets = 37 seconds \\n\n",
    "lets say 378 pair combs in baseline = 37 * 2 * 378 \\n\n",
    "approx 8 hours\n",
    "for that baseline type\n",
    "\n",
    "I should probably try this parrallel function again...!\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e3f4184",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "num_cores=16\n",
    "inputs=tqdm(cbfiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad8386d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# startm = timer()\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#         process=Parallel(n_jobs=num_cores)(delayed(RMSEcalc)(file) for file in inputs)\n",
    "        \n",
    "# endm = timer()\n",
    "# print(\"time taken parrallel\", endm - startm, \"s\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd019bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(len(process), len(cbfiles))\n",
    "\n",
    "#cbfilesshort = cbfiles[:57]\n",
    "\n",
    "#print(cbfilesshort)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "cbfiles.sort(key=lambda f: int(re.sub('\\D', '', f)))\n",
    "\n",
    "print(cbfiles[95:108])\n",
    "\n",
    "cbfilesshort = cbfiles[103:108]\n",
    "\n",
    "# print(cbfilesshort[90:100])\n",
    "\n",
    "# file = open(claudiasbaselinerep+\"RMSEs/\"+\"CBtypeRMSE_\"+str(N_unique)+\".txt\", \"w\")\n",
    "# file.write(\"h1, h2, h3, h4, FPRMSE, pixRMSE\"+'\\n')\n",
    "# np.savetxt(file, index2_partitioned_baselines, delimiter=', ', fmt=fmt)\n",
    "# file.close()\n",
    "\n",
    "#16 files started approx 17:30 \n",
    "#for all combs, 2 fps, 2 pix calcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "416dc8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#os.path.basename('/folderA/folderB/folderC/folderD')\n",
    "rmsepath = '/home/james/mylibs/multifrequency/baseline_files/ClaudiasBaselines/RMSEs/'\n",
    "rmseApath = '/home/james/mylibs/multifrequency/baseline_files/ClaudiasBaselines/RMSEs/analysisdata/'\n",
    "\n",
    "def RMSEcalc(file):\n",
    "    #load file\n",
    "    dat = np.loadtxt(file, delimiter=',', skiprows=1)\n",
    "    \n",
    "    if len(dat.shape) == 1:\n",
    "        print(\"break for baseline of 1\")\n",
    "        return\n",
    "\n",
    "    bi = np.linspace(0, len(dat[:,0])-1, len(dat[:,0]), dtype=int)\n",
    "    comb = np.array(list(combinations(bi, 2)))\n",
    "    \n",
    "    #open a file here and file orginal file\n",
    "    fname = os.path.basename(file)  \n",
    "    sfile = open(rmsepath+'RMSE_'+fname, \"w\")\n",
    "    sfile.write(\"Orginal CB type file -> \"+file+'\\n')\n",
    "    sfile.write(\"tdh1, tdh2, tdh3, tdh4, h1, h2, h3, h4, rmse\"+'\\n')\n",
    "    \n",
    "    for i in range(len(comb[:,0])):\n",
    "        print(i, comb[i], comb[i,0], comb[i,1], \n",
    "              dat[comb[i,0], 0], dat[comb[i,0], 1], dat[comb[i,1], 0], dat[comb[i,1], 1],\n",
    "             int(FIhorns[np.where(TDhornsFIconf == dat[int(comb[i,0]),0])]),\n",
    "             int(FIhorns[np.where(TDhornsFIconf == dat[int(comb[i,0]),1])]),\n",
    "             int(FIhorns[np.where(TDhornsFIconf == dat[int(comb[i,1]),0])]),\n",
    "             int(FIhorns[np.where(TDhornsFIconf == dat[int(comb[i,1]),1])]))\n",
    "    \n",
    "    #print(i)\n",
    "        x, y, i1 = calculate_intensity_4_baseline((int(FIhorns[np.where(TDhornsFIconf == dat[int(comb[i,0]),0])]), int(FIhorns[np.where(TDhornsFIconf == dat[int(comb[i,0]),1])])), my150dat)\n",
    "        x, y, i2 = calculate_intensity_4_baseline((int(FIhorns[np.where(TDhornsFIconf == dat[int(comb[i,1]),0])]), int(FIhorns[np.where(TDhornsFIconf == dat[int(comb[i,1]),1])])), my150dat)\n",
    "        rmse1 = RMSE(i1/max(i1), i2/max(i2))\n",
    "#         px, py, pi1 = IntegrateHornCombOnFP(i1, np.array([x, y]), vtxs)\n",
    "#         px, py, pi2 = IntegrateHornCombOnFP(i2, np.array([x, y]), vtxs)\n",
    "#         rmse2 = RMSE(pi1, pi2)\n",
    "        sfile.write(\"{}, {}, {}, {}, {}, {}, {}, {}, {:.5e} \\n\".format(\n",
    "            int(dat[comb[i,0], 0]),\n",
    "            int(dat[comb[i,0], 1]),\n",
    "            int(dat[comb[i,1], 0]),\n",
    "            int(dat[comb[i,1], 1]),\n",
    "            int(FIhorns[np.where(TDhornsFIconf == dat[int(comb[i,0]),0])]),\n",
    "            int(FIhorns[np.where(TDhornsFIconf == dat[int(comb[i,0]),1])]),\n",
    "            int(FIhorns[np.where(TDhornsFIconf == dat[int(comb[i,1]),0])]),\n",
    "            int(FIhorns[np.where(TDhornsFIconf == dat[int(comb[i,1]),1])]),\n",
    "            rmse1))\n",
    "        \n",
    "    #close file here\n",
    "    sfile.close()\n",
    "    \n",
    "    return \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4569fa9f",
   "metadata": {},
   "source": [
    "here the parallel code is run to calculate the RMSEs for all combinations in all combination types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35847912",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cores=16\n",
    "inputs=tqdm(cbfiles)\n",
    "\n",
    "startm = timer()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "        process=Parallel(n_jobs=num_cores)(delayed(RMSEcalc)(file) for file in inputs)\n",
    "        \n",
    "endm = timer()\n",
    "print(\"time taken parrallel\", endm - startm, \"s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77aae822",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"95 - 108 10 seconds with no TES\n",
    "85 - 108 24 seconds with no TES\n",
    "85 - 108 with TES calc = \n",
    "55 mins for all combs and files with no TES rmse calc\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07394a9c",
   "metadata": {},
   "source": [
    "do the plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eba9308",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rmsepath = '/home/james/mylibs/multifrequency/baseline_files/ClaudiasBaselines/RMSEs/'\n",
    "jet= plt.get_cmap('jet')\n",
    "colors = iter(jet(np.linspace(0,10,11)))\n",
    "\n",
    "rmsefiles = glob.glob(rmsepath+'*.txt')\n",
    "rmsefiles.sort(key=lambda f: int(re.sub('\\D', '', f)))\n",
    "#print(rmsefiles)\n",
    "\n",
    "typelist = np.array([])\n",
    "rmses = np.array([])\n",
    "rmsesm = np.array([])\n",
    "rmsesSTD = np.array([])\n",
    "ind = np.array([])\n",
    "\n",
    "font = {'family' : 'normal',\n",
    "        'weight' : 'normal',\n",
    "        'size'   : 20}\n",
    "plt.rc('font', **font)\n",
    "%matplotlib inline\n",
    "plt.rc('font', **font)\n",
    "plt.figure(figsize=(16, 8))\n",
    "\n",
    "temp=0\n",
    "#106 since only one baseline for these types\n",
    "for i, file in enumerate(rmsefiles[0:106]):\n",
    "    \n",
    "    num = re.findall(r'\\d+', file)\n",
    "    #print(file, num, i)\n",
    "    \n",
    "    dat = np.loadtxt(file, delimiter = ',', skiprows=2)\n",
    "    \n",
    "    temp = len(dat[:,8].shape) + temp\n",
    "    \n",
    "    index = i+temp\n",
    "        \n",
    "    nums = np.full(dat[:,8].shape, num)\n",
    "    \n",
    "    #print(dat.shape, i, dat[:,8].shape, nums.shape)\n",
    "    \n",
    "    \n",
    "    rmses = np.append(rmses, dat[:,8])\n",
    "    rmsesm = np.append(rmsesm, np.mean(dat[:,8]))\n",
    "    rmsesSTD = np.append(rmsesSTD, np.std(dat[:,8]))\n",
    "    typelist = np.append(typelist, nums)\n",
    "    ind = np.append(ind, index)\n",
    "\n",
    "    plt.plot(nums, dat[:,8], '.', markersize=10)\n",
    "\n",
    "plt.legend(loc='upper right', fontsize=12)\n",
    "plt.xlabel('Baseline Type')\n",
    "plt.ylabel('RMSE')\n",
    "\n",
    "#plt.savefig('/media/james/DATA/baseline_figures/results_cb_all.png', facecolor='white')\n",
    "\n",
    "plt.figure(figsize=(16, 8))\n",
    "for i, file in enumerate(rmsefiles[0:106]):\n",
    "    plt.plot(i+1, rmsesm[i], 's', markersize=5)\n",
    "    \n",
    "plt.gca().set_prop_cycle(None)\n",
    "for i, file in enumerate(rmsefiles[0:106]):\n",
    "    plt.errorbar(i+1, rmsesm[i], yerr=rmsesSTD[i], elinewidth=3)\n",
    "    \n",
    "plt.xlabel('Baseline Type')\n",
    "plt.ylabel('Mean RMSE with Standard Deviation')\n",
    "\n",
    "#plt.savefig('/media/james/DATA/baseline_figures/results_cb_meanstd.png', facecolor='white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c79d797",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"finished\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a9ea76e",
   "metadata": {},
   "source": [
    "The rest is just test code and debugging that may be useful in the future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f9989b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(typelist), len(rmses), len(ind))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa6bb8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import cm\n",
    "import seaborn as sns\n",
    "color=iter(cm.rainbow(np.linspace(0,len(typelist),len(typelist))))\n",
    "colors = iter(plt.cm.Spectral(np.linspace(0,len(typelist),len(typelist))))\n",
    "#print(colors.shape)\n",
    "\n",
    "colors = sns.palplot(sns.color_palette(\"hls\", len(typelist)))\n",
    "\n",
    "color=iter(cm.rainbow(np.linspace(0,1,len(typelist))))\n",
    "# for i in range(n):\n",
    "#    cn = next(color)\n",
    "#    plt.plot(x, y,c=c)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(16, 8))\n",
    "\n",
    "plt.scatter(typelist, rmses, '.', color=colors)\n",
    "\n",
    "#for i in range(len(typelist)):\n",
    "    \n",
    "\n",
    "# # # #     plt.plot(typelist[i], rmses[i], '.', \n",
    "# # # #              color=(0, typelist[i] / max(typelist), typelist[i] / max(typelist), typelist[i] / max(typelist)))\n",
    "#     plt.plot(typelist[i], rmses[i], color=c)\n",
    "\n",
    "#     if typelist[i] > typelist[i-1]:\n",
    "#         c=next(color)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2a98ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# startm = timer()\n",
    "# ls = []\n",
    "# for file in cbfiles:\n",
    "#     ls.append(RMSEcalc(file))\n",
    "\n",
    "# endm = timer()\n",
    "# print(\"time taken cpu loop\", endm - startm, \"s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a418fa4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"okay great so parrallel is faster this time!\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ce297d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def RMSEcalc2(horns):\n",
    "#     #print(horns)\n",
    "\n",
    "#     #print(i)\n",
    "#     x, y, i1 = calculate_intensity_4_baseline((121, 147), my150dat)\n",
    "#     x, y, i2 = calculate_intensity_4_baseline((120, 146), my150dat)\n",
    "#     rmse = RMSE(i1,i2)\n",
    "#     print(rmse)\n",
    "#     #px, py, pi = IntegrateHornCombOnFP(i, np.array([x, y]), vtxs)\n",
    "#     #print(x.shape, i.shape, px.shape, pi.shape)\n",
    "#     return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de246ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\"now try with file as main loop but combs as parrallel\"\"\"\n",
    "\n",
    "# \"\"\"now convert TD to FI and check 50, 51 has a problem type 97\"\"\"\n",
    "# for file in cbfiles[0:1]:\n",
    "#     print(file)\n",
    "#     dat = np.loadtxt(file, delimiter=',', skiprows=1)\n",
    "#     #print(len(dat.shape))\n",
    "    \n",
    "#     if len(dat.shape) == 1:\n",
    "#         print(\"break for baseline of 1\")\n",
    "#         continue\n",
    "    \n",
    "#     bi = np.linspace(0, len(dat[:,0])-1, len(dat[:,0]), dtype=int)\n",
    "#     arsize = scipy.special.factorial(len(bi)) / ( scipy.special.factorial(2) * scipy.special.factorial(len(bi) - 2))\n",
    "#     #print(\"file, dat, bi, arsize, \", file, dat.shape, bi, arsize)\n",
    "#     comb = np.array(list(combinations(bi, 2)))\n",
    "#     print(comb.shape)\n",
    "    \n",
    "#     h1 = []\n",
    "#     h2 = []\n",
    "#     h3 = []\n",
    "#     h4 = []\n",
    "    \n",
    "#     for i in range(len(comb[:,0])):\n",
    "    \n",
    "#         h1.append(FIhorns[np.where(TDhornsFIconf == dat[int(comb[i,0]),0])])\n",
    "#         h2.append(FIhorns[np.where(TDhornsFIconf == dat[int(comb[i,0]),1])])\n",
    "#         h3.append(FIhorns[np.where(TDhornsFIconf == dat[int(comb[i,1]),0])])\n",
    "#         h4.append(FIhorns[np.where(TDhornsFIconf == dat[int(comb[i,1]),1])])\n",
    "    \n",
    "#     ha = np.hstack([h1, h2, h3, h4])\n",
    "#     print(ha.shape)\n",
    "\n",
    "# #     num_cores = 16\n",
    "\n",
    "# #     if len(ha[:,0]) <= 16:\n",
    "# #         num_cores=1\n",
    "# #         continue\n",
    "#     inputs=tqdm(ha)\n",
    "    \n",
    "    \n",
    "#     if __name__ == '__main__':\n",
    "#         process=Parallel(n_jobs=num_cores)(delayed(RMSEcalc2)(i) for i in inputs)\n",
    "        \n",
    "#     #RMSE for these combinations\n",
    "#     RMSE = np.array(process)\n",
    "#     print(\"RMSE shape, \", RMSE.shape)\n",
    "    \n",
    "#     tosave = np.hstack([ha, RMSE])\n",
    "#     print(\"to save shape,  \", tosave.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08500bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #print(len(inputs))\n",
    "# print(ha.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a110ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in ha:\n",
    "#     print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85afb97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs=tqdm(ha)\n",
    "\n",
    "# startm = timer()\n",
    "    \n",
    "# if __name__ == '__main__':\n",
    "#     proces=Parallel(n_jobs=num_cores)(delayed(RMSEcalc2)(i) for i in inputs)\n",
    "\n",
    "        \n",
    "# endm = timer()\n",
    "# print(\"time taken parrallel\", endm - startm, \"s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec15f384",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(proces), proces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "823a4676",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"time to loop over 378 horn combs a calc rmse residual approx 32 seconds\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f58503",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs=tqdm(ha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c80ea65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843c5ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RMSEcalc3(h1, h2, h3, h4):\n",
    "    #print(horns)\n",
    "\n",
    "    #print(i)\n",
    "    x, y, i1 = calculate_intensity_4_baseline((h1, h2), my150dat)\n",
    "    x, y, i2 = calculate_intensity_4_baseline((h3, h4), my150dat)\n",
    "    rmse1 = RMSE(i1, i2)\n",
    "    print(rmse)\n",
    "    px, py, pi1 = IntegrateHornCombOnFP(i, np.array([x, y]), vtxs)\n",
    "    px, py, pi2 = IntegrateHornCombOnFP(i, np.array([x, y]), vtxs)\n",
    "    rmse2 = RMSE(pi1, pi2)\n",
    "    #print(x.shape, i.shape, px.shape, pi.shape)\n",
    "    return rmse1, rmse2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3990614f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RMSEforHornCombs(file):\n",
    "    print(file)\n",
    "    #load file\n",
    "    dat = np.loadtxt(file, delimiter=',', skiprows=1)\n",
    "    #print(len(dat.shape))\n",
    "    \n",
    "    #check to make sure combination exists\n",
    "    if len(dat.shape) == 1:\n",
    "        print(\"break for baseline of 1\")\n",
    "        return\n",
    "        \n",
    "    #create indexed combinations\n",
    "    bi = np.linspace(0, len(dat[:,0])-1, len(dat[:,0]), dtype=int)\n",
    "    #arsize = scipy.special.factorial(len(bi)) / ( scipy.special.factorial(2) * scipy.special.factorial(len(bi) - 2))\n",
    "    #print(\"file, dat, bi, arsize, \", file, dat.shape, bi, arsize)\n",
    "    comb = np.array(list(combinations(bi, 2)))\n",
    "    print(comb.shape)\n",
    "    \n",
    "    h1 = np.array(len(comb[:,0]))\n",
    "    h2 = np.array(len(comb[:,0]))\n",
    "    h3 = np.array(len(comb[:,0]))\n",
    "    h4 = np.array(len(comb[:,0]))\n",
    "    #set TD horns in FI indexing\n",
    "    h1 = np.array(FIhorns[np.where(TDhornsFIconf == dat[int(comb[:,0]),0])])\n",
    "    h2 = FIhorns[np.where(TDhornsFIconf == dat[int(comb[:,0]),1])]\n",
    "    h3 = FIhorns[np.where(TDhornsFIconf == dat[int(comb[:,1]),0])]\n",
    "    h4 = FIhorns[np.where(TDhornsFIconf == dat[int(comb[:,1]),1])]\n",
    "    \n",
    "    #calculation RMSE for each horn combination\n",
    "    RMSE_FP = []\n",
    "    RMSE_dets = []\n",
    "    for i in range(len(comb[:,0])):\n",
    "    \n",
    "        rmse1, rmse2 = RMSEcalc3(h1[i], h2[i], h3[i], h4[i])\n",
    "        \n",
    "        RMSE_FP.append(rmse1)\n",
    "        RMSE_dets.append(rmse2)\n",
    "        \n",
    "    RMSE_FP = np.array(RMSE_FP)\n",
    "    RMSE_dets = np.array(RMSE_dets)\n",
    "    \n",
    "    savear = np.hstack([h1, h2, h3, h4, RMSE_FP, RMSE_dets])\n",
    "    print(savear.shape)\n",
    "    \n",
    "    #now save to file\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42234b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cores=16\n",
    "inputs=tqdm(cbfiles)\n",
    "\n",
    "startm = timer()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "        process=Parallel(n_jobs=num_cores)(delayed(RMSEforHornCombs)(file) for file in inputs)\n",
    "        \n",
    "endm = timer()\n",
    "print(\"time taken parrallel\", endm - startm, \"s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb0e5649",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
