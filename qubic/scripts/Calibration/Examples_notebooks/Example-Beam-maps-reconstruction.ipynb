{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7f76389",
   "metadata": {},
   "source": [
    "# Example of Beam maps analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede879b9",
   "metadata": {},
   "source": [
    "This notebook is to explain how to use the new method for beam maps analysis. The new method brings all the old method to have a easy way to compute beam maps of QUBIC."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b0b526",
   "metadata": {},
   "source": [
    "# Importation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f79e429",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%matplotlib notebook\n",
    "%matplotlib inline\n",
    "from matplotlib import rc\n",
    "rc('figure',figsize=(9,4.5))\n",
    "rc('font',size=12)\n",
    "rc('text',usetex=False)\n",
    "\n",
    "from qubicpack.qubicfp import qubicfp\n",
    "import qubic.demodulation_lib as dl\n",
    "from pysimulators import FitsArray\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib.pyplot import *\n",
    "# import matplotlib.mlab as mlab\n",
    "import scipy.ndimage.filters as f\n",
    "import glob\n",
    "import string\n",
    "# import pickle\n",
    "from importlib import reload\n",
    "import healpy as hp\n",
    "import os\n",
    "\n",
    "import DataHandling as DH\n",
    "\n",
    "from qubicpack.utilities import Qubic_DataDir\n",
    "import qubic\n",
    "from qubic import selfcal_lib as scal\n",
    "# Get a dictionary\n",
    "basedir = Qubic_DataDir()\n",
    "print('basedir : ', basedir)\n",
    "dictfilename = basedir + '/dicts/global_source_oneDet.dict'\n",
    "d = qubic.qubicdict.qubicDict()\n",
    "d.read_from_file(dictfilename)\n",
    "q = qubic.QubicInstrument(d)\n",
    "\n",
    "# If there is not this command, the kernel shut down every time..\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4110af63",
   "metadata": {},
   "outputs": [],
   "source": [
    "day = '2022-04-14'\n",
    "#day= '2020-11-10'\n",
    "keyword = '*Scan*'\n",
    "#keyword= '*test'\n",
    "#data_dir = '/sps/hep/qubic/Data/'+day+'/'\n",
    "data_dir = day+'/'\n",
    "dirs = np.sort(glob.glob(data_dir+keyword))\n",
    "print(dirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24fc96ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "day = '2022-04-14'\n",
    "\n",
    "#day= '2020-11-10'\n",
    "keyword = '**'\n",
    "#keyword= '*test'\n",
    "#data_dir = '/sps/hep/qubic/Data/'+day+'/'\n",
    "data_dir = day+'/'\n",
    "dirs = np.sort(glob.glob(data_dir+keyword))\n",
    "print(dirs)\n",
    "\n",
    "ifile = 0\n",
    "thedir = dirs[ifile]\n",
    "print(thedir)\n",
    "#note here is how you load the data in memory!\n",
    "a = qubicfp()\n",
    "a.read_qubicstudio_dataset(thedir)\n",
    "#a.read_qubicstudio_dataset('/path/to/dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b04c63",
   "metadata": {},
   "source": [
    "Here you can have several information on the calibration source."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0f26ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(a.hk.keys())\n",
    "a.hk.keys()\n",
    "\n",
    "print(\"The keys in this dictionary are:\\n\")\n",
    "for k in a.hk['CALSOURCE-CONF'].keys():\n",
    "    print(k, a.hk['CALSOURCE-CONF'][k])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca90139a",
   "metadata": {},
   "source": [
    "For this dataset, the scan was performed without modulation of the source, so in this configuration you don't have to demodulate and to filter the data before making flat maps. \n",
    "\n",
    "The analysis is perform in a very easy way, you just have to write a simple line to analyse all the TES and sev them. \n",
    "\n",
    "+ If you want to analyse all TES, keep `number_of_tes=None`\n",
    "\n",
    "+ If not, put the number of the TES that you want to analyse (the number of the TES, not in python index)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b8be58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you already precompute beam maps, you can skip this step. If not, decomment and run the line to have them\n",
    "\n",
    "# If you want to save files, be careful to put save=True because the computation is long \n",
    "\n",
    "\n",
    "# Make a loop over TES\n",
    "#from importlib import reload\n",
    "#reload(DH)\n",
    "\n",
    "# Construction of the object\n",
    "#analysis=DH.BeamMapsAnalysis(a)\n",
    "\n",
    "# Analysis of all TES\n",
    "#mymaps=analysis.fullanalysis(number_of_tes=None, filter=False, demod=False, remove_noise=True, \n",
    "#                                                                          doplot=False, save=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32362b5f",
   "metadata": {},
   "source": [
    "Congratulation, you have analyse all the TES and created beam maps for this dataset ! Maybe you want to see your data, in `DataHandling.py`, you can see your data directly on the focal plane."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c18b538",
   "metadata": {},
   "source": [
    "# Visualisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce6c5421",
   "metadata": {},
   "source": [
    "The computation can be long for all TES, in `DataHandling.py` you can find a function to open previous fits file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "501fcb50",
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(DH)\n",
    "tes=np.arange(1, 257, 1)\n",
    "\n",
    "allmaps=np.zeros((len(tes), 101, 101))\n",
    "\n",
    "for i in tes:\n",
    "    print(i)\n",
    "    beam=DH._read_fits_beam_maps(i)\n",
    "    allmaps[i-1]=beam.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55515e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "reload(DH)\n",
    "DH.plot_data_on_FP(datain=allmaps, vmin=0, vmax=2e5, q=q, savepdf=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f24dc8",
   "metadata": {},
   "source": [
    "We can also see 1D plot, not for this dataset but it can be useful for others. You just have to adapt the shape of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e63a3174",
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "reload(DH)\n",
    "DH.plot_data_on_FP(datain=allmaps[:, 51], q=q, savepdf=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb9e01a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc9e997",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d200221d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085b3437",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60831cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
