{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2bf221bb",
   "metadata": {},
   "source": [
    "Automatic function for the correction of the jumps (more than one version): \n",
    "- Saturation function \n",
    "- Application of not of the savgol filter that adjusts a polynomial  \n",
    "- Haar filter \n",
    "- Threshold \n",
    "- Clustering, beginning and final of the jump. If the distance between jumps is very small I don't save this data. \n",
    "- Offsets, with differences or fitting a lineal polynomial\n",
    "- Correction\n",
    "- Correccion of the peaks that are left over, only data that is removed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf45341",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_dir = '/home/bcostanza/qubic/jumps'\n",
    "\n",
    "\n",
    "dataset0 = top_dir+'/2022-07-14/2022-07-14_23.54.19__MoonScan_Speed_VE14'\n",
    "\n",
    "import numpy as np\n",
    "from qubicpack.qubicfp import qubicfp\n",
    "import sys,os\n",
    "import numpy as np\n",
    "\n",
    "from qubic import fibtools as ft\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from pysimulators import FitsArray\n",
    "\n",
    "from qubic import fibtools as ft\n",
    "from qubic.plotters import *\n",
    "from qubicpack.qubicfp import qubicfp\n",
    "import qubic.demodulation_lib as dl\n",
    "import qubic.sb_fitting as sbfit\n",
    "from qubic.io import write_map\n",
    "\n",
    "import matplotlib.mlab as mlab\n",
    "import scipy.ndimage.filters as f\n",
    "\n",
    "from scipy.signal import argrelextrema, find_peaks, find_peaks_cwt, savgol_filter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82b4830",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bottleneck as bn\n",
    "from sklearn.cluster import DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "962a7c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = qubicfp()\n",
    "a.read_qubicstudio_dataset(dataset0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55011019",
   "metadata": {},
   "outputs": [],
   "source": [
    "tod = a.tod()\n",
    "timeaxis = tod[0]\n",
    "todarray = tod[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea348ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "init = timeaxis[0]\n",
    "tt = timeaxis - init"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e63afd4b",
   "metadata": {},
   "source": [
    "Discard saturated TES more than 10%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad6fdfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def saturation(todarray): \n",
    "    \n",
    "    \n",
    "    #returns  ok = array of True and False \n",
    "    #         bad_idx = idx of the saturated TES in the focalplane \n",
    "    #         frac_sat_pertes = fraction of the TOD saturated in the TES\n",
    "    #         number = number of TES saturated more than 10% in the focalplane\n",
    "    \n",
    "    ok = np.ones(256,dtype=bool)\n",
    "    maxis = np.max(abs(todarray), axis=1)\n",
    "    upper_satval = np.max(maxis)\n",
    "    lower_satval = -np.max(maxis)\n",
    "    badtes = (maxis == np.max(maxis))\n",
    "    number = badtes.sum() #number of TES saturated in every measurement\n",
    "    bad_idx = np.array(np.where(badtes==True)) #index of the TES saturated\n",
    "    bad_idx = np.reshape(bad_idx, (bad_idx.shape[1]))\n",
    "\n",
    "    frac_sat_pertes = np.zeros((256))\n",
    "    size = todarray.shape[1]\n",
    "\n",
    "    for i in range(len(todarray)): \n",
    "        mask1 = todarray[i] == upper_satval\n",
    "        mask2 = todarray[i] == lower_satval\n",
    "        frac = (np.sum(mask1)+np.sum(mask2))/size\n",
    "        frac_sat_pertes[i] = frac\n",
    "    \n",
    "        if frac_sat_pertes[i] ==0:\n",
    "            ok[i] = True #good, no saturated\n",
    "        elif frac_sat_pertes[i] >0.1:\n",
    "            ok[i] = False #bad, saturated more than 10%\n",
    "        else: \n",
    "            ok[i] = True #good, saturated but less than 10%\n",
    "            \n",
    "    return ok, bad_idx, frac_sat_pertes, number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fba85ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "ok, bad_idx, frac, number = saturation(todarray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6614cf65",
   "metadata": {},
   "outputs": [],
   "source": [
    "number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a25726ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_tod = np.array(np.where(ok==False))\n",
    "bad_tod = np.reshape(bad_tod, (bad_tod.shape[1]))\n",
    "good_tod = np.array(np.where(ok==True))\n",
    "good_tod = np.reshape(good_tod, (good_tod.shape[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40710795",
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_tod #discarded, only index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1129eca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "good_tod #TES that I will work, some of them have jumps "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d576b104",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2e623720",
   "metadata": {},
   "source": [
    "Function that detects the jumps V1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b036e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def jumps_new(todarray, size=100, treshold=0.2e6, doplot=False): \n",
    "    \n",
    "    #return xc = beginning of the jump \n",
    "    #       xcf = final of the jump \n",
    "    #       dif = diference between the final of a jump and the beginning of the next jump \n",
    "    #       nc = number of clusters/number of jumps \n",
    "    \n",
    "    tod_sav = savgol_filter(todarray,window_length=401,polyorder=3, mode='nearest')\n",
    "    \n",
    "    def haar(x, size=100):\n",
    "        out = np.zeros(x.size)\n",
    "        xf = bn.move_median(x, size)[size:]   \n",
    "        out[size+size//2:-size+size//2] = xf[:-size] - xf[size:]\n",
    "        return out\n",
    "    \n",
    "    #treshold using that the difference is going to be value between 0.25e6, 0.5e6, 1e6, 1.5e6, 2e6, 2.5e6\n",
    "    jumps = np.abs(tod_haar) > treshold\n",
    "    \n",
    "    #if you don't find any jump then don't make the savgol filter and try with the unfiltered TOD\n",
    "    true = np.array(np.where(jumps==False))\n",
    "    if true.shape[1] == len(todarray):\n",
    "        tod_haar = haar(todarray)\n",
    "        jumps = np.abs(tod_haar) > treshold\n",
    "\n",
    "    \n",
    "    idx = np.arange(len(todarray))\n",
    "    idx_jumps = idx[jumps] - 50 \n",
    "    time_jumps = tt[jumps]\n",
    "        \n",
    "    \n",
    "    clust = DBSCAN(eps=size//5, min_samples=1).fit(np.reshape(idx_jumps, (len(idx_jumps),1)))\n",
    "    nc = np.max(clust.labels_)+1\n",
    "    xc = np.zeros(nc, dtype=int) \n",
    "    xcf = np.zeros(nc, dtype=int)\n",
    "    for i in range(nc):\n",
    "        xc[i] = np.min(idx_jumps[clust.labels_ == i])\n",
    "        xcf[i]= np.max(idx_jumps[clust.labels_ == i])\n",
    "        \n",
    "        \n",
    "    dif = np.zeros(nc-1)\n",
    "    for j in range(nc):\n",
    "        if j < nc-1:\n",
    "            dif[j] = xc[j+1]-xcf[j]\n",
    "        \n",
    "        \n",
    "    if doplot == True:\n",
    "        fig, ax = plt.subplots(3, figsize = (10,10))\n",
    "        if true.shape[1] == len(todarray):\n",
    "            ax[0].plot(tt, todarray)\n",
    "            ax2 = ax[0].twinx()\n",
    "            ax2.plot(tt, tod_haar, color='red', label='haar filter')\n",
    "            ax[0].set_xlabel('time')\n",
    "            ax[0].set_ylabel('tod')\n",
    "            ax2.set_ylabel('haar filter')\n",
    "            ax2.legend()\n",
    "        else:\n",
    "            ax[0].plot(tt, tod_sav)\n",
    "            ax2 = ax[0].twinx()\n",
    "            ax2.plot(tt, tod_haar, color='red', label='haar filter')\n",
    "            ax[0].set_xlabel('time')\n",
    "            ax[0].set_ylabel('tod')\n",
    "            ax2.set_ylabel('haar filter')\n",
    "            ax2.legend()\n",
    "        \n",
    "        if true.shape[1] == len(todarray):\n",
    "            ax[1].plot(tt, todarray)\n",
    "            ax[1].plot(tt[idx_jumps], todarray[idx_jumps], 'r.', label='time samples jumps')        \n",
    "            ax[1].set_xlabel('time')\n",
    "            ax[1].set_ylabel('tod')\n",
    "            ax[1].legend()\n",
    "        else:       \n",
    "            ax[1].plot(tt, tod_sav)\n",
    "            ax[1].plot(tt[idx_jumps], tod_sav[idx_jumps], 'r.', label='time samples jumps')        \n",
    "            ax[1].set_xlabel('time')\n",
    "            ax[1].set_ylabel('tod')\n",
    "            ax[1].legend()\n",
    "        \n",
    "        ax[2].plot(tt, tod_haar, label='haar filter')\n",
    "        ax[2].plot(tt[idx_jumps], tod_haar[idx_jumps], 'r.')\n",
    "        ax[2].plot(tt[xc], tod_haar[xc], 'g.')\n",
    "        ax[2].plot(tt[xcf], tod_haar[xcf], 'g.')\n",
    "        ax[2].legend()\n",
    "        \n",
    "    return xc, xcf, dif, nc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be0410f",
   "metadata": {},
   "outputs": [],
   "source": [
    "xc_5, xcf_5, dif_5, number_5= jumps_new(todarray[5],doplot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc08438",
   "metadata": {},
   "outputs": [],
   "source": [
    "xc_31, xcf_31, dif_31, number_31 = jumps_new(todarray[31],doplot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b062106",
   "metadata": {},
   "outputs": [],
   "source": [
    "xc_51, xcf_51, dif_51, number_51 = jumps_new(todarray[50],doplot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3398b18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "xc_28, xcf_28, dif_28, number_28 = jumps_new(todarray[28],doplot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c52ff632",
   "metadata": {},
   "outputs": [],
   "source": [
    "tod_31 = todarray[31]\n",
    "idx = np.arange(len(tod_31))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aec4347",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(idx, tod_31)\n",
    "plt.plot(idx[xc_31], tod_31[xc_31], 'r.', label='cluster initial')\n",
    "plt.plot(idx[xcf_31], tod_31[xcf_31], 'g.', label='cluster final')\n",
    "plt.xlabel('time')\n",
    "plt.ylabel('tod')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0980f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(idx, tod_31)\n",
    "plt.plot(idx[xc_31], tod_31[xc_31], 'r.', label='cluster initial')\n",
    "plt.plot(idx[xcf_31], tod_31[xcf_31], 'g.', label='cluster final')\n",
    "plt.xlabel('time')\n",
    "plt.ylabel('tod')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7056ddf6",
   "metadata": {},
   "source": [
    "Function that redefines the number of clusters. If the distances between clusters if very small I'm going to consider as a single one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94aedbbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def redefine(xc, xcf, dif, number): \n",
    "    \n",
    "    shape = np.shape(dif)\n",
    "    if shape != 0:  \n",
    "        for i in range(number-1): \n",
    "            value = dif[i]\n",
    "            if value < 500.: \n",
    "                number_new = number -1 \n",
    "                xc_new = np.zeros(number-1, dtype=int)\n",
    "                xcf_new = np.zeros(number-1, dtype=int)\n",
    "                for j in range(number-1): \n",
    "                    xc_new[j]= xc[i]\n",
    "                    xcf_new[j] = xcf[i+1]\n",
    "    return xc_new, xcf_new, number_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9779ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "xc_new, xcf_new, number_new = redefine(xc_31,xcf_31,dif_31,number_31)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40dd6b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_new "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda150a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "xc_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44e2228",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(idx, tod_31)\n",
    "plt.plot(idx[xc_new], tod_31[xc_new], 'r.')\n",
    "plt.plot(idx[xcf_new], tod_31[xcf_new], 'r.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edcc9b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Correction of the jump calculating the offset and shifting\n",
    "def corr_off(todarray, xc, xcf, number, region=100):  \n",
    "    tod_new = todarray.copy()\n",
    "    offset = np.zeros(number)\n",
    "    for i in range(len(xc)): \n",
    "        offset[i] = np.median(todarray[xcf[i]:xcf[i]+region])-np.median(todarray[xc[i]-region:xc[i]])\n",
    "    if number == 1: \n",
    "        initial = xcf[0]\n",
    "        final = idx[-1]+1\n",
    "        tod_new[initial:final] = todarray[initial:final] - offset[0]\n",
    "    else:\n",
    "        for i in range(len(xcf)-1,-1,-1):\n",
    "            initial = xcf[i]\n",
    "            final = idx[-1]+1\n",
    "            tod_new[initial:final]=tod_new[initial:final]-offset[i]\n",
    "    return tod_new, offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c9893c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Correction of the jump fitting a linear polynomial and shifting\n",
    "def pol_corr(todarray, xc, xcf, number, region=100): \n",
    "    tod_new = todarray.copy()\n",
    "    pol = np.zeros(len(xc))\n",
    "    off = np.zeros(len(xc))\n",
    "    for i in range(len(xc)):        \n",
    "        tp = tt[xc[i]-region:xcf[i]+region]\n",
    "        adup = todarray[xc[i]-region:xcf[i]+region]\n",
    "        z = np.polyfit(tp, adup, 1)\n",
    "        p = np.poly1d(z)\n",
    "        pol = p(tp)\n",
    "        off[i] = pol[-1]-pol[0]\n",
    "    if number == 1: \n",
    "        tod_new[xcf[0]+region:] = todarray[xcf[0]+region:] - off[0]\n",
    "    else: \n",
    "        for i in range(len(xcf)-1,-1,-1):\n",
    "            initial = xcf[i]\n",
    "            final = idx[-1]+1\n",
    "            tod_new[initial:final]=tod_new[initial:final]-off[i]\n",
    "    return tod_new, off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70db0b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tod_new_51, offset_51 = corr_off(todarray[50], xc_51, xcf_51, number_51, region=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b111d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(tt, tod_new_51)\n",
    "plt.ylabel('tod corrected')\n",
    "plt.xlabel('time')\n",
    "plt.title('TES 51')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146ba9ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "tod_pol_51, offset_51 = pol_corr(todarray[50],xc_51, xcf_51, number_51, region=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85200bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(tt, tod_pol_51)\n",
    "plt.ylabel('tod corrected')\n",
    "plt.xlabel('time')\n",
    "plt.title('TES 51')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd3b9161",
   "metadata": {},
   "outputs": [],
   "source": [
    "tod_new_28, offset_28 = corr_off(todarray[28], xc_28, xcf_28, number_28, region=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d8a95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "offset_28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0333dccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(tt, tod_new_28)\n",
    "plt.ylabel('tod corrected')\n",
    "plt.xlabel('time')\n",
    "plt.title('TES 28')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3604109e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace the peak with random noise realization\n",
    "def changesignal(y, xini, xend):\n",
    "    # interpolation + random noise\n",
    "    #yini = np.mean(y[:xini])\n",
    "    #yend = np.mean(y[xend:])# - offset\n",
    "    y_cor = y.copy()\n",
    "    # Take the std of the signal up to idx_jump\n",
    "    for i in range(len(xini)):        \n",
    "        std = np.std(y[xini[i]-10:xini[i]])# * (len(y[:xini]))/(len(y[:xini])-1)\n",
    "        mean = np.mean(y[xini[i]-10:xini[i]])\n",
    "        ynew=np.random.normal(mean, std, len(y[xini[i]:xend[i]]))\n",
    "        y_cor[xini[i]:xend[i]] = ynew\n",
    "    \n",
    "    return y_cor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ea9fb0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91edefdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "tod = todarray[good_tod]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40800799",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00b32fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e2213266",
   "metadata": {},
   "source": [
    "Function that detects the jumps V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e6498e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def jumps_new_2(todarray, size=100, treshold=0.2e6, doplot=False): \n",
    "    \n",
    "    #return xc = beginning of the jump \n",
    "    #       xcf = final of the jump \n",
    "    #       dif = diference between the final of a jump and the beginning of the next jump \n",
    "    #       nc = number of clusters/number of jumps\n",
    "    \n",
    "    \n",
    "    tod_sav = savgol_filter(todarray,window_length=401,polyorder=3, mode='nearest')\n",
    "    \n",
    "    def haar(x, size=100):\n",
    "        out = np.zeros(x.size)\n",
    "        xf = bn.move_median(x, size)[size:]   \n",
    "        out[size+size//2:-size+size//2] = xf[:-size] - xf[size:]\n",
    "        return out\n",
    "    \n",
    "    #treshold using that the difference is going to be a value between 0.25e6, 0.5e6, 1e6, 1.5e6, 2e6, 2.5e6\n",
    "    \n",
    "    tod_haar_sav = haar(tod_sav, size)\n",
    "    tod_haar = haar(todarray,size)\n",
    "    \n",
    "    #if you don't find any jump then don't make the savgol filter and try with the unfiltered TOD\n",
    "    if max(abs(tod_haar_sav)) < treshold:\n",
    "        #if the tood haar also is less than 0.2, probably is not a jump \n",
    "        if max(abs(tod_haar)) < 0.2e6:\n",
    "            number = 0\n",
    "            print('no jump')\n",
    "            return number\n",
    "        else:\n",
    "            jumps = np.abs(tod_haar) > treshold\n",
    "            no_sav = True #don't use the savgol filter\n",
    "    else:\n",
    "        no_sav = False\n",
    "        print('use savgol')\n",
    "        jumps = np.abs(tod_haar_sav) > treshold\n",
    "    \n",
    "    idx = np.arange(len(todarray))\n",
    "    #por el threshold que pones me parece que estas perdiendo valores por eso al indice le resto 50\n",
    "    idx_jumps = idx[jumps] - 50\n",
    "    time_jumps = tt[jumps]\n",
    "        \n",
    "    \n",
    "    clust = DBSCAN(eps=size//5, min_samples=1).fit(np.reshape(idx_jumps, (len(idx_jumps),1)))\n",
    "    nc = np.max(clust.labels_)+1\n",
    "    xc = np.zeros(nc, dtype=int) \n",
    "    xcf = np.zeros(nc, dtype=int)\n",
    "    for i in range(nc):\n",
    "        xc[i] = np.min(idx_jumps[clust.labels_ == i])\n",
    "        xcf[i]= np.max(idx_jumps[clust.labels_ == i])\n",
    "        \n",
    "    delta = xcf - xc\n",
    "    print(delta)\n",
    "    for i in range(len(delta)):\n",
    "        if delta[i] < 80: \n",
    "            number = 0 \n",
    "            print('no jump')\n",
    "            return number \n",
    "        \n",
    "    dif = np.zeros(nc-1)\n",
    "    for j in range(nc):\n",
    "        #print(j)\n",
    "        if j < nc-1:\n",
    "            dif[j] = xc[j+1]-xcf[j]\n",
    "        \n",
    "        \n",
    "    if doplot == True:\n",
    "        fig, ax = plt.subplots(3, figsize = (10,10))\n",
    "        if no_sav:\n",
    "            ax[0].plot(tt, todarray)\n",
    "            ax2 = ax[0].twinx()\n",
    "            ax2.plot(tt, tod_haar, color='red', label='haar filter')\n",
    "            ax[0].set_xlabel('time')\n",
    "            ax[0].set_ylabel('tod')\n",
    "            ax2.set_ylabel('haar filter')\n",
    "            ax2.legend()\n",
    "        else:\n",
    "            ax[0].plot(tt, tod_sav)\n",
    "            ax2 = ax[0].twinx()\n",
    "            ax2.plot(tt, tod_haar, color='red', label='haar filter')\n",
    "            ax[0].set_xlabel('time')\n",
    "            ax[0].set_ylabel('tod')\n",
    "            ax2.set_ylabel('haar filter')\n",
    "            ax2.legend()\n",
    "        \n",
    "        if no_sav:\n",
    "            ax[1].plot(tt, todarray)\n",
    "            ax[1].plot(tt[idx_jumps], todarray[idx_jumps], 'r.', label='time samples jumps')        \n",
    "            ax[1].set_xlabel('time')\n",
    "            ax[1].set_ylabel('tod')\n",
    "            ax[1].legend()\n",
    "        else:       \n",
    "            ax[1].plot(tt, tod_sav)\n",
    "            ax[1].plot(tt[idx_jumps], tod_sav[idx_jumps], 'r.', label='time samples jumps')        \n",
    "            ax[1].set_xlabel('time')\n",
    "            ax[1].set_ylabel('tod')\n",
    "            ax[1].legend()\n",
    "        \n",
    "        if no_sav:            \n",
    "            ax[2].plot(tt, tod_haar, label='haar filter')\n",
    "            ax[2].plot(tt[idx_jumps], tod_haar[idx_jumps], 'r.')\n",
    "            ax[2].plot(tt[xc], tod_haar[xc], 'g.')\n",
    "            ax[2].plot(tt[xcf], tod_haar[xcf], 'g.')\n",
    "            ax[2].legend()\n",
    "        else:\n",
    "            ax[2].plot(tt, tod_haar_sav, label='haar filter')\n",
    "            ax[2].plot(tt[idx_jumps], tod_haar_sav[idx_jumps], 'r.')\n",
    "            ax[2].plot(tt[xc], tod_haar_sav[xc], 'g.')\n",
    "            ax[2].plot(tt[xcf], tod_haar_sav[xcf], 'g.')\n",
    "            ax[2].legend()\n",
    "        \n",
    "    return xc, xcf, dif, nc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed58b1a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1ce25269",
   "metadata": {},
   "source": [
    "Loop in the entire focalplane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7fd76a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(tod)):\n",
    "    good = tod[i]\n",
    "    locals()['result_{}'.format(i)]=jumps_new_2(good,doplot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e45c825",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b23d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "result3 = jumps_new_2(tod[3], doplot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18222cb3",
   "metadata": {},
   "source": [
    "Example of no jump detected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f54e161",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(tt, todarray[48])\n",
    "plt.title('TES 49')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf8db52",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(tt, tod[28])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b68edb52",
   "metadata": {},
   "outputs": [],
   "source": [
    "result15 = jumps_new_2(tod[15], doplot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93eca0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "result5 = jumps_new_2(todarray[5], doplot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e0f0d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d79df73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d939a809",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66743069",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14826aaa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad24e9c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
