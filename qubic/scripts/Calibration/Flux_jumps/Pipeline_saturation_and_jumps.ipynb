{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "b5bf0fda",
      "metadata": {},
      "source": [
        "General idea of a pipeline for the detection of the time samples with saturation and flux jumps\n",
        "\n",
        "Author: BelÃ©n Costanza, Elenia Manzan, Mathias Regnier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f7753e2d",
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from qubicpack.qubicfp import qubicfp\n",
        "import sys,os\n",
        "import numpy as np\n",
        "import glob\n",
        "\n",
        "from qubic import fibtools as ft\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from pysimulators import FitsArray\n",
        "\n",
        "from qubic import fibtools as ft\n",
        "from qubic.plotters import *\n",
        "from qubicpack.qubicfp import qubicfp\n",
        "import qubic.demodulation_lib as dl\n",
        "import qubic.sb_fitting as sbfit\n",
        "from qubic.io import write_map\n",
        "\n",
        "import matplotlib.mlab as mlab\n",
        "import scipy.ndimage.filters as f\n",
        "\n",
        "from scipy.signal import argrelextrema, find_peaks, find_peaks_cwt, savgol_filter \n",
        "\n",
        "import bottleneck as bn\n",
        "from sklearn.cluster import DBSCAN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e5eaae8e",
      "metadata": {},
      "outputs": [],
      "source": [
        "%matplotlib notebook"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ff151fc2",
      "metadata": {},
      "source": [
        "Put the day that you want to analyze "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e8744d76",
      "metadata": {},
      "outputs": [],
      "source": [
        "day = '2023-03-06'\n",
        "data_dir = '/home/qubic/Calib-TD/'+day+'/'\n",
        "words = ['DomeOpen']\n",
        "keywords = ['*{}*'.format(word) for word in words]\n",
        "for keyword in keywords:\n",
        "    dirs = np.sort(glob.glob(data_dir+keyword))\n",
        "    print(dirs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eb91e63c",
      "metadata": {},
      "outputs": [],
      "source": [
        "dirs[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "74af056a",
      "metadata": {},
      "outputs": [],
      "source": [
        "if len(dirs)==1: \n",
        "    dataset0 = dirs[0]\n",
        "    a = qubicfp()\n",
        "    a.read_qubicstudio_dataset(dataset0)\n",
        "\n",
        "\n",
        "else: \n",
        "    for ifile in range(len(dirs)):\n",
        "        thedir = dirs[ifile]\n",
        "        print('================', thedir,)\n",
        "        locals()['qfp_{}'.format(ifile)] = qubicfp()\n",
        "        locals()['qfp_{}'.format(ifile)].read_qubicstudio_dataset(thedir)\n",
        "        locals()['tod_{}'.format(ifile)] = locals()['qfp_{}'.format(ifile)].tod()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bfd8cf61",
      "metadata": {},
      "outputs": [],
      "source": [
        "tod = a.tod()\n",
        "timeaxis = tod[0]\n",
        "todarray = tod[1]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "34426e27",
      "metadata": {},
      "outputs": [],
      "source": [
        "init = timeaxis[0]\n",
        "tt = timeaxis - init"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1c35da2f",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "f80148b9",
      "metadata": {},
      "source": [
        "### Saturation function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "184df012",
      "metadata": {},
      "outputs": [],
      "source": [
        "def saturation(todarray): \n",
        "    \n",
        "    #returns  ok = array of True and False, True if it's saturated, False if's not\n",
        "    #         bad_idx = idx of the saturated TES in the focalplane \n",
        "    #         frac_sat_pertes = fraction of the TOD saturated in the TES\n",
        "    #         number = number of TES saturated \n",
        "    \n",
        "    ok = np.ones(256,dtype=bool)\n",
        "    maxis = np.max(abs(todarray), axis=1)\n",
        "    upper_satval = 4.19e6\n",
        "    lower_satval = -4.19e6\n",
        "    \n",
        "    frac_sat_pertes = np.zeros((256))\n",
        "    size = todarray.shape[1]\n",
        "\n",
        "    for i in range(len(todarray)): \n",
        "        mask1 = todarray[i] > upper_satval\n",
        "        mask2 = todarray[i] < lower_satval\n",
        "        frac = (np.sum(mask1)+np.sum(mask2))/size\n",
        "        frac_sat_pertes[i] = frac\n",
        "    \n",
        "        if frac_sat_pertes[i] ==0:\n",
        "            ok[i] = True #good, no saturated\n",
        "        elif frac_sat_pertes[i] > 0.:\n",
        "            ok[i] = False #bad, saturated\n",
        "        else:\n",
        "            ok[i] = True\n",
        "    \n",
        "    bad_idx = np.array(np.where(ok==False))\n",
        "    bad_idx = np.reshape(bad_idx, bad_idx.shape[1])        \n",
        "    number = len(bad_idx)    \n",
        "        \n",
        "    return ok, bad_idx, frac_sat_pertes, number"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d40e4791",
      "metadata": {},
      "outputs": [],
      "source": [
        "ok, bad_idx, frac, number = saturation(todarray)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2979246d",
      "metadata": {},
      "source": [
        "- How many TES are saturated? \n",
        "- Which ones? "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "290fa5cb",
      "metadata": {},
      "outputs": [],
      "source": [
        "print('number of TES saturated in the focal plane:', number)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c4873c3d",
      "metadata": {},
      "outputs": [],
      "source": [
        "print('index TES saturated:')\n",
        "print(bad_idx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "de05302a",
      "metadata": {},
      "outputs": [],
      "source": [
        "TES_saved = (frac < 0.1) & (frac >0.)\n",
        "TES_number = np.arange(256)\n",
        "index_TES_saved = TES_number[TES_saved]\n",
        "print('TES with saturation less than 10% and the signal can be saved')\n",
        "print(index_TES_saved)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ab063d53",
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.title('TES with saturation less than 10%')\n",
        "for i in range(len(index_TES_saved)):\n",
        "    index = index_TES_saved[i]\n",
        "    plt.plot(tt, todarray[index])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "10f23ea1",
      "metadata": {},
      "outputs": [],
      "source": [
        "bad_tod = np.array(np.where(ok==False))\n",
        "bad_tod = np.reshape(bad_tod, (bad_tod.shape[1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "45afc700",
      "metadata": {},
      "outputs": [],
      "source": [
        "TES_saturated = bad_tod"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "37d0db4e",
      "metadata": {},
      "source": [
        "### Jumps functions\n",
        "\n",
        "We are going to look out the TES with no saturation and identify the jumps candidates"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "771f7734",
      "metadata": {},
      "outputs": [],
      "source": [
        "print('index TES with no saturation:')\n",
        "good_tod = np.array(np.where(ok==True))\n",
        "good_tod = np.reshape(good_tod, (good_tod.shape[1]))\n",
        "print(good_tod)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bd9a2bb3",
      "metadata": {},
      "source": [
        "Necessary functions for the detection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9b94c451",
      "metadata": {},
      "outputs": [],
      "source": [
        "def haar(x, size=100):\n",
        "    out = np.zeros(x.size)\n",
        "    xf = bn.move_median(x, size)[size:]   \n",
        "    out[size+size//2:-size+size//2] = xf[:-size] - xf[size:]\n",
        "    return out\n",
        "\n",
        "def find_jumps(tod_haar, thr):    #Elenia's version, function that iterate through many thresholds\n",
        "    number = 0\n",
        "    jumps = 0\n",
        "    thr_used = 0 \n",
        "        #iterate over the amplitude thresholds\n",
        "    for j,thr_val in enumerate(thr):\n",
        "        if number == 0: #haven't detected any jump yet\n",
        "            if max(abs(tod_haar)) < thr_val:\n",
        "                print('No jump')\n",
        "            else: #there's a jump\n",
        "                number += 1\n",
        "                thr_used = thr_val\n",
        "                print('Found jump')\n",
        "                jumps = (abs(tod_haar) >= thr_val) #save the timestamp of the jump\n",
        "                threshold_TES = thr_val\n",
        "        else:\n",
        "            pass\n",
        "    return jumps, thr_used\n",
        "\n",
        "def clusters(todarray,jumps):\n",
        "    size=130\n",
        "    idx = np.arange(len(todarray))\n",
        "    idx_jumps = idx[jumps]\n",
        "    if idx_jumps.size > 1:\n",
        "        clust = DBSCAN(eps=size//5, min_samples=1).fit(np.reshape(idx_jumps, (len(idx_jumps),1)))\n",
        "        nc = np.max(clust.labels_)+1\n",
        "    else: \n",
        "        nc = 0.\n",
        "        idx_jumps = 0.\n",
        "        clust = 0.\n",
        "    return nc, idx_jumps, clust\n",
        "\n",
        "def star_end(nc, idx_jumps, tod_haar, thr_used, clust):\n",
        "    #consider the jump to be over when it's (filtered) amplitude is reduced by 95% (beware: now use raw tod!)\n",
        "    xc = np.zeros(nc, dtype=int) \n",
        "    xcf = np.zeros(nc, dtype=int)\n",
        "    \n",
        "    for i in range(nc):\n",
        "        idx_jumps_from_thr = idx_jumps[clust.labels_ == i]\n",
        "        idx_delta_end_jump = np.where( tod_haar[idx_jumps_from_thr[-1]:] < thr_used*0.05 )[0][0]\n",
        "        idx_delta_start_jump = idx_jumps_from_thr[0] - np.where( tod_haar[:idx_jumps_from_thr[0]] < thr_used*0.05 )[0][-1]\n",
        "        xc[i] = idx_jumps_from_thr[0] - idx_delta_start_jump\n",
        "        xcf[i] = idx_jumps_from_thr[-1] + idx_delta_end_jump\n",
        "        \n",
        "    delta = xcf - xc\n",
        "    return xc, xcf, delta \n",
        "        "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "18be42a8",
      "metadata": {},
      "source": [
        "Function that detect the time samples of the jumps using the functions defined in the cell above"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ac9b4c85",
      "metadata": {},
      "outputs": [],
      "source": [
        "def jumps_detection(todarray):\n",
        "    size = 130\n",
        "    thr = np.array([2e5, 1.5e5, 1e5, 5e4, 4e4, 3e4])\n",
        "    \n",
        "    tod_haar = haar(todarray,size) #1. make the haar filter of the raw TOD\n",
        "    \n",
        "    jumps, thr_used= find_jumps(tod_haar, thr) #2. if the haar filter is higher than a threshold then is a jump \n",
        "                                               #   (iterate through an array of possible thresholds)\n",
        "   \n",
        "    nc, idx_jumps, clust = clusters(todarray, jumps) #3. Cluster the jumps and find the number of jumps detected in every TES\n",
        "    \n",
        "    if nc==0.:\n",
        "        xc=0\n",
        "        xcf=0\n",
        "        delta=0\n",
        "        return nc, xc, xcf, delta\n",
        "    \n",
        "    if nc > 10:                                         #4. Elenia's idea: if the number of jumps is higher than 10, then filter the raw TOD with Salvitzky golay                                                       # then filter\n",
        "        thr = np.array([2e5, 1.5e5, 1e5, 5e4, 4e4, 3e4])\n",
        "        tod_sav = savgol_filter(todarray,window_length=401,polyorder=3, mode='nearest')\n",
        "        tod_haar_sav = haar(tod_sav, size)\n",
        "        jumps_sav, thr_used = find_jumps(tod_haar_sav, thr)\n",
        "        nc, idx_jumps, clust = clusters(tod_sav, jumps_sav)\n",
        "        if nc==0:\n",
        "            xc=0\n",
        "            xcf=0\n",
        "            delta=0\n",
        "            return nc, xc, xcf, delta\n",
        "    \n",
        "    xc, xcf, delta = star_end(nc, idx_jumps, tod_haar, thr_used, clust) #5. find the beginning and the end of a jump, also the size of the jump\n",
        "\n",
        "    \n",
        "    return nc, xc, xcf, delta\n",
        "    \n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "925b77d4",
      "metadata": {},
      "source": [
        "run the code over the entire set of TES with no saturation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ffbfef1d",
      "metadata": {},
      "outputs": [],
      "source": [
        "for i in range(len(good_tod)):\n",
        "    idx_good = good_tod[i]\n",
        "    print('Analisis TES', idx_good)\n",
        "    locals()['nc_{}'.format(idx_good)], locals()['xc_{}'.format(idx_good)],  locals()['xcf_{}'.format(idx_good)],  locals()['delta_{}'.format(idx_good)]=jumps_detection(todarray[idx_good])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "062aedbc",
      "metadata": {},
      "outputs": [],
      "source": [
        "TES_jump = np.ones(len(good_tod), dtype=int)\n",
        "for i in range(len(good_tod)):\n",
        "    idx = good_tod[i]   \n",
        "    result = locals()['nc_{}'.format(idx)]\n",
        "    if result == 0.:\n",
        "        TES_jump[i] = 0 \n",
        "        \n",
        "TES_yes = np.array(np.where(TES_jump==1))\n",
        "TES_yes = good_tod[TES_yes]\n",
        "TES_no = np.array(np.where(TES_jump==0))\n",
        "TES_no = good_tod[TES_no]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bf4f4d34",
      "metadata": {},
      "outputs": [],
      "source": [
        "print('index of TES with candidates to flux jumps detected:')\n",
        "print(TES_yes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f2748589",
      "metadata": {},
      "outputs": [],
      "source": [
        "TES_yes = np.reshape(TES_yes, TES_yes.shape[1])\n",
        "TES_no = np.reshape(TES_no, TES_no.shape[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e4909cff",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ab17d5d0",
      "metadata": {},
      "outputs": [],
      "source": [
        "np.save('TES_candidates_jumps_0306.npy', TES_yes)\n",
        "np.save('TES_nojumps_0306.npy', TES_no)\n",
        "np.save('TES_saturated_0306.npy', TES_saturated)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ddc739a2",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "f9e5008a",
      "metadata": {},
      "source": [
        "If you have enough memory you can plot the function of Mathias that plot all the TES in the focalplane with the raw TOD and colors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b4cad9a3",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7a664ba8",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "015389bd",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "c19caa70",
      "metadata": {},
      "source": [
        "### Discrimination functions\n",
        "\n",
        "Not all of the TES with flux jumps detected have real flux jumps, some of them are only very noisy TES with higher peaks that the code confuses as jumps. \n",
        "\n",
        "Apply discrimination functions that can estimate if it's a real jump or not: \n",
        "\n",
        "- Threshold to the size of a jump (very tiny jumps are probably not jumps)\n",
        "- Take a region near the jump detected and analyze the derivation, the derivative of a peak won't change a lot as the derivative of a jump (in general it's deeper). Here we made an iteration over many characteristic thresholds in the derivative "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0b47a173",
      "metadata": {},
      "outputs": [],
      "source": [
        "def redefine_jumps(nc, xc, xcf, delta):\n",
        "    delta_thr = np.rint(len(tt)/4915.2)\n",
        "    del_idx = np.reshape(np.array(np.where(delta<delta_thr)),np.array(np.where(delta<delta_thr)).shape[1])\n",
        "    xc = np.delete(xc, del_idx) #if the amount of time samples is less than 90 probably is not a jump \n",
        "    xcf = np.delete(xcf, del_idx)\n",
        "    nc -= len(del_idx)\n",
        "    return nc, xc, xcf   \n",
        "\n",
        "def derivation(todarray, xc, xcf, region=10):\n",
        "    ini, fin = xc, xcf\n",
        "    tod_portion, time_portion = todarray[ini-region:fin+region], tt[ini-region:fin+region]\n",
        "    smooth_tod = savgol_filter(tod_portion, window_length=401, polyorder=4, mode='nearest')\n",
        "    deriv_tod_smooth = np.diff(smooth_tod)\n",
        "    deriv_tod_raw = np.diff(tod_portion)\n",
        "    return time_portion, tod_portion, smooth_tod, deriv_tod_smooth    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "28b3b766",
      "metadata": {},
      "outputs": [],
      "source": [
        "nc_171_new, xc_171_new, xcf_171_new = redefine_jumps(nc_171, xc_171, xcf_171, delta_171)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "28c0618f",
      "metadata": {},
      "source": [
        "only an example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9bc74e8e",
      "metadata": {},
      "outputs": [],
      "source": [
        "fig, ax=plt.subplots(1,2)\n",
        "\n",
        "ax[0].plot(tt, todarray[171])\n",
        "ax[0].set_title('TES 171: jumps before')\n",
        "ax[0].plot(tt[xc_171], todarray[171][xc_171], 'r.')\n",
        "ax[0].plot(tt[xcf_171], todarray[171][xcf_171], 'g.')\n",
        "\n",
        "ax[1].plot(tt, todarray[171])\n",
        "ax[1].set_title('TES 171: jumps after')\n",
        "ax[1].plot(tt[xc_171_new], todarray[171][xc_171_new], 'r.')\n",
        "ax[1].plot(tt[xcf_171_new], todarray[171][xcf_171_new], 'g.')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "73d24232",
      "metadata": {},
      "source": [
        "run the discrimination functions over the entire set of TES with flux jumps detected:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "336eb04a",
      "metadata": {},
      "outputs": [],
      "source": [
        "thr_deriv = np.array([4000,3000,2500, 2300, 1800])\n",
        "idx_real = np.zeros(len(TES_yes), dtype=int)\n",
        "for i in range(len(TES_yes)):\n",
        "    index = TES_yes[i]\n",
        "    tod = todarray[index] \n",
        "    nc_old = locals()['nc_{}'.format(index)]\n",
        "    xc_old = locals()['xc_{}'.format(index)]\n",
        "    xcf_old = locals()['xcf_{}'.format(index)]\n",
        "    delta = locals()['delta_{}'.format(index)]\n",
        "    locals()['nc_new_{}'.format(index)], locals()['xc_new_{}'.format(index)], locals()['xcf_new_{}'.format(index)] = redefine_jumps(nc_old, xc_old, xcf_old, delta)\n",
        "    \n",
        "    nc_new = locals()['nc_new_{}'.format(index)]    \n",
        "    xc_new = locals()['xc_new_{}'.format(index)]\n",
        "    xcf_new = locals()['xcf_new_{}'.format(index)]\n",
        "    \n",
        "    for j in range(nc_new):            \n",
        "        time_portion, tod_portion, smooth_tod, deriv_tod = derivation(tod, xc_new[j], xcf_new[j], region=10)\n",
        "        for k in range(len(thr_deriv)):\n",
        "            if max(abs(deriv_tod)) > thr_deriv[k]:\n",
        "                idx_real[i] = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7879f6db",
      "metadata": {},
      "outputs": [],
      "source": [
        "tes_real_jump = TES_yes[idx_real==1]\n",
        "tes_no_jump = TES_yes[idx_real == 0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1579dd14",
      "metadata": {},
      "outputs": [],
      "source": [
        "TES_yesjumps = tes_real_jump"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "59774379",
      "metadata": {},
      "outputs": [],
      "source": [
        "print('index of TES with real flux jumps:')\n",
        "tes_real_jump"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "863e8b9c",
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.title('TES with real jumps')\n",
        "for i in range(len(tes_real_jump)):\n",
        "    index = tes_real_jump[i]\n",
        "    plt.plot(tt, todarray[index])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d1040ae4",
      "metadata": {},
      "outputs": [],
      "source": [
        "TES_nojumps = np.concatenate((TES_no, tes_no_jump))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "045db2d6",
      "metadata": {},
      "outputs": [],
      "source": [
        "TES_nojumps = np.sort(TES_nojumps)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e0d72bd7",
      "metadata": {},
      "outputs": [],
      "source": [
        "TES_nojumps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ba109060",
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.title('TES with no jumps')\n",
        "for i in range(len(TES_nojumps)):\n",
        "    index = TES_nojumps[i]\n",
        "    plt.plot(tt, todarray[index])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5e6a6aec",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "fa53d606",
      "metadata": {},
      "source": [
        "Until now you have three important arrays: \n",
        " - TES_saturated = index of the TES with saturation \n",
        " - TES_yesjumps = index of the TES with flux jumps (detected by this process)\n",
        " - TES_nojumps = index of TES with no flux jumps and no saturation "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "93d13bad",
      "metadata": {},
      "outputs": [],
      "source": [
        "np.save('TES_real_jumps_0306.npy', TES_yesjumps)\n",
        "np.save('TES_real_nojumps_0306.npy', TES_nojumps)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f1bdb61d",
      "metadata": {},
      "outputs": [],
      "source": [
        "def offset_func(todarray, xc, xcf, number, region=50, order=1):  \n",
        "    #tod_new = todarray.copy()\n",
        "    offset_lin = np.zeros(number)\n",
        "    idx = np.arange(len(todarray))\n",
        "    for i in range(len(xc)): \n",
        "        offset_lin[i] = np.median(todarray[xcf[i]:xcf[i]+region])-np.median(todarray[xc[i]-region:xc[i]])\n",
        "    \n",
        "    pol = np.zeros(len(xc))\n",
        "    offset_pol = np.zeros(len(xc))\n",
        "    for i in range(len(xc)):        \n",
        "        tp = tt[xc[i]-region:xcf[i]+region]\n",
        "        adup = todarray[xc[i]-region:xcf[i]+region]\n",
        "        z = np.polyfit(tp, adup, order)\n",
        "        p = np.poly1d(z)\n",
        "        pol = p(tp)\n",
        "        offset_pol[i] = pol[-1]-pol[0]\n",
        "    \n",
        "    return offset_lin, offset_pol"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "caec5fc1",
      "metadata": {},
      "outputs": [],
      "source": [
        "index_TES_saved"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b007eee0",
      "metadata": {},
      "outputs": [],
      "source": [
        "nc_sat_3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cae104cc",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e0d0bc96",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "69f8d7a0",
      "metadata": {},
      "outputs": [],
      "source": [
        "for i in range(len(index_TES_saved)):\n",
        "    index = index_TES_saved[i]\n",
        "    tod = todarray[index]\n",
        "    locals()['nc_sat_{}'.format(index)], locals()['xc_sat_{}'.format(index)], locals()['xcf_sat_{}'.format(index)], locals()['delta_sat_{}'.format(index)] = jumps_detection(tod)\n",
        "    locals()['off_lin_{}'.format(index)], locals()['off_pol_{}'.format(index)] = offset_func(tod, locals()['xc_sat_{}'.format(index)], locals()['xcf_sat_{}'.format(index)], locals()['nc_sat_{}'.format(index)])\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "057b2bc0",
      "metadata": {},
      "outputs": [],
      "source": [
        "for i in range(len(index_TES_saved)):\n",
        "    index = index_TES_saved[i]\n",
        "    print('TES',index) \n",
        "    print('offset',locals()['off_lin_{}'.format(index)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "95e14d93",
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.plot(tt, todarray[13])\n",
        "plt.plot(tt[xc_sat_13], todarray[13][xc_sat_13], 'r.')\n",
        "plt.plot(tt[xcf_sat_13], todarray[13][xcf_sat_13], 'g.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4ffccc1b",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {},
  "nbformat": 4,
  "nbformat_minor": 5
}
