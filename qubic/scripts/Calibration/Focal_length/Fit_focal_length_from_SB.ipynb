{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2461d9f7",
   "metadata": {},
   "source": [
    "# Fit focal length from the Beam measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75065bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import healpy as hp\n",
    "import scipy.optimize as op\n",
    "from astropy.io import fits \n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, Math\n",
    "from matplotlib.colors import SymLogNorm\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "%matplotlib inline\n",
    "%matplotlib notebook\n",
    "\n",
    "from matplotlib import rc\n",
    "rc('figure', figsize=(12, 12))\n",
    "rc('font', size=14)\n",
    "\n",
    "import emcee\n",
    "import corner\n",
    "\n",
    "from qubicpack.utilities import Qubic_DataDir\n",
    "import qubic \n",
    "from qubic import selfcal_lib as scal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1719df0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary\n",
    "d = qubic.qubicdict.qubicDict()\n",
    "d.read_from_file(os.environ['QUBIC_DICT']+'pipeline_demo.dict')\n",
    "\n",
    "d['config'] = 'TD'\n",
    "d['synthbeam_kmax'] = 3\n",
    "d['nside'] = 256\n",
    "NSIDE = d['nside']\n",
    "npix = 12 * NSIDE**2\n",
    "\n",
    "kmax = d['synthbeam_kmax']\n",
    "npeaks = (2 * kmax + 1)**2\n",
    "\n",
    "# Scene\n",
    "s = qubic.QubicScene(d)\n",
    "q = qubic.QubicInstrument(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ddb0933",
   "metadata": {},
   "source": [
    "### Get real data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58371df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "mydir = '/home/lmousset/QUBIC/Qubic_work/Calibration/datas/Synthetic_beams/'\n",
    "\n",
    "# === 2019 April\n",
    "date = '2019-avril'\n",
    "freq = 150\n",
    "data_dir = mydir + date + f'/synth_beam_{freq}/Healpix/'\n",
    "myname = date + '_Healpix_maps.pdf'\n",
    "# Selection of good TES\n",
    "PIX_ok = [6, 9, 16, 22, 26, 27, 37, 50, 51, 58, 73, 74, 75, 76, 80, 83, 86, 87, 93, 107, \n",
    "          34, 135, 150, 170, 185, 186, 191, 195, 206, 210, 218, 219, 236] \n",
    "PIX_ok = [93, 37, 73]\n",
    "\n",
    "# === 2020 January\n",
    "# date = '2020-01-14'\n",
    "# data_dir = mydir + date + '/Healpix/'\n",
    "# myname = date + '_Healpix_maps.pdf'\n",
    "# # Selection of good TES\n",
    "# PIX_ok = np.arange(1, 257)\n",
    "\n",
    "# === 2020 June\n",
    "# date = '2020-06-26'\n",
    "# data_dir = mydir + date + '/Healpix/'\n",
    "# myname = date + '_Healpix_maps.pdf'\n",
    "# # Selection of good TES\n",
    "# PIX_ok = np.arange(1, 123) # No files after TES 122\n",
    "\n",
    "\n",
    "# === 2020 July 29\n",
    "# date = '2020-07-29'\n",
    "# data_dir = mydir + date + '/Healpix/'\n",
    "# myname = date + '_Healpix_maps.pdf'\n",
    "# # Selection of good TES\n",
    "# PIX_ok = np.arange(1, 257) \n",
    "\n",
    "# === 2020 July\n",
    "# date = '2020-07-30'\n",
    "# data_dir = mydir + date + '/Healpix/'\n",
    "# myname = date + '_Healpix_maps.pdf'\n",
    "# # Selection of good TES\n",
    "# PIX_ok = [2, 5, 9, 13, 14, 15, 19, 22, 23, 24, 25, 27, 28, 31, 33, 34, 51, 52, 61, 62, 64, 66, 67, 69, 70, 71, 72]#, 73,\n",
    "#           74, 75, 76, 80, 81, 82, 83, 85, 86, 87, 88, 93, 94, 95, 96, 107, 133, 134, 158, 160, 162, 163, 167, 197, \n",
    "#           200, 201, 210, 216, 221, 255]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb98659",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get TES coordinate and index_q, ordered as on the instrument\n",
    "xONAFP, yONAFP, FP_index, index_q = scal.get_TES_Instru_coords(q, frame='ONAFP')\n",
    "print(index_q.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc5981fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_radius = 20 # [deg]\n",
    "ndet = len(PIX_ok)\n",
    "print('Number of detectors:', ndet)\n",
    "mydata = []\n",
    "index_q_ok = []\n",
    "for PIX in PIX_ok:\n",
    "    print('\\nPIX:', PIX)\n",
    "    # Convert to Qubic soft numerotation        \n",
    "    index_q_ok.append(index_q[PIX-1])\n",
    "    print('Index_q:', index_q_ok[-1])\n",
    "    \n",
    "    # Get the map\n",
    "    hdu = fits.open(data_dir + f'healpix_TESNum_{PIX}.fits')\n",
    "    print(hdu.info())\n",
    "    image = hdu[1].data\n",
    "    # For April 2019, maps have an extra dim\n",
    "    if image.ndim != 1:\n",
    "        image = image[0] \n",
    "\n",
    "    NSIDE_data = hp.get_nside(image)\n",
    "    print('Old NSIDE:', NSIDE_data)\n",
    "\n",
    "    # Downgrade resolution\n",
    "    image = hp.ud_grade(image, NSIDE)\n",
    "    print('New NSIDE:',hp.get_nside(image))\n",
    "\n",
    "    # Make a patch\n",
    "    vec = hp.ang2vec(0, 0, lonlat=True)\n",
    "    radius = np.deg2rad(patch_radius)\n",
    "    ipix_patch = hp.query_disc(NSIDE, vec, radius)\n",
    "    data_patch = image[ipix_patch]\n",
    "    npix_patch = np.shape(data_patch)[0]\n",
    "    print('#pix in the patch:', npix_patch)\n",
    "    mydata.append(data_patch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b521c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========== Save plots in a pdf file\n",
    "# with PdfPages(mydir + myname) as pp:\n",
    "#     for i, data_patch in enumerate(mydata):\n",
    "#         patch_mask = np.zeros(12 * NSIDE**2) + hp.UNSEEN\n",
    "#         patch_mask[ipix_patch] = data_patch\n",
    "        \n",
    "#         hp.gnomview(patch_mask, reso=10, title=f'PIX {PIX_ok[i]} - Index_q {index_q_ok[i]}', min=0)\n",
    "#         # hp.visufunc.projscatter(0., 0., color='r', marker='+', lonlat=True, s=100)\n",
    "#         hp.graticule()\n",
    "    \n",
    "#         pp.savefig()\n",
    "\n",
    "\n",
    "# ============= Plot just in the Notebook\n",
    "for i, data_patch in enumerate(mydata):\n",
    "    patch_mask = np.zeros(12 * NSIDE**2) + hp.UNSEEN\n",
    "    patch_mask[ipix_patch] = data_patch\n",
    "\n",
    "    hp.gnomview(patch_mask, reso=10, title=f'PIX {PIX_ok[i]} - Index_q {index_q_ok[i]}', min=0)\n",
    "    # hp.visufunc.projscatter(0., 0., color='r', marker='+', lonlat=True, s=100)\n",
    "    hp.graticule()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f1646ed",
   "metadata": {},
   "source": [
    "### Model: Simulated beam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef05ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(theta, index_q, d, s, radius=20, nu=150e9, PIrot=True, doplot=False):\n",
    "    fl, phi = theta\n",
    "    print('theta:', theta)\n",
    "    \n",
    "    nside = d['nside']\n",
    "    \n",
    "    # Change the focal length\n",
    "    d['filter_nu'] = nu\n",
    "    d['focal_length'] = fl\n",
    "    q = qubic.QubicInstrument(d)\n",
    "    print('Focal length = ', q.optics.focal_length)\n",
    "    \n",
    "    # Synthetic beams on the sky for the TES\n",
    "    sb = q.get_synthbeam(s, idet=index_q, external_A=None, hwp_position=0)\n",
    "    \n",
    "    # Rotate\n",
    "    if PIrot:\n",
    "        Rotator = hp.Rotator(rot=(0, 90, 180+phi), deg=True)\n",
    "    else:\n",
    "        Rotator = hp.Rotator(rot=(0, 90, phi), deg=True)\n",
    "    sb_rot = Rotator.rotate_map_alms(sb)\n",
    "    \n",
    "    # Make a patch\n",
    "    vec = hp.ang2vec(0, 0, lonlat=True)\n",
    "    radius = np.deg2rad(radius)\n",
    "    ipix_patch = hp.query_disc(nside, vec, radius)\n",
    "\n",
    "    sb_rot_patch = np.zeros(12 * nside**2) + hp.UNSEEN\n",
    "    sb_rot_patch[ipix_patch] = sb_rot[ipix_patch]\n",
    "    \n",
    "    if doplot:\n",
    "#         hp.mollview(sb)\n",
    "#         hp.mollview(sb_rot)\n",
    "        hp.gnomview(sb_rot_patch, reso=15, title=f'Index_q {index_q}')\n",
    "        hp.graticule()\n",
    "        hp.visufunc.projscatter(0., 0., color='r', marker='+', lonlat=True, s=100)\n",
    "    \n",
    "    return sb_rot_patch[ipix_patch]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a8501d4",
   "metadata": {},
   "source": [
    "### Make fake data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce0e34f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_fake = (0.3, 0)\n",
    "\n",
    "mydata_fake = []\n",
    "gains_fake = np.zeros(ndet)\n",
    "for i, idet in enumerate(index_q_ok):\n",
    "    M = model(theta_fake, idet, d, s, nu=freq * 1e9, PIrot=True, doplot=False)\n",
    "    gains_fake[i] = 1.#np.random.rand(1) * 5\n",
    "    noise = np.random.normal(0., 10., M.shape) * 0.\n",
    "    mydata_fake.append((gains_fake[i] * M) + noise)\n",
    "\n",
    "print(gains_fake)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b7ad99",
   "metadata": {},
   "source": [
    "### Compare real and fake data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ba6482",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Save a pdf\n",
    "# myname = date + '_Healpix_maps_simu_data.pdf'\n",
    "# with PdfPages(mydir + myname) as pp:\n",
    "#     for idx in range(ndet):\n",
    "#         real = np.zeros(12 * NSIDE**2) + hp.UNSEEN\n",
    "#         real[ipix_patch] = mydata[idx]\n",
    "\n",
    "#         fake = np.zeros(12 * NSIDE**2) + hp.UNSEEN\n",
    "#         fake[ipix_patch] = mydata_fake[idx]\n",
    "\n",
    "#         plt.figure(figsize=(12, 8))\n",
    "#         plt.suptitle(f'PIX {PIX_ok[idx]} - Index_q {index_q_ok[idx]}')\n",
    "#         hp.gnomview(real, sub=(121), reso=15, title='Real', min=0., max=None)#norm=SymLogNorm(1e3))\n",
    "#         hp.gnomview(fake, sub=(122), reso=15, title='Fake', min=0., max=None)#norm=SymLogNorm(1e4))\n",
    "#         hp.graticule()\n",
    "#         hp.visufunc.projscatter(0., 0., color='r', marker='+', lonlat=True, s=100)\n",
    "        \n",
    "#         pp.savefig()\n",
    "        \n",
    "### Plot in the notebook\n",
    "for idx in range(ndet):\n",
    "    TES = PIX_ok[idx] % 128\n",
    "    ASIC = PIX_ok[idx] // 128 + 1\n",
    "    real = np.zeros(12 * NSIDE**2) + hp.UNSEEN\n",
    "    real[ipix_patch] = mydata[idx]\n",
    "\n",
    "    fake = np.zeros(12 * NSIDE**2) + hp.UNSEEN\n",
    "    fake[ipix_patch] = mydata_fake[idx]\n",
    "\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.suptitle(f'TES {TES} - ASIC {ASIC} - {freq} GHz')# - Index_q {index_q_ok[idx]}')\n",
    "    hp.gnomview(real, sub=(121), reso=13, title='Measurement', min=0., max=5e4)#norm=SymLogNorm(1e3))\n",
    "    hp.gnomview(fake, sub=(122), reso=13, title='Simulation', min=0., max=1e6)#norm=SymLogNorm(1e4))\n",
    "#     hp.graticule()\n",
    "#     hp.visufunc.projscatter(0., 0., color='r', marker='+', lonlat=True, s=100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e3e808b",
   "metadata": {},
   "source": [
    "### Covariance matrix of the noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f8192e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Covariance matrix (npix x npix)\n",
    "invcov = np.zeros((ndet, npix_patch, npix_patch))\n",
    "for i in range(ndet):\n",
    "#     cov = 100 * np.identity(npix_patch)\n",
    "    \n",
    "    diago = np.abs(mydata_fake[i])\n",
    "    cov = np.diag(diago)\n",
    "\n",
    "#     diago = np.abs(mydata[i])\n",
    "#     cov = np.diag(diago)\n",
    "#     # Remove 0 value\n",
    "#     zero_pix = 0\n",
    "#     for j in range(npix_patch):\n",
    "#         if cov[j, j] == 0.:\n",
    "#             cov[j, j] = np.mean(diago) / 1e4\n",
    "#             zero_pix += 1\n",
    "#     print(zero_pix)\n",
    "\n",
    "    # Inverse covariance: Cholesky method\n",
    "    L = np.linalg.inv(np.linalg.cholesky(cov))\n",
    "    invcov[i, :, :] = L.T @ L\n",
    "    \n",
    "# plt.figure()\n",
    "# plt.imshow(invcov)\n",
    "# plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "058f35b2",
   "metadata": {},
   "source": [
    "### Define the Chi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81704a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chi2\n",
    "def get_chi2(theta, data, invcov, d, s, radius=20, verbose=False):\n",
    "    ndet = len(data)\n",
    "    chi2 = 0.\n",
    "    for idet in range(ndet):\n",
    "        M = model(theta, idet, d, s, radius=radius, doplot=False)\n",
    "        \n",
    "        # Amplitude factor (linear so we can compute it analitically)\n",
    "        sigma_A = 1. / (M.T @ invcov[idet] @ M)\n",
    "        A = sigma_A * M.T @ invcov[idet] @ data[idet]\n",
    "        \n",
    "        R = A * M - data[idet]\n",
    "        chi2 += R.T @ invcov[idet] @ R\n",
    "        \n",
    "        if verbose:\n",
    "            print(f'Det {idet+1}/{ndet}')\n",
    "            print('M =', M)\n",
    "            print('A =', A)\n",
    "            print('R =', R)\n",
    "            \n",
    "    print('Chi2 =', chi2)\n",
    "    return chi2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfdfd0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore the chi2\n",
    "nval = 10\n",
    "phi_min, phi_max = 0., 10.\n",
    "fl_min, fl_max = 0.25, 0.35\n",
    "chi2_grid = np.zeros((nval, nval))\n",
    "all_phi = np.linspace(phi_min, phi_max, nval)\n",
    "all_fl = np.linspace(fl_min, fl_max, nval)\n",
    "for f, fl in enumerate(all_fl):\n",
    "    for p, phi in enumerate(all_phi):\n",
    "        theta = (fl, phi)\n",
    "        chi2_grid[f, p] = get_chi2(theta, mydata, invcov, d, s)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38001574",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "plt.imshow(chi2_grid)\n",
    "plt.colorbar()\n",
    "plt.xlabel('phi')\n",
    "plt.ylabel('Focal length')\n",
    "plt.xticks(np.arange(nval), np.round(all_phi, 1), fontsize=10)\n",
    "plt.yticks(np.arange(nval), np.round(all_fl, 2), fontsize=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d0cb31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the min on the grid => guess values for the MCMC or the minimizer\n",
    "print(np.min(chi2_grid))\n",
    "min_indices = np.unravel_index(np.argmin(chi2_grid), (nval, nval))\n",
    "print(min_indices)\n",
    "\n",
    "fl_guess = all_fl[min_indices[0]]\n",
    "phi_guess = all_phi[min_indices[1]]\n",
    "theta_guess = np.array((fl_guess, phi_guess))\n",
    "\n",
    "print('Guess:', fl_guess, phi_guess)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baea8f08",
   "metadata": {},
   "source": [
    "### Minimize the Chi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b59a61f",
   "metadata": {},
   "outputs": [],
   "source": [
    "bds = ((0, 10), (None, None))\n",
    "result = op.minimize(get_chi2, \n",
    "                     x0=[fl_guess, phi_guess], \n",
    "                     args=(mydata, invcov, d, s), \n",
    "                     bounds=None,\n",
    "                     method='Nelder-Mead')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6060338",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Data fake:', theta_fake)\n",
    "print('\\nMinimization result:\\n', result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27600c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "invcov.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc7edc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute analitically gains for each TES\n",
    "def get_gains(theta, data, invcov, d, s, radius=18, verbose=False):\n",
    "    ndet = len(data)\n",
    "    gains = np.zeros(ndet)\n",
    "    for idet in range(ndet):\n",
    "        M = model(theta, idet, d, s, radius=radius, doplot=False)\n",
    "\n",
    "        # Amplitude factor (linear so we can compute it analitically)\n",
    "        sigma_A = 1. / (M.T @ invcov[idet] @ M)\n",
    "        gains[idet] = sigma_A * M.T @ invcov[idet] @ data[idet]\n",
    "        \n",
    "        if verbose:\n",
    "            print(f'Det {idet+1}/{ndet}')\n",
    "            print('M =', M)\n",
    "            print('A =', gains[idet])\n",
    "            \n",
    "    return gains\n",
    "\n",
    "gains = get_gains(result['x'], mydata, invcov, d, s)\n",
    "print('Gains:', gains)\n",
    "print('Gains fake:', gains_fake)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7031ac16",
   "metadata": {},
   "source": [
    "### MCMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80025f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lnlike(theta, data, invcov, d, s, radius=20, verbose=False):\n",
    "    LnLike = -0.5 * get_chi2(theta, data, invcov, d, s, radius=radius, verbose=verbose)\n",
    "    return LnLike"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e094d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lnprior(theta):\n",
    "    fl, phi = theta\n",
    "    if fl > 0 and phi > 0:\n",
    "        return 0.0\n",
    "    else:\n",
    "        return -np.inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ba5a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log of the posterior (Posterior = prior x likelihood)\n",
    "def lnprob(theta, data, invcov, d, s, radius=20, verbose=False):\n",
    "    lp = lnprior(theta)\n",
    "    if not np.isfinite(lp):\n",
    "        return -np.inf\n",
    "    return lp + lnlike(theta, data, invcov, d, s, radius=radius, verbose=verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34d4133",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(p0, nwalkers, niter, ndim, lnprob, args):\n",
    "    sampler = emcee.EnsembleSampler(nwalkers, ndim, lnprob, args=args)\n",
    "\n",
    "    print(\"\\n =========== Running burn-in... ===============\")\n",
    "    p0, _, _ = sampler.run_mcmc(p0, 10, progress=True)\n",
    "    sampler.reset()\n",
    "\n",
    "    print(\"\\n =========== Running production... ===========\")\n",
    "    pos, prob, state = sampler.run_mcmc(p0, niter, progress=True)\n",
    "\n",
    "    return sampler, pos, prob, state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf0c861d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ndim = 2\n",
    "nwalkers = 8\n",
    "\n",
    "# Initial guess\n",
    "p0 = [theta_guess + 1e-4 * np.random.rand(ndim) for i in range(nwalkers)]\n",
    "\n",
    "niter = 200\n",
    "args = (mydata, invcov, d, s)\n",
    "sampler, pos, prob, state = run(p0, nwalkers, niter, ndim, lnprob, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acea56f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_samples = sampler.get_chain(discard=100, thin=15, flat=True)\n",
    "print(flat_samples.shape)\n",
    "\n",
    "plt.subplots(1, 2, figsize=(14, 6))\n",
    "plt.subplot(121)\n",
    "plt.hist(flat_samples[:, 0], 100, color=\"k\", histtype=\"step\")\n",
    "plt.xlabel(r\"$\\theta_1$\")\n",
    "plt.ylabel(r\"$p(\\theta_1)$\")\n",
    "# plt.gca().set_yticks([]);\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.hist(flat_samples[:, 1], 100, color=\"k\", histtype=\"step\")\n",
    "plt.xlabel(r\"$\\theta_2$\")\n",
    "plt.ylabel(r\"$p(\\theta_2)$\")\n",
    "# plt.gca().set_yticks([]);\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b08247d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Mean acceptance fraction: {0:.3f}\".format(np.mean(sampler.acceptance_fraction)))\n",
    "\n",
    "print(\"Mean autocorrelation time: {0:.3f} steps\".format(\n",
    "        np.mean(sampler.get_autocorr_time())))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6379513",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['FL', 'phi']\n",
    "rc('font', size=12)\n",
    "rc('figure', figsize=(20, 20))\n",
    "fig = corner.corner(\n",
    "    flat_samples, labels=labels, truths=theta_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5210107e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(ndim):\n",
    "    mcmc = np.percentile(flat_samples[:, i], [16, 50, 84])\n",
    "    q = np.diff(mcmc)\n",
    "    txt = \"\\mathrm{{{3}}} = {0:.5f}_{{-{1:.5f}}}^{{{2:.5f}}}\"\n",
    "    txt = txt.format(mcmc[1], q[0], q[1], labels[i])\n",
    "    display(Math(txt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85683fda",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
