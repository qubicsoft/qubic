{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa4553a3",
   "metadata": {},
   "source": [
    "# Generate Fringes from datasets\n",
    "\n",
    "In this notebook we produce the fringes files from the raw QUBIC datasets.\n",
    "\n",
    "They are saved into numpy files of the type: fringes_bs_17_21_2020-10-27_11.34.04.npy\n",
    "\n",
    "## Status of the code:\n",
    "There is clear room for improvement:\n",
    "- intercalibration are not good. This is addressed in the notebook called Analyse-Fringes-Oct-2020.Rmd\n",
    "- for the fringe construction: apparently the fringe patterns seems to disappear gradually with the number of cycles (see for example with fringe [49,53] and [17,21] in the last part of code (label: Try to improve method). This is not understood yet and is a big issue as for now it seems that integrating longer does not improve statistics. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7e6e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "#%matplotlib notebook\n",
    "\n",
    "from pylab import *\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import pickle\n",
    "from importlib import reload\n",
    "\n",
    "\n",
    "# Specific science modules\n",
    "import healpy as hp\n",
    "import scipy\n",
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.optimize as sop\n",
    "import pandas as pd\n",
    "import scipy.signal\n",
    "\n",
    "\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import qubic\n",
    "from qubic import selfcal_lib as sc\n",
    "from qubicpack.utilities import Qubic_DataDir\n",
    "from qubicpack import qubicpack as qp\n",
    "from qubicpack.qubicfp import qubicfp\n",
    "import qubic.fibtools as ft\n",
    "import qubic.demodulation_lib as dl\n",
    "from qubic import fringes_lib as fl\n",
    "\n",
    "rc('figure', figsize=(16,7))\n",
    "rc('font', size=12)\n",
    "\n",
    "\n",
    "\n",
    "# Get a dictionary\n",
    "basedir = Qubic_DataDir(datafile='instrument.py', )\n",
    "print('basedir : ', basedir)\n",
    "dictfilename = basedir + '/dicts/global_source_oneDet.dict'\n",
    "d = qubic.qubicdict.qubicDict()\n",
    "d.read_from_file(dictfilename)\n",
    "q = qubic.QubicInstrument(d)\n",
    "\n",
    "reload(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88ef36f9",
   "metadata": {},
   "source": [
    "# looping over TES and Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c244a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============== Get data ==============\n",
    "\n",
    "#### 27/10/2020\n",
    "#### Vtes = 5\n",
    "global_dir = '/Volumes/LaCie/QubicData/Calib-TD/Fringes/2020-10-27/'\n",
    "vtes = 5\n",
    "eco = 1\n",
    "out_dir = '/Users/hamilton/Qubic/Calib-TD/Fringes/Fringes_2020-10-27_Vtes_5_Eco_1'\n",
    "datasets = np.sort(glob.glob(global_dir+'/*RF_switch*'))\n",
    "equiv = [0,0,1,1,2,2,3,3,3,3,3,3,3,3]    \n",
    "\n",
    "#### 28/10/2020\n",
    "# global_dir = '/Volumes/LaCie/QubicData/Calib-TD/Fringes/2020-10-28/'\n",
    "# ### Vtes=4\n",
    "# datasets = np.sort(glob.glob(global_dir+'/*RF_switch_Vtes_4_*'))\n",
    "# vtes = 4\n",
    "# eco = 1\n",
    "# equiv = [0,0,1,1,2,2,3,3]    \n",
    "# out_dir = '/Users/hamilton/Qubic/Calib-TD/Fringes/Fringes_2020-10-28_Vtes_4_Eco_1'\n",
    "# ### Vtes=3.5\n",
    "# datasets = np.sort(glob.glob(global_dir+'/*RF_switch_Vtes_3.5_*'))\n",
    "# vtes = 3.5\n",
    "# eco = 1\n",
    "# equiv = [0,0,1,1,2,2,3,3]    \n",
    "# out_dir = '/Users/hamilton/Qubic/Calib-TD/Fringes/Fringes_2020-10-28_Vtes_3.5_Eco_1'\n",
    "### Vtes=4 & No Eccosorb\n",
    "# datasets = np.sort(glob.glob(global_dir+'/*RF_switch_NoEco_Vtes_4_*'))\n",
    "# vtes = 4\n",
    "# eco = 0\n",
    "# equiv = [0,0,1,1,2,2,3,3]    \n",
    "# out_dir = '/Users/hamilton/Qubic/Calib-TD/Fringes/Fringes_2020-10-28_Vtes_4_Eco_0'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b12ac2d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "horns = []\n",
    "ncycles = []\n",
    "wt = []\n",
    "for ds in datasets:\n",
    "    strs = ds.split('_')\n",
    "    ncycles.append(float(strs[strs.index('ncycles')+1]))\n",
    "    wt.append(float(strs[strs.index('wt')+1]))\n",
    "    horns.append([int(strs[-2]), int(strs[-1])])\n",
    "\n",
    "print('Ncycles')\n",
    "print(ncycles)\n",
    "print('WT')\n",
    "print(wt)\n",
    "print('Horns')\n",
    "print(horns)\n",
    "\n",
    "#### Equivalency class\n",
    "bseqindex, equiv = sc.find_equivalent_baselines(horns, q)\n",
    "all_equiv = np.unique(equiv)\n",
    "\n",
    "print('equivalency of baselines')\n",
    "print(equiv)\n",
    "print()\n",
    "print()\n",
    "print()\n",
    "print('Found {} equivalency classes:'.format(len(all_equiv)))\n",
    "reload(sc)\n",
    "figure()\n",
    "for i in range(len(all_equiv)):\n",
    "    dsequiv = where(np.array(equiv)==all_equiv[i])[0]\n",
    "    subplot(1,4,i+1, aspect='equal')\n",
    "    sc.plot_horns(q, simple=True)\n",
    "    title('Type = {}'.format(all_equiv[i]))\n",
    "    print(' - Type {}'.format(all_equiv[i]))\n",
    "    for j in range(len(dsequiv)):\n",
    "        print('     * dsnum={} [{},{}]'.format(dsequiv[j], horns[dsequiv[j]][0], horns[dsequiv[j]][1]))\n",
    "        sc.plot_baseline(q,[horns[dsequiv[j]][0], horns[dsequiv[j]][1]])\n",
    "    legend(fontsize=10)\n",
    "tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa6714d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =================== Make a mask ==============\n",
    "# Mask to remove the 8 thermometer pixels\n",
    "mask = np.ones((17,17))\n",
    "mask[0, 12:] = np.nan\n",
    "mask[1:5, 16] = np.nan\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d5d467",
   "metadata": {},
   "source": [
    "### Try to improve method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d6f8d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(fl)\n",
    "#### Read data for a given baseline\n",
    "ids = 0\n",
    "myds = [datasets[ids]]\n",
    "myhorns = horns[ids]\n",
    "stable_time = wt[ids]/1000\n",
    "print('Stable Time Th: {}'.format(stable_time))\n",
    "print(myds)\n",
    "print(myhorns)\n",
    "\n",
    "read_data = []\n",
    "#### Read data\n",
    "for asic in [1, 2]:\n",
    "    my_t_data, my_data, t_src, data_src = fl.get_data(myds[0], asic, doplot=False, src_data=True)\n",
    "    read_data.append([my_t_data, my_data])\n",
    "    tmin = my_t_data[0]\n",
    "    tmax = my_t_data[-1]\n",
    "    delta_t = tmax-tmin\n",
    "print(tmin, tmax, delta_t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e83634",
   "metadata": {},
   "outputs": [],
   "source": [
    "rc('font', size=12)\n",
    "TESnum = 95\n",
    "mydata = read_data[0]\n",
    "subplot(2,1,1)\n",
    "plot(mydata[0],  mydata[1][TESnum-1,:])\n",
    "title('TES #{}'.format(TESnum))\n",
    "subplot(2,1,2)\n",
    "title('Cal Source')\n",
    "### Remove a linear trand to source data\n",
    "linfct = np.poly1d(np.polyfit(t_src, data_src,1))\n",
    "data_src = data_src - linfct(t_src)\n",
    "plot(t_src, data_src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e1bf8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the best period for a given TES\n",
    "ppp, rms, per = fl.find_right_period(6 * stable_time, mydata[0], mydata[1][TESnum-1,:], delta=0.5, nb=20)\n",
    "subplot(1,2,1)\n",
    "plot(ppp,rms,'o-')\n",
    "xlabel('Test Period')\n",
    "ylabel('Folded data RMS')\n",
    "axvline(x=per, label='Best period: {0:6.3f}s'.format(per))\n",
    "legend()\n",
    "print(per)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a14882",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(mydata[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "585bd112",
   "metadata": {},
   "outputs": [],
   "source": [
    "rc('font', size=15)\n",
    "nsp_per = 240\n",
    "used_period = per.copy()\n",
    "nper = np.floor((delta_t/used_period)).astype(int)\n",
    "\n",
    "THEPIX = TESnum-1\n",
    "print(THEPIX)\n",
    "rebin = None\n",
    "verbose = None\n",
    "time = mydata[0]\n",
    "dd = mydata[1]\n",
    "tstart = 0\n",
    "period = 30.07831325301205\n",
    "\n",
    "# plot(time, dd[TESnum-1,:],label='Raw')\n",
    "# print('Data: {}, {}'.format(np.shape(time), np.shape(dd)))\n",
    "# print()\n",
    "\n",
    "### start_time and end_time\n",
    "tmin = time[0]\n",
    "tmax = time[-1]\n",
    "print('input data: tmin={}, tmax={}'.format(tmin,tmax))\n",
    "print('Period is: {}'.format(period))\n",
    "print('Tstart is: {}'.format(tstart))\n",
    "nper = np.floor((tmax-tstart)/period).astype(int)\n",
    "print('We have {} periods between tstart and tmax'.format(nper))\n",
    "tend = tstart + nper*period\n",
    "print('Tend is {}'.format(tend))\n",
    "okdata = (time >= tstart) & (time <= tend)\n",
    "data = dd[THEPIX, okdata]\n",
    "time = time[okdata]\n",
    "print('Time after cut: from {} to {}'.format(time[0], time[-1]))\n",
    "print('Shapes after cut: {} {}'.format(np.shape(time), np.shape(data)))\n",
    "print()\n",
    "\n",
    "oksrc = (t_src >= tstart) & (t_src <= tend)\n",
    "time_src = t_src[oksrc]\n",
    "dsrc = data_src[oksrc]\n",
    "\n",
    "# Filter the the data\n",
    "lowcut = 6e-6\n",
    "highcut = 5.\n",
    "nharm = 30\n",
    "notch = np.array([[1.724, 0.005, nharm]])\n",
    "\n",
    "newdata = ft.filter_data(time, data, lowcut, highcut, notch=notch, rebin=rebin, verbose=verbose)\n",
    "\n",
    "dsrc = ft.filter_data(t_src, dsrc, lowcut, highcut, notch=notch, rebin=rebin, verbose=verbose)\n",
    "\n",
    "print('Shape for time and filtered data: {} , {}'.format(np.shape(time), np.shape(newdata)))\n",
    "print()\n",
    "\n",
    "newd = scipy.signal.resample(newdata, nper*nsp_per)\n",
    "newsrc = scipy.signal.resample(dsrc, nper*nsp_per)\n",
    "newt = np.linspace(tstart, tend, nper*nsp_per)\n",
    "print('Resampled time goes from {} to {}'.format(newt[0], newt[-1]))\n",
    "print('Shape for Resampled time and filtered data: {} , {}'.format(np.shape(newt), np.shape(newd)))\n",
    "\n",
    "#subplot(1,2,1)\n",
    "plot(newt,dl.renorm(newd), label='Resampled (normalized) TES#{}'.format(TESnum))\n",
    "plot(newt, -dl.renorm(newsrc)/10-0.7, label='CalSrc (normalized) sign inverted')\n",
    "xlabel('Time')\n",
    "ylabel('Signal')\n",
    "ylim(-2,2)\n",
    "legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19639dc5",
   "metadata": {},
   "source": [
    "# New reconstruction on all TES\n",
    "But the t0 and period are determined on a reference TES (we'll have to figure out an automated technique to choose the TES on which these are determined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfabdf2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_t0(tfold, dfold, period, nconfigs = 6, doplot=False):\n",
    "    ### This finds time where configuration change in the square modulation\n",
    "    \n",
    "    # Average the signal over all periods\n",
    "    msignal = np.mean(dfold, axis=0)\n",
    "    # calculate the derivative and find where it is high\n",
    "    dsignal = np.abs(np.gradient(msignal))\n",
    "    md, sd = ft.meancut(dsignal, 3)\n",
    "    thr = np.abs(dsignal-md) > (3*sd)\n",
    "    \n",
    "    # Let's find clusters of high derivatives: \n",
    "    # each time we take the first high derivative element\n",
    "    t_change = tfold[thr]\n",
    "    expected_stable_time = period/nconfigs\n",
    "    start_times = []\n",
    "    incluster = 0\n",
    "    for i in range(len(t_change)):\n",
    "        if incluster==0:\n",
    "            start_times.append(t_change[i])\n",
    "            incluster=1\n",
    "        if i > 0:\n",
    "            if (t_change[i]-t_change[i-1]) > (expected_stable_time * 0.6):\n",
    "                incluster = 0\n",
    "    start_times = np.array(start_times)\n",
    "    \n",
    "    # Now we take the median of all start_times modulo period/nconfigs\n",
    "    t0 = np.median(start_times % (period/nconfigs))\n",
    "\n",
    "    if doplot:\n",
    "        subplot(1,2,2)\n",
    "        plot(tfold, msignal, label='Mean over periods')\n",
    "        plot(tfold, dsignal, label='Derivative')\n",
    "        plot(tfold[thr], dsignal[thr], 'ro', label='High Derivative (>3sig)')\n",
    "        for i in range(len(start_times)):\n",
    "            if i==0:\n",
    "                lab = 'Found Start times'\n",
    "            else:\n",
    "                lab = None\n",
    "            axvline(x=start_times[i], ls='--', label=lab, alpha=0.5)\n",
    "        for i in range(6):\n",
    "            if i ==0:\n",
    "                lab = 'Median Start Time (modulo period/6)'\n",
    "            else:\n",
    "                lab = None\n",
    "            axvline(x=t0+i*period/nconfigs, color='r', ls='--', label=lab)\n",
    "        legend(framealpha=0.2)\n",
    "        title('t0 determination on Reference TES')\n",
    "        xlabel('Time in Period')\n",
    "        ylabel('Signal averaged over periods')\n",
    "        tight_layout()\n",
    "\n",
    "    \n",
    "    return t0\n",
    "\n",
    "#### Now we have various ways of calculating the average in each bin over periods\n",
    "# 1/ We can use the whole flat section or cut a bit at the beginning and at the end\n",
    "# 2/ Simple average\n",
    "# 3/ more fancy stuff: removing a slope determined by asking the three measurements of \"all horns\" to be equal\n",
    "def average_bins_periods(tfold, dfold, period, skip_rise=0., skip_fall=0.,\n",
    "                        median=True, remove_slope=False, return_residuals=False, \n",
    "                         all_h = [True, False, False, True, False, True], speak=False,\n",
    "                        doplot=False):\n",
    "    # We assume that the array has been np.rolled so that the t0 is in time sample 0    \n",
    "    sh = np.shape(dfold)\n",
    "    nper = sh[0]\n",
    "    nsp_per = sh[1]\n",
    "    nconfigs=len(all_h)\n",
    "    \n",
    "    status = np.zeros(nconfigs)\n",
    "    \n",
    "    # First we remove the average of each period\n",
    "    #dfold = (dfold.T-np.mean(dfold,axis=1)).T\n",
    "    \n",
    "    # then we perform first an average / median in each of the stable sections of each\n",
    "    # period (possibly skipping beginning and end)\n",
    "    vals_per = np.zeros((nper, nconfigs))\n",
    "    errs_per = np.zeros((nper, nconfigs))\n",
    "    stable_time = period/nconfigs\n",
    "    for i in range(nconfigs):\n",
    "        tstart = i*stable_time + skip_rise*stable_time\n",
    "        tend = (i+1)*stable_time - skip_fall*stable_time\n",
    "        ok = (tfold >= tstart) & (tfold < tend)\n",
    "        for j in range(nper):\n",
    "            if median:\n",
    "                vals_per[j,i] = np.median(dfold[j,ok])                \n",
    "            else:\n",
    "                vals_per[j,i], _ = ft.meancut(dfold[j,ok],3) \n",
    "            errs_per[j,i] = np.std(dfold[j,ok]) \n",
    "    ttt = np.arange(nconfigs)*stable_time+stable_time/2\n",
    "            \n",
    "    if doplot:\n",
    "        #figure()\n",
    "        #subplot(1,2,1)\n",
    "        for i in range(nper):\n",
    "            if i==0:\n",
    "                lab = 'Raw'\n",
    "            else:\n",
    "                lab=None\n",
    "            errorbar(ttt, vals_per[i,:], yerr=errs_per[i,:], \n",
    "                     xerr=stable_time/2, fmt='o', label=lab)\n",
    "        title('Configuration bins before levelling per period')\n",
    "        xlabel('Time in period')\n",
    "        ylabel('Value for each period')\n",
    "        legend()\n",
    "        tight_layout()\n",
    "        \n",
    "    if remove_slope:\n",
    "        ### We fit a slope between the \"all horns open\" configurations and remove it\n",
    "        xx = np.arange(6)\n",
    "        for i in range(nper):\n",
    "            pars, cc = np.polyfit(np.arange(6)[all_h], vals_per[i,all_h], 1, w=1./errs_per[i,all_h]**2, cov=True)\n",
    "            errfit = np.sqrt(np.diag(cc))\n",
    "            vals_per[i,:] = vals_per[i,:] - (pars[0]*xx+pars[1])  \n",
    "    else:\n",
    "        ### We just remove the average off \"all horns open configurations\"\n",
    "        for i in range(nper):\n",
    "            vals_per[i,:] -= np.mean(vals_per[i,all_h])\n",
    "        \n",
    "\n",
    "    # And finally we average/median all periods\n",
    "    vals = np.zeros(6)\n",
    "    errs = np.zeros(6)\n",
    "    for i in range(nconfigs):\n",
    "        if median:\n",
    "            vals[i] = np.median(vals_per[:,i])\n",
    "        else:\n",
    "            vals[i] = np.mean(vals_per[:,i])\n",
    "        errs[i] = np.std(vals_per[:,i])\n",
    "        ### Try to detect cases where switches did not work properly\n",
    "        if errs[i] > (4*np.mean(errs_per[:,i])):\n",
    "            status[i] += 1\n",
    "    if doplot:   \n",
    "        errorbar(ttt, vals, yerr=errs, xerr=stable_time/2, color='r', \n",
    "                 label='Final Points', fmt='rx')\n",
    "        legend()\n",
    "    \n",
    "    if speak:\n",
    "        for i in range(nconfigs):\n",
    "            print('############')\n",
    "            print('config {}'.format(i))\n",
    "            for j in range(nper):\n",
    "                print('per {}: {} +/- {}'.format(j, vals_per[j,i], errs_per[j,i]))\n",
    "            print('============')\n",
    "            print('Value {} +/- {}'.format(vals[i], errs[i]))\n",
    "            print('============')\n",
    "    \n",
    "    ### Residuals in time domain (not too relevant as some baseloines were removed\n",
    "    ### as a result, large fluctuations in time-domain are usually well removed)\n",
    "    newdfold = np.zeros_like(dfold)\n",
    "    for i in range(6):\n",
    "        newdfold[:,i*nsp_per//6:(i+1)*nsp_per//6] = vals[i]\n",
    "    residuals = dfold-newdfold\n",
    "    \n",
    "    ### We would rather calculate the relevant residuals in the binned domain\n",
    "    ### between the final values and those after levelling\n",
    "    final_residuals = np.ravel(vals_per-vals)\n",
    "    mm, ss = ft.meancut(final_residuals,3)\n",
    "    if doplot:\n",
    "        figure()\n",
    "        plot(np.ravel(dfold), label='Input signal')\n",
    "        plot(np.ravel(newdfold), label='Reconstructed')\n",
    "        plot(np.ravel(residuals), label='Residuals')\n",
    "        xlabel('time samples')\n",
    "        ylabel('Time domain signal')\n",
    "        title('Time domain \\n[large drift is actually remvoed]')\n",
    "        legend()\n",
    "        tight_layout()\n",
    "\n",
    "        figure()\n",
    "        plot(np.ravel(vals_per), ls='steps', label='Per Period')\n",
    "        plot(np.ravel(vals_per-vals_per+vals), ls='steps', label='Values')\n",
    "        plot(final_residuals, ls='steps', label='Residuals')\n",
    "        xlabel('Time')\n",
    "        ylabel('Values')\n",
    "        title('Final Residuals')\n",
    "        legend()\n",
    "        tight_layout()\n",
    "        \n",
    "    if doplot:\n",
    "        figure()\n",
    "        ttt = np.arange(nconfigs)*stable_time+stable_time/2\n",
    "        for i in range(nper):\n",
    "            if i==0:\n",
    "                lab = 'remove_slope={}'.format(remove_slope)\n",
    "            else:\n",
    "                lab=None\n",
    "            errorbar(ttt, vals_per[i,:], yerr=errs_per[i,:], \n",
    "                     xerr=stable_time/2, fmt='x', alpha=0.3, color='orange', label=lab)\n",
    "        title('Final Configurations (after levelling)')\n",
    "        xlabel('Time in period')\n",
    "        ylabel('Value')\n",
    "        legend()\n",
    "        tight_layout()\n",
    "\n",
    "    if return_residuals:\n",
    "        return vals, errs, final_residuals, ss, status\n",
    "    else:\n",
    "        return vals, errs, status\n",
    "\n",
    "def get_baselines_configurations(datain, \n",
    "                                 lowcut=1e-5, highcut = 5., notch=np.array([[1.724, 0.005, 30]]),\n",
    "                                 refTESnum=95, expected_period=30, all_h = [True, False, False, True, False, True],\n",
    "                                 nsp_per = 240, skip_rise=0.2, skip_fall=0.1, remove_slope=True,\n",
    "                                 force_period=None, force_t0=None,\n",
    "                                 verbose=True, doplot=True):\n",
    "    \n",
    "    sh = np.shape(datain[1])\n",
    "    ndet = sh[0]\n",
    "    nconfigs=len(all_h)\n",
    "    ########## First Step: Data Filtering ######################################\n",
    "    time = datain[0]\n",
    "    data = np.zeros_like(datain[1])\n",
    "    for i in range(ndet):\n",
    "        data[i,:] = ft.filter_data(time, datain[1][i,:], lowcut, highcut, notch=notch, rebin=True)\n",
    "    ############################################################################\n",
    "\n",
    "    ########## Determine the correct period on the reference TES ################\n",
    "    if force_period is None:\n",
    "        ppp, rms, period = fl.find_right_period(expected_period, time, data[refTESnum-1,:], delta=0.5, nb=100)\n",
    "        if verbose:\n",
    "            print('Found period {0:5.3f}s on TES#{1:}'.format(period, refTESnum))\n",
    "    else:\n",
    "        period=force_period\n",
    "        if verbose:\n",
    "            print('Using Forced period {0:5.3f}s'.format(period))\n",
    "\n",
    "    #############################################################################\n",
    "    \n",
    "    ########## Crop the data in order to have an integer number of periods #####\n",
    "    tmin = time[0]\n",
    "    tmax = time[-1]\n",
    "    nper = np.floor((tmax-tmin)/period).astype(int)\n",
    "    tend = tmin + nper*period\n",
    "    okdata = (time >= tmin) & (time <= tend)\n",
    "    time = time[okdata]\n",
    "    data = data[:, okdata]\n",
    "    #############################################################################\n",
    "    \n",
    "    ########## Resample the signal ##############################################\n",
    "    newdata = np.zeros((ndet, nper * nsp_per))\n",
    "    newt = np.linspace(tstart, tend, nper * nsp_per)\n",
    "    for i in range(ndet):\n",
    "        newdata[i,:] = scipy.signal.resample(data[i,:], nper*nsp_per)\n",
    "    if doplot:\n",
    "        figure()\n",
    "        subplot(1,2,1)\n",
    "        plot(newt, newdata[refTESnum-1,:])\n",
    "        xlabel('time')\n",
    "        ylabel('ADU')\n",
    "        title('TES #{}'.format(refTESnum))\n",
    "    #############################################################################\n",
    "    \n",
    "    ######### Now Fold the data #################################################\n",
    "    tdata = np.linspace(0, period, nsp_per)\n",
    "    newdata = np.reshape(newdata, (ndet, nper, nsp_per))\n",
    "    #############################################################################\n",
    "\n",
    "    ######### Now determine t0 on reference TES #################################\n",
    "    if force_t0 is None:\n",
    "        t0 = find_t0(tdata, newdata[refTESnum-1,:,:], period, doplot=doplot)\n",
    "        if verbose:\n",
    "            print('Found t0 {0:5.3f}s on TES#{1:}'.format(t0, refTESnum))\n",
    "    else:\n",
    "        t0 = force_t0\n",
    "        if verbose:\n",
    "            print('Using forced t0 {0:5.3f}s'.format(t0))\n",
    "    #############################################################################\n",
    "    \n",
    "    ######### Shift the folded data in order to have t0=0 ######################\n",
    "    newdata = np.roll(newdata, -int(t0/period*nsp_per), axis=2)\n",
    "    # Also roughly remove the average of the all_h configurations\n",
    "    ok_all_horns = np.zeros_like(tdata, dtype=bool)\n",
    "    for i in range(nconfigs):\n",
    "        if all_h[i]:\n",
    "            tmini = i*period/nconfigs + skip_rise*period/nconfigs\n",
    "            tmaxi = (i+1)*period/nconfigs - skip_fall*period/nconfigs\n",
    "            ok = (tdata >= tmini) & (tdata < tmaxi)\n",
    "            ok_all_horns[ok] = True\n",
    "    for i in range(ndet):\n",
    "        newdata[i,:,:] -= np.median(newdata[i,:,ok_all_horns])\n",
    "    #############################################################################\n",
    "    \n",
    "    ######### Do some plots #####################################################\n",
    "    if doplot:\n",
    "        figure()\n",
    "        subplot(1,2,1)\n",
    "        imshow(newdata[refTESnum-1,:,:], origin='lower', aspect='auto', extent=[0,np.max(tdata)+(tdata[1]-tdata[0])/2, 0, nper+0.5])\n",
    "        for i in range(6):\n",
    "            axvline(x=i*(period/6), color='k', lw=3)\n",
    "        title('Reference TES#{}'.format(refTESnum))\n",
    "        xlabel('Time in period')\n",
    "        ylabel('Period #')\n",
    "        subplot(1,2,2)\n",
    "        for i in range(nper):\n",
    "            plot(tdata, newdata[refTESnum-1, i,:], alpha=0.5)\n",
    "        for i in range(6):\n",
    "            axvline(x=i*(period/6), color='k', lw=3)\n",
    "            axvspan(i*(period/6), (i+skip_rise)*(period/6), alpha=0.1, color='red')\n",
    "            axvspan((i+(1.-skip_fall))*(period/6), (i+1)*(period/6), alpha=0.1, color='red')\n",
    "        title('Reference TES#{}'.format(refTESnum))\n",
    "    #############################################################################\n",
    "\n",
    "    ######### Calculate the baselines configurations in each TES\n",
    "    vals = np.zeros((ndet,nconfigs))\n",
    "    errs = np.zeros((ndet,nconfigs))\n",
    "    sigres = np.zeros(ndet)\n",
    "    status = np.zeros((ndet, nconfigs))\n",
    "    for i in range(ndet):\n",
    "        if i == (refTESnum-1):\n",
    "            speak = True\n",
    "            thedoplot = True * doplot\n",
    "        else:\n",
    "            speak = False\n",
    "            thedoplot=False\n",
    "        vals[i,:], errs[i,:], res, sigres[i], status[i,:] =  average_bins_periods(tdata, newdata[i,:,:], period, \n",
    "                                                                     all_h=all_h,\n",
    "                                                                     skip_rise=skip_rise, \n",
    "                                                                     skip_fall=skip_fall, \n",
    "                                                                     remove_slope=remove_slope, \n",
    "                                                                     return_residuals=True,\n",
    "                                                                     doplot=thedoplot)\n",
    "#         if speak:\n",
    "#             print(status[i,:])\n",
    "    if doplot:\n",
    "#         print('++++++++++++')\n",
    "#         print('Final :')\n",
    "#         for i in range(nconfigs):\n",
    "#             print('Config {}: {} +/- {}'.format(i, vals[refTESnum-1,i], errs[refTESnum-1,i]))\n",
    "        errorbar((np.arange(6)+0.5)*period/6, vals[refTESnum-1,:], yerr=errs[refTESnum-1,:], xerr=period/12,\n",
    "                 fmt='bo', label='Configuration values', barsabove=True, zorder=100, capsize=5, capthick=2)\n",
    "        legend()\n",
    "\n",
    "    return vals, errs, sigres, period, t0, status\n",
    "\n",
    "def weighted_sum(vals, errs, coeffs):\n",
    "    thesum = np.sum(coeffs * vals)\n",
    "    thesigma = np.sqrt(np.sum(coeffs**2 * errs**2))\n",
    "    return thesum, thesigma\n",
    "\n",
    "def get_baselines_configurations_asics(directory, asics=[1,2], \n",
    "                                 lowcut=1e-5, highcut = 5., notch=np.array([[1.724, 0.005, 30]]),\n",
    "                                 refTESnum=95, expected_period=30, all_h = [True, False, False, True, False, True],\n",
    "                                 nsp_per = 240, skip_rise=0.2, skip_fall=0.1, remove_slope=True,\n",
    "                                 force_period=None, force_t0=None,\n",
    "                                 verbose=True, doplot=True, myhorns=None):\n",
    "    ### Prepare data read\n",
    "    a = qubicfp()\n",
    "    a.verbosity = 0\n",
    "    a.read_qubicstudio_dataset(directory)\n",
    "    \n",
    "    dsdate = myds.split('/')[-1].split('_')[0]\n",
    "    dstime = myds.split('/')[-1].split('_')[1]\n",
    "    add_title=(dsdate + ' '+dstime)\n",
    "    \n",
    "    ### Loop on asics\n",
    "    for asic in asics:\n",
    "        if verbose:\n",
    "            print('Doing ASIC#{}'.format(asic))\n",
    "        # read data and put in a list [time, dataTES]\n",
    "        datain = [a.timeaxis(datatype='science',asic=asic), a.timeline_array(asic=asic)]\n",
    "        # start time at 0\n",
    "        datain[0] -= datain[0][0]\n",
    "        \n",
    "        if asic != 1:\n",
    "            force_period = period\n",
    "            force_t0 = t0\n",
    "            mydoplot = False\n",
    "        else:\n",
    "            mydoplot = doplot\n",
    "            \n",
    "        myvals, myerrs, mysigres, period, t0, mystatus = get_baselines_configurations(datain,\n",
    "                                                                      lowcut=lowcut, highcut=highcut,notch=notch,\n",
    "                                                                      refTESnum=refTESnum, \n",
    "                                                                      expected_period=expected_period, all_h = all_h, \n",
    "                                                                      nsp_per = nsp_per,\n",
    "                                                                      skip_rise=skip_rise, skip_fall=skip_fall, \n",
    "                                                                      remove_slope=remove_slope,\n",
    "                                                                      force_period=force_period, \n",
    "                                                                      force_t0=force_t0,\n",
    "                                                                      verbose=verbose, doplot=mydoplot)\n",
    "        if asic == 1:\n",
    "            vals = myvals\n",
    "            errs = myerrs\n",
    "            sigres = mysigres\n",
    "            status = mystatus\n",
    "        else:\n",
    "            vals = np.concatenate((vals, myvals))\n",
    "            errs = np.concatenate((errs, myerrs))\n",
    "            sigres = np.concatenate((sigres, mysigres))\n",
    "            status = np.concatenate((status, mystatus))\n",
    "\n",
    "    \n",
    "    coeffs = np.array([1./3, -1, 1, 1./3, -1, 1./3])\n",
    "    fringes = np.zeros(256)\n",
    "    err_fringes = np.zeros(256)\n",
    "    for i in range(256):\n",
    "        fringes[i], err_fringes[i] = weighted_sum(vals[i,:], errs[i,:], coeffs)\n",
    "\n",
    "    ### Cut on residuals\n",
    "    mm, ss = ft.meancut(np.log10(sigres),3)\n",
    "    oktes = np.ones(256)\n",
    "    oktes[np.abs(np.log10(sigres)-mm) > 2*ss] = np.nan\n",
    "\n",
    "        \n",
    "    if doplot:\n",
    "        errorbar(period/2, fringes[refTESnum-1], yerr=err_fringes[refTESnum-1], xerr=period/2, \n",
    "         fmt='ro', capsize=5, capthick=2, label='Fringe Value',zorder=200, lw=3)\n",
    "        legend()\n",
    "        \n",
    "        figure()\n",
    "        subplot(2,3,1)\n",
    "        a=hist(np.log10(sigres), bins=15, label='{0:5.2f} +/- {1:5.2f}'.format(mm,ss))\n",
    "        axvline(x=mm, color='r', ls='--')\n",
    "        axvline(x=mm-ss, color='r', ls=':')\n",
    "        axvline(x=mm+ss, color='r', ls=':')\n",
    "        axvline(x=mm-2*ss, color='r', ls=':')\n",
    "        axvline(x=mm+2*ss, color='r', ls=':')\n",
    "        xlabel('np.log10(TOD Residuals)')\n",
    "        title('{}\\n'.format(myhorns)+add_title)\n",
    "        legend()\n",
    "\n",
    "        subplot(2,3,2)\n",
    "        title('TES OK (2sig) {}\\n'.format(myhorns) +add_title)\n",
    "        residuals = ft.image_asics(all1=oktes)\n",
    "        imshow(residuals, vmin=0,vmax=1,cmap='bwr')\n",
    "        colorbar()\n",
    "\n",
    "        subplot(2,3,3)\n",
    "        title('TOD Residuals {}\\n'.format(myhorns) +add_title)\n",
    "        residuals = ft.image_asics(all1=sigres * oktes)\n",
    "        imshow(residuals, vmin=0)\n",
    "        colorbar()\n",
    "\n",
    "        \n",
    "        fr2d = ft.image_asics(all1=fringes) * mask\n",
    "        err_fr2d = ft.image_asics(all1=err_fringes) *mask\n",
    "        mm, ss = ft.meancut(fringes,3)\n",
    "        rng = 3*ss\n",
    "        figure()\n",
    "        myinterp = 'Gaussian'\n",
    "        subplot(2,3,4)\n",
    "        imshow(np.nan_to_num(fr2d), cmap='bwr', vmin=-rng, vmax=rng, interpolation=myinterp)\n",
    "        ft.qgrid()\n",
    "        colorbar()\n",
    "        title('Fringe {}\\n'.format(myhorns) +add_title)\n",
    "\n",
    "        subplot(2,3,5)\n",
    "        imshow(np.nan_to_num(err_fr2d), cmap='bwr', vmin=-rng, vmax=rng, interpolation=None)\n",
    "        ft.qgrid()\n",
    "        colorbar()\n",
    "        title('Error {}\\n'.format(myhorns) +add_title)\n",
    "\n",
    "        subplot(2,3,6)\n",
    "        imshow(np.nan_to_num(np.abs(fr2d/err_fr2d)), vmin=0, vmax=3, interpolation=None)\n",
    "        ft.qgrid()\n",
    "        colorbar()\n",
    "        title('Values / Error {}\\n'.format(myhorns) +add_title)   \n",
    "        tight_layout()\n",
    "        \n",
    "        figure()\n",
    "        imshow(np.nan_to_num(fr2d), cmap='bwr', vmin=-rng, vmax=rng, interpolation=myinterp)\n",
    "        ft.qgrid()\n",
    "        colorbar()\n",
    "        title('Fringe {}\\n'.format(myhorns) +add_title)\n",
    "\n",
    "        figure()\n",
    "        imshow(np.nan_to_num(fr2d), cmap='bwr', vmin=-rng, vmax=rng, interpolation=None)\n",
    "        ft.qgrid()\n",
    "        colorbar()\n",
    "        title('Fringe {}\\n'.format(myhorns) +add_title)\n",
    "        show()\n",
    "    return vals, errs, sigres, period, t0, fringes, err_fringes, oktes, status\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbce166a",
   "metadata": {},
   "outputs": [],
   "source": [
    "myref = 95\n",
    "ids = 0\n",
    "myds = datasets[ids]\n",
    "myhorns = horns[ids]\n",
    "print(myds)\n",
    "print(myhorns)\n",
    "lowcut=1e-5\n",
    "highcut = 5.\n",
    "vals, errs, sigres, period, t0, fringes, err_fringes, oktes, status = get_baselines_configurations_asics(myds, \n",
    "                                                                                          refTESnum=myref,\n",
    "                                                                                         myhorns=myhorns,\n",
    "                                                                                        lowcut=lowcut,\n",
    "                                                                                        highcut=highcut) \n",
    "print(np.sum(status, axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f3cf14",
   "metadata": {},
   "source": [
    "### We have everything needed to recover the fringes from individual configurations\n",
    "This will be need when accounting for non-linearities..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75332b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "rc('figure', figsize=(16,6))\n",
    "list_tes = [40, 34, 33, 64, 51, 62]\n",
    "\n",
    "coeffs = np.array([1./3, -1, 1, 1./3, -1, 1./3])\n",
    "for thetes in list_tes:\n",
    "    figure()\n",
    "    subplot(1,2,1)\n",
    "    errorbar(np.arange(6)+0.5, vals[thetes-1,:], yerr=errs[thetes-1,:], \n",
    "             xerr=0.5, fmt='ro', capsize=5, capthick=2, label='Configurations')\n",
    "    errorbar(3, fringes[thetes-1], yerr=err_fringes[thetes-1], xerr=3, \n",
    "             fmt='bo', capsize=5, capthick=2, label='Fringe Value')\n",
    "    for i in range(len(coeffs)):\n",
    "        text(i+0.1,0, '{0:4.2f}'.format(coeffs[i]))\n",
    "    xlabel('Configuration')\n",
    "    ylabel('ADU')\n",
    "    title('TES #{}'.format(thetes))\n",
    "    legend()\n",
    "\n",
    "    subplot(1,2,2)\n",
    "    fringes = np.zeros(256)\n",
    "    err_fringes = np.zeros(256)\n",
    "    for i in range(256):\n",
    "        fringes[i], err_fringes[i] = weighted_sum(vals[i,:], errs[i,:], coeffs)\n",
    "\n",
    "    fr2d = ft.image_asics(all1=fringes * oktes) * mask\n",
    "    err_fr2d = ft.image_asics(all1=err_fringes * oktes) * mask\n",
    "    mm, ss = ft.meancut(fringes,3)\n",
    "    rng = 3*ss\n",
    "\n",
    "    myinterp = 'None'\n",
    "    imshow(np.nan_to_num(fr2d), cmap='bwr', vmin=-rng, vmax=rng, interpolation=myinterp)\n",
    "    ft.qgrid()\n",
    "    colorbar()\n",
    "    title('Fringe {}'.format(myhorns))\n",
    "\n",
    "    imgnums = ft.image_asics(all1=np.arange(1,257))\n",
    "    indx = np.argwhere(imgnums == thetes)[0]\n",
    "\n",
    "    plot(indx[1], indx[0], '+', color='lime',ms=15, mew=3)\n",
    "    show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0fd2c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = 20000\n",
    "subplot(2,2,1)\n",
    "title('All configurations')\n",
    "xlabel('Configuration #')\n",
    "ylabel('TES#')\n",
    "imshow(vals, aspect='auto', vmin=-rng, vmax=rng)\n",
    "colorbar()\n",
    "\n",
    "subplot(2,2,2)\n",
    "imshow(errs, aspect='auto', vmin=-rng, vmax=rng)\n",
    "title('All configurations Error')\n",
    "xlabel('Configuration #')\n",
    "ylabel('TES#')\n",
    "colorbar()\n",
    "tight_layout()\n",
    "subplot(2,3,4)\n",
    "mm, ss = ft.meancut(np.log10(sigres),3)\n",
    "a=hist(np.log10(sigres), bins=15, label='{0:5.2f} +/- {1:5.2f}'.format(mm,ss))\n",
    "axvline(x=mm, color='r', ls='--')\n",
    "axvline(x=mm-ss, color='r', ls=':')\n",
    "axvline(x=mm+ss, color='r', ls=':')\n",
    "axvline(x=mm-2*ss, color='r', ls=':')\n",
    "axvline(x=mm+2*ss, color='r', ls=':')\n",
    "xlabel('np.log10(TOD Residuals)')\n",
    "legend()\n",
    "\n",
    "subplot(2,3,5)\n",
    "title('TES OK (residuals 2sig)')\n",
    "residuals = ft.image_asics(all1=oktes)\n",
    "imshow(residuals, vmin=0,vmax=1,cmap='bwr')\n",
    "colorbar()\n",
    "\n",
    "\n",
    "subplot(2,3,6)\n",
    "title('TOD Residuals')\n",
    "oktes = np.ones(len(sigres))\n",
    "oktes[np.log10(sigres) > 4.5] = np.nan\n",
    "residuals = ft.image_asics(all1=sigres * oktes)\n",
    "imshow(residuals)\n",
    "colorbar()\n",
    "\n",
    "tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a8511f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Now the fringes\n",
    "coeffs = np.array([1./3, -1, 1, 1./3, -1, 1./3])\n",
    "fringes = np.zeros(256)\n",
    "err_fringes = np.zeros(256)\n",
    "for i in range(256):\n",
    "    fringes[i], err_fringes[i] = weighted_sum(vals[i,:], errs[i,:], coeffs)\n",
    "\n",
    "fr2d = ft.image_asics(all1=fringes * oktes) * mask\n",
    "err_fr2d = ft.image_asics(all1=err_fringes * oktes) * mask\n",
    "mm, ss = ft.meancut(fringes,3)\n",
    "rng = 3*ss\n",
    "\n",
    "myinterp = 'Gaussian'\n",
    "subplot(1,3,1)\n",
    "imshow(np.nan_to_num(fr2d), cmap='bwr', vmin=-rng, vmax=rng, interpolation=myinterp)\n",
    "ft.qgrid()\n",
    "colorbar()\n",
    "title('Fringe {}'.format(myhorns))\n",
    "\n",
    "subplot(1,3,2)\n",
    "imshow(np.nan_to_num(err_fr2d), cmap='bwr', vmin=-rng, vmax=rng, interpolation=myinterp)\n",
    "ft.qgrid()\n",
    "colorbar()\n",
    "title('Error{}'.format(myhorns))\n",
    "\n",
    "subplot(1,3,3)\n",
    "imshow(np.nan_to_num(np.abs(fr2d/err_fr2d)), vmin=0, vmax=3, interpolation=myinterp)\n",
    "ft.qgrid()\n",
    "colorbar()\n",
    "title('Values / Error {}'.format(myhorns))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79da048e",
   "metadata": {},
   "source": [
    "# Now we can have a look at any dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b091bc76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============== Get data ==============\n",
    "\n",
    "#### 27/10/2020\n",
    "#### Vtes = 5\n",
    "global_dir = '/Volumes/LaCie/QubicData/Calib-TD/Fringes/2020-10-27/'\n",
    "vtes = 5\n",
    "eco = 1\n",
    "out_dir = '/Users/hamilton/Qubic/Calib-TD/Fringes/Fringes_2020-10-27_Vtes_5_Eco_1'\n",
    "datasets = np.sort(glob.glob(global_dir+'/*RF_switch*'))\n",
    "equiv = [0,0,1,1,2,2,3,3,3,3,3,3,3,3]    \n",
    "\n",
    "#### 28/10/2020\n",
    "# global_dir = '/Volumes/LaCie/QubicData/Calib-TD/Fringes/2020-10-28/'\n",
    "# ### Vtes=4\n",
    "# datasets = np.sort(glob.glob(global_dir+'/*RF_switch_Vtes_4_*'))\n",
    "# vtes = 4\n",
    "# eco = 1\n",
    "# equiv = [0,0,1,1,2,2,3,3]    \n",
    "# out_dir = '/Users/hamilton/Qubic/Calib-TD/Fringes/Fringes_2020-10-28_Vtes_4_Eco_1'\n",
    "# ### Vtes=3.5\n",
    "# datasets = np.sort(glob.glob(global_dir+'/*RF_switch_Vtes_3.5_*'))\n",
    "# vtes = 3.5\n",
    "# eco = 1\n",
    "# equiv = [0,0,1,1,2,2,3,3]    \n",
    "# out_dir = '/Users/hamilton/Qubic/Calib-TD/Fringes/Fringes_2020-10-28_Vtes_3.5_Eco_1'\n",
    "### Vtes=4 & No Eccosorb\n",
    "# datasets = np.sort(glob.glob(global_dir+'/*RF_switch_NoEco_Vtes_4_*'))\n",
    "# vtes = 4\n",
    "# eco = 0\n",
    "# equiv = [0,0,1,1,2,2,3,3]    \n",
    "# out_dir = '/Users/hamilton/Qubic/Calib-TD/Fringes/Fringes_2020-10-28_Vtes_4_Eco_0'\n",
    "\n",
    "\n",
    "horns = []\n",
    "ncycles = []\n",
    "wt = []\n",
    "dsdate = []\n",
    "for ds in datasets:\n",
    "    strs = ds.split('_')\n",
    "    dsdate.append((strs[0]+' '+strs[1]).split('/')[-1])\n",
    "    ncycles.append(float(strs[strs.index('ncycles')+1]))\n",
    "    wt.append(float(strs[strs.index('wt')+1]))\n",
    "    horns.append([int(strs[-2]), int(strs[-1])])\n",
    "\n",
    "print('Dates')\n",
    "print(dsdate)\n",
    "print('Ncycles')\n",
    "print(ncycles)\n",
    "print('WT')\n",
    "print(wt)\n",
    "print('Horns')\n",
    "print(horns)\n",
    "\n",
    "#### Equivalency class\n",
    "bseqindex, equiv = sc.find_equivalent_baselines(horns, q)\n",
    "all_equiv = np.unique(equiv)\n",
    "\n",
    "print('equivalency of baselines')\n",
    "print(equiv)\n",
    "print()\n",
    "print()\n",
    "print()\n",
    "print('Found {} equivalency classes:'.format(len(all_equiv)))\n",
    "reload(sc)\n",
    "for i in range(len(all_equiv)):\n",
    "    dsequiv = where(np.array(equiv)==all_equiv[i])[0]\n",
    "    subplot(1,4,i+1, aspect='equal')\n",
    "    sc.plot_horns(q)\n",
    "    title('Type = {}'.format(all_equiv[i]))\n",
    "    print(' - Type {}'.format(all_equiv[i]))\n",
    "    for j in range(len(dsequiv)):\n",
    "        print('     * dsnum={} [{},{}]'.format(dsequiv[j], horns[dsequiv[j]][0], horns[dsequiv[j]][1]))\n",
    "        sc.plot_baseline(q,[horns[dsequiv[j]][0], horns[dsequiv[j]][1]])\n",
    "    legend(fontsize=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380e1f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "allvals = []\n",
    "allerrs= []\n",
    "allsigres = []\n",
    "allfringes = []\n",
    "allerr_fringes =[]\n",
    "alloktes = []\n",
    "allstatus = []\n",
    "for ids in range(len(datasets)):\n",
    "    myds = datasets[ids]\n",
    "    myhorns = horns[ids]\n",
    "    print('#########################################################################')\n",
    "    print(myds)\n",
    "    print(myhorns)\n",
    "    myref = 95\n",
    "    vals, errs, sigres, period, t0, fringes, err_fringes, oktes, status = get_baselines_configurations_asics(myds, \n",
    "                                                                                          refTESnum=myref,\n",
    "                                                                                         myhorns=myhorns) \n",
    "    allvals.append(vals)\n",
    "    allerrs.append(errs)\n",
    "    allsigres.append(sigres)\n",
    "    allfringes.append(fringes)\n",
    "    allerr_fringes.append(err_fringes)\n",
    "    alloktes.append(oktes)\n",
    "    allstatus.append(status)\n",
    "\n",
    "allvals = np.array(allvals)\n",
    "allerrs = np.array(allerrs)\n",
    "allsigres = np.array(allsigres)\n",
    "allfringes = np.array(allfringes)\n",
    "allerr_fringes = np.array(allerr_fringes)\n",
    "alloktes = np.array(alloktes)\n",
    "allstatus = np.array(allstatus)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8076536",
   "metadata": {},
   "outputs": [],
   "source": [
    "# allvals = np.array(allvals)\n",
    "# allerrs = np.array(allerrs)\n",
    "# allsigres = np.array(allsigres)\n",
    "# allfringes = np.array(allfringes)\n",
    "# allerr_fringes = np.array(allerr_fringes)\n",
    "# alloktes = np.array(alloktes)\n",
    "\n",
    "np.shape(allerr_fringes)\n",
    "# for i in range(len(horns)):\n",
    "#     plot(allerr_fringes[i,:])\n",
    "plot(np.median(allerr_fringes, axis=0), color='k', lw=3, label='Median Error on Fringes')\n",
    "plot(np.median(allsigres, axis=0), color='r', lw=3, label='Median RMS residuals')\n",
    "legend()\n",
    "yscale('log')\n",
    "xlabel('TES number')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02616002",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a8e4174",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ad37ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24de9036",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3bea59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f54613",
   "metadata": {},
   "outputs": [],
   "source": [
    "rc('figure', figsize=(16,10))\n",
    "## Make a map of TES#\n",
    "nums = np.arange(1,257)\n",
    "im = ft.image_asics(all1=nums)\n",
    "imshow(im, cmap='binary')\n",
    "ft.qgrid()\n",
    "for j in range(17):\n",
    "    for i in range(17):\n",
    "        if isfinite(im[i,j]):\n",
    "            text(j-0.25,i+0.25,int(im[i,j]), fontsize=12, color='r', fontweight='bold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac592cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
