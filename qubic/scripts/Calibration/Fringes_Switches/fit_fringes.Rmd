---
jupyter:
  jupytext:
    text_representation:
      extension: .Rmd
      format_name: rmarkdown
      format_version: '1.2'
      jupytext_version: 1.4.0
  kernelspec:
    display_name: Python 3
    language: python
    name: python3
---

## Fit the fringe measurements and intercalibrate the TES

Edited by Louise 16/03/2021

In this notebook, I use an analytical model to simulate the fringes, defined in the library `selfcal_lib.py`. The goal is to fit the fringes measurements and measure the focal length of the combiner f, the off-axis angle of the source theta and the gain of each detectors. This is a good manner to intercalibrate the TES. 

The measurements are .fits files generated by the notebook `scripts/Calibration/Fringes_Switches/Generate-Fringes-Oct-2020-Louise.Rmd` that makes the fringes analysis from the raw TODs.  

```{python}
from __future__ import division, print_function

# %matplotlib inline
# %matplotlib notebook

from multiprocessing import cpu_count, Pool
import time
import os
import glob
import numpy as np

import matplotlib.pyplot as plt
from matplotlib.colors import SymLogNorm
from matplotlib.backends.backend_pdf import PdfPages
from mpl_toolkits.axes_grid1 import make_axes_locatable

import scipy.optimize as sop
from scipy.ndimage import gaussian_filter
import pandas as pd
import emcee
import corner

import qubic
from qubic import selfcal_lib as scal
from qubicpack.utilities import Qubic_DataDir
from qubic import fringes_lib as flib
import qubic.fibtools as ft

rc('figure', figsize=(12, 6))
rc('font', size=14)
```

### Choose if you work with real data or with simulations

```{python}
simu = True
```

### Get the measurement


Get the .fits file with the fringes measurement. You must put your personal directory.

```{python}
global_dir = '/home/lmousset/QUBIC/Qubic_work/Calibration/datas/Fringes/'
myfringes = 'Fringes_2020-10-27_12BLs_RemoveSlopePerTES_medianTrue_refTESautomatic_maskbadTES0.75.fits'
```

Read informations saved in the fits file and make a QubicInstrument:

```{python}
header, fdict = flib.read_fits_fringes(global_dir + myfringes)
print(fdict.keys())

allfringes = fdict['FRINGES_1D']
allerr = fdict['ERRORS']

# Normalization 
for k in range(len(allfringes)):
    std = np.std(allfringes[k])
    allfringes[k] /= std
    allerr[k] /= std

allmask_bad_TES = fdict['MASK_BAD_TES']
BLs = fdict['BLS']
nimages = len(BLs)

xTES = fdict['X_TES']
yTES = fdict['Y_TES']
# print(BLs)

# Make a QUBIC instrument
d = qubic.qubicdict.qubicDict()
d.read_from_file('global_source_oneDet.dict')
d['nf_sub'] = 1
d['Multiband'] = False
q = qubic.QubicInstrument(d)


BLs_sort, BLs_type = scal.find_equivalent_baselines(BLs, q)
```

Plot the baselines. There are sorted by equivalence type.

```{python}
scal.plot_BLs_eq(BLs, BLs_sort, q)
```

### Detect bad detectors

This is also done at theend of the Notebook `scripts/Calibration/Fringes_Switches/Generate-Fringes-Oct-2020-Louise.Rmd`. To be set as bad, the TES must be NAN in at least N images. This N can be chosen. 

```{python}
# Make a loop on N, compute how many bad TES it gives to choose the N you want.
thecond = np.arange(2, 12)
nbad = []

for cond in thecond:
    the_mask = flib.decide_bad_TES(allmask_bad_TES, condition=cond)
#     print(the_mask)
    nbad.append(int(256 - np.nansum(the_mask)))

plt.figure()
plt.plot(thecond, nbad, 'bo')
plt.xlabel('Number of images where the TES is NAN')
plt.ylabel('Number of bad TES')
plt.grid()

```

There is a plateau around N=9,10 which leads to ~30 bad detectors. We will choose N=30.

```{python}
the_mask = flib.decide_bad_TES(allmask_bad_TES, condition=5)
nbad = int(256 - np.nansum(the_mask))

# print(the_mask)
flib.plot_fringes_scatter(q, xTES, yTES, the_mask, normalize=False, s=140, cbar=False)

badTES = flib.give_index_bad_TES(the_mask)
print(badTES.T)

```

### Plot the fringes measurements. 
We make 2 plots:
* A simple scatter plot
* A imshow plot after performing a Gaussian convolution using Astropy (just for visual help)

```{python}
# Color map whith bad detectors in black
cmap_bwr = flib.make_cmap_nan_black('bwr')

for k in range(nimages):
    fig, axs = plt.subplots(1, 2, figsize=(13, 7))
    fig.subplots_adjust(wspace=0.5)
    fig.suptitle(f'k={k} - BL {BLs[k]}')
    ax0, ax1 = axs.ravel()
    
    # Scatter plot
    flib.plot_fringes_scatter(q, xTES, yTES, allfringes[k] * the_mask, normalize=False, s=180, fig=fig, ax=ax0)


    # Plot with Astropy convolution 
    fringes2D = flib.make2Dfringes_data(allfringes[k] * the_mask)
    fringes2D_conv = flib.astropy_convolution(fringes2D, sigma=0.7)
    flib.plot_fringes_imshow(fringes2D_conv, normalize=True, fig=fig, ax=ax1, cmap=cmap_bwr, 
                             title='Gaussian convolution', mask=flib.make_mask2D_thermometers_TD())
    
    
```

### Remove thermometers 

Data contains 256 detectors, 248 are bolometers but 8 are thermometers. To compare with Qubic soft simulations, it is useful to remove thermometers.

```{python}
xdata, ydata, the_mask = flib.remove_thermometers(xTES, yTES, the_mask)
ndet = xdata.shape[0]
print('Number of detectors:', ndet)

data, error = [], []
for k in range(nimages):
    _, _, mydata = flib.remove_thermometers(xTES, yTES, allfringes[k])
    _, _, myerror = flib.remove_thermometers(xTES, yTES, allerr[k])
    data.append(mydata)
    error.append(myerror)


```

### Re-order data as simulations from Qubic soft
TES numbering on the instrument and in simulations are different. To compare the two, we re-order the data following simulation order.

```{python}
xONAFP, yONAFP, _ = scal.get_TEScoordinates_ONAFP(q)
the_mask = flib.reorder_data(the_mask, xdata, ydata, xONAFP, yONAFP)

fringes, errs = [], []
for k in range(nimages):
    fringes.append(flib.reorder_data(data[k], xdata, ydata, xONAFP, yONAFP))
    errs.append(flib.reorder_data(error[k], xdata, ydata, xONAFP, yONAFP))


# Check the re-ordering is correct, the 2 plots for each baseline should be identical.
vmin = -1
vmax = 1
for k in range(nimages):
    fig, axs = plt.subplots(1, 2, figsize=(12, 6))
    fig.suptitle(f'BL {BLs[k]}')
    fig.subplots_adjust(wspace=0.5)
    ax0, ax1 = axs
    scal.scatter_plot_FP(q, xdata, ydata, data[k]*the_mask, frame='ONAFP', 
                         fig=fig, ax=ax0, s=170, cmap='bwr', 
                         vmin=vmin, vmax=vmax, title='Original order', unit=None)

    scal.scatter_plot_FP(q, xONAFP, yONAFP, fringes[k]*the_mask, frame='ONAFP', 
                         fig=fig, ax=ax1, s=170, cmap='bwr', 
                         vmin=vmin, vmax=vmax, title='Re-order', unit=None)
```

### Make a selection
If you want to perform the fit on a reduce number of images, you can select them here.

```{python}
selection = True
if selection:
    myselection = [0, 2, 5]
#     myselection = [0, 1, 2, 3, 4, 5]
    remind_all_fringes = fringes.copy() 
    fringes = [fringes[i] for i in myselection]
    errs = [errs[i] for i in myselection]
    BLs = [BLs[i] for i in myselection]
    print('Selected baselines:', BLs)
    
nimages = len(BLs)
print(f'We will work with {nimages} images.')
```

# Start fitting


#### Make fake data

This is only useful if you work with a simulation and not with real data.

```{python}
ndet = 248 
print('ndet:', ndet)

# Parameters for the fit
focal_fake = 0.29
theta_fake = np.deg2rad(0.5)
# allP_fake = [0.5] * nimages
allP_fake = list(np.random.rand(nimages))
print('P_k fake:', allP_fake)
params_fake = [focal_fake, theta_fake] + allP_fake


# Gain for each TES (same for each image)
# gains_fake = np.ones(ndet)
gains_fake = np.random.normal(1., 1., size=ndet)
gains_fake /= np.mean(gains_fake)
print('gain mean:', np.mean(gains_fake))
print('gains fake:', gains_fake[:10])
print('gains negative:', gains_fake[gains_fake<0.])

sigma = 0.3 # Gaussian noise

fake_fringes = []
allPhi_fake = []
d['focal_length'] = focal_fake
q = qubic.QubicInstrument(d)
for k in range(nimages):
    model_fake_data = scal.Model_Fringes_Ana(q, BLs[k], 
                                             theta_source=theta_fake, 
                                             nu_source=150e9,
                                             frame='ONAFP')

    x, y, Phi = model_fake_data.get_fringes(times_gaussian=False)
    allPhi_fake.append(Phi)
    
    # Multiply by a global amplitude (Calibration source power)
    fake_P = Phi * allP_fake[k]
    
    # Gain
    fake_gain = fake_P * gains_fake
    
    # Add gaussian noise
    noise = np.random.normal(loc=0., scale=sigma, size=ndet)
    print('Gaussian noise:', noise[:10])
    fake_noise = fake_gain + noise
    
    fake_fringes.append(fake_noise)
    
    fig, axs = plt.subplots(2, 2, figsize=(12, 12))
    fig.subplots_adjust(wspace=0.5)
    ax0, ax1, ax2, ax3 = np.ravel(axs)
    scal.scatter_plot_FP(q, xONAFP, yONAFP, Phi, frame='ONAFP', 
                         fig=fig, ax=ax0, title='Pure fringes', unit=None, s=170, cmap='bwr')
    scal.scatter_plot_FP(q, xONAFP, yONAFP, fake_P, frame='ONAFP', 
                         fig=fig, ax=ax1, title='Fringes x Power', unit=None, s=170, cmap='bwr')
    scal.scatter_plot_FP(q, xONAFP, yONAFP, fake_gain, frame='ONAFP', 
                         fig=fig, ax=ax2, title='With Gains', unit=None, s=170, cmap='bwr')
    scal.scatter_plot_FP(q, xONAFP, yONAFP, fake_noise, frame='ONAFP',
                         fig=fig, ax=ax3, title='Adding noise', unit=None, s=170, cmap='bwr')

if simu:
    fringes = fake_fringes
    errs = list(np.ones_like(fake_fringes) * sigma)
```

#### Covariance matrix of the noise

To eliminate bad TES, we put a very high error on them => very small weight in the fit.

Then we make a list with an inverse covariance matrix for each image.

```{python}
for k in range(nimages):
    errs[k][np.isnan(the_mask)] *= 1e20 

allInvCov = [scal.make_inverse_covariance(errs[k], verbose=True) for k in range(nimages)]
```

#### Explore the chi2 to find guess parameters

```{python}
all_fl, all_th, chi2_grid = scal.make_chi2_grid(allInvCov, fringes, BLs, q, 
                                nval_fl=40, nval_th=40, 
                                fl_min=0.25, fl_max=0.35,
                                th_min=np.deg2rad(-1.), th_max=np.deg2rad(1), 
                                fixPower=True)
```

```{python}
# Smooth with a gaussian to avoid loosing the min in random pixel very low (not always necessary).
smooth = False
step_fl = all_fl[1] - all_fl[0]
step_th = all_th[1] - all_th[0]
if smooth:
    chi2_grid = gaussian_filter(chi2_grid, sigma=[step_fl*4e2, step_th*4e2])
```

```{python}
# Find the min and take it as a guess for the following
min_indices = np.unravel_index(np.argmin(chi2_grid), chi2_grid.shape)
print(f'Chi2 min = {np.min(chi2_grid)} at {min_indices}')

fl_guess = all_fl[min_indices[0]]
th_guess = all_th[min_indices[1]]

allP_guess = [0.5] * nimages


params_guess = [fl_guess, th_guess] + allP_guess

print('Guess:', params_guess)
if simu:
    print('Fake:', params_fake)
```

```{python}
# Plot the chi2 map 
fig, ax = plt.subplots(figsize=(8, 8))
c = ax.pcolor(np.rad2deg(all_th), all_fl, chi2_grid, vmin=0, vmax=1e7)#, norm=SymLogNorm(99e9))
ax.set_xlabel('Theta')
ax.set_ylabel('Focal length')
if simu:
    ax.scatter(np.rad2deg(theta_fake),  focal_fake,  marker='o', color='r', s=100, label='Fake data')
ax.scatter(np.rad2deg(th_guess),  fl_guess,  marker='o', color='m', s=100, label='Guess')
fig.colorbar(c, ax=ax)
ax.legend()
```

## Minimize the chi2 

Using `scipy.optimize.minimize`

```{python}
# params_guess = [0.30, np.deg2rad(-0.5)] + [0.5]*3
result = sop.minimize(scal.get_chi2, 
                      x0=params_guess, 
                      args=(allInvCov, fringes, BLs, q), 
                      method='Nelder-Mead',
                      options={'maxiter':10000})
print(result)
```

```{python}
print('***** Focal:')
if simu:
    print('Fake:', focal_fake)
print('Result:', result['x'][0])
print('Guess:', fl_guess)

print('\n***** Theta:')
if simu:
    print('Fake:', np.rad2deg(theta_fake))
print('Result:', np.round(np.rad2deg(result['x'][1]), 6))
print('Guess:', np.round(np.rad2deg(th_guess), 6))

print('\n***** Power:')
print('Guess:', allP_guess)
print('Result:', np.round(result['x'][2:], 4))
if simu:
    print('Fake:', np.round(allP_fake, 4))
    print('Fake / Result:', np.round(allP_fake / result['x'][2:], 4))
    
print('\nReduce Chi2:', result['fun']/(nimages * ndet -(ndet + nimages + 2)))
```

#### Get the intercalibrations
We compute the detector gains using the result of the minimisation.

```{python}
q.optics.focal_length = result['x'][0]
allP_res = result['x'][2:]
PowerPhi = []
for k in range(nimages):
    model = scal.Model_Fringes_Ana(q, BLs[k], 
                                   theta_source=result['x'][1], 
                                   nu_source=150e9, 
                                   frame='ONAFP')

    x, y, Phi = model.get_fringes(times_gaussian=False)
    
    # Global amplitude
    PowerPhi.append(Phi * allP_res[k])
    

# Gain for each detector
A, Cov_A = scal.get_gains(PowerPhi, allInvCov, fringes)

print('Gains found:\n', np.round(A[:10], 4))
if simu:
    print('\nGains fake:\n', np.round(gains_fake[:10], 4))
```

```{python}
if simu:
    fig, axs = plt.subplots(2, 2, figsize=(12, 8))
    ax1, ax2, ax3, ax4 = np.ravel(axs)
    fig.subplots_adjust(wspace=0.4)
    scal.scatter_plot_FP(q, xONAFP, yONAFP, gains_fake, fig=fig, ax=ax1, frame='ONAFP', title='Gains fake', 
                         unit=None, vmin=None, vmax=None, s=150, cmap='bwr')
    scal.scatter_plot_FP(q, xONAFP, yONAFP, A, fig=fig, ax=ax2, frame='ONAFP', title='Gains found', 
                         unit=None, vmin=None, vmax=None, s=150, cmap='bwr')
    scal.scatter_plot_FP(q, xONAFP, yONAFP, A-gains_fake, fig=fig, ax=ax3, frame='ONAFP', title='Residuals', 
                         unit=None, vmin=None, vmax=None, s=150, cmap='bwr')
    mean = np.mean(A-gains_fake)
    std = np.std(A-gains_fake)
    ax4.hist(A-gains_fake, range=(-1, 1), bins=30, label='{:.6f} +- {:.6f}'.format(mean, std))
    ax4.axvline(mean, color='r')
    ax4.set_title('Histogram residuals')
    ax4.legend()
    fig.tight_layout()
else:
    fig, axs = plt.subplots(1, 2, figsize=(13, 4))
    ax1, ax2 = np.ravel(axs)
    scal.scatter_plot_FP(q, xONAFP, yONAFP, A, fig=fig, ax=ax1, frame='ONAFP', title='Gains found', 
                         unit=None, vmin=-1, vmax=1, s=100, cmap='bwr')
    ax2.hist(A, bins=30, range=(-10, 10), label='{:.2f} +- {}'.format(np.mean(A), np.std(A)))
    ax2.set_xlabel('Gains found')
    ax2.axvline(np.mean(A), color='r')
    ax2.legend()
    fig.tight_layout()
```

```{python}
if simu:
    fig, axs = plt.subplots(1, 2, figsize=(12, 6))
    ax1, ax2 = np.ravel(axs)

    ax1.plot(allP_fake, result['x'][2:], 'ro')
    ax1.plot([0, 1], [0, 1], 'k--', label='y=x')
    ax1.set_xlabel('P Fake Data')
    ax1.set_ylabel('P Fit result')
    ax1.set_title('Power')
    ax1.legend()

    ax2.errorbar(gains_fake, A, yerr=np.sqrt(np.diag(Cov_A)), fmt='o', color='b')
    # ax2.plot(gains_fake, A, 'b.')
    ax2.plot(gains_fake, gains_fake, 'k--', label='y=x')
#     ax2.set_ylim(-5, 5)
    ax2.set_xlabel('Gain Fake Data')
    ax2.set_ylabel('Gain Fit result')
    ax2.set_title('Gain')
    ax2.legend()


```

#### Residuals and correction by intercalibrations (gains)

```{python}
def make_colorbar(ax, image):
    divider = make_axes_locatable(ax)
    cax = divider.append_axes('right', size='5%', pad=0.05)
    clb = fig.colorbar(image, cax=cax)
    return
 
def plot_residuals(q, xONAFP, yONAFP, BL, data, the_mask, PowerPhi, errors, gains, cmap='bwr', normalize=True):
    fig, axs = plt.subplots(4, 2, figsize=(12, 16))
    fig.suptitle(f'BL {BL}')
    axs = np.ravel(axs)
    
    # Initial / corrected 
    correct = data/gains
    flib.plot_fringes_scatter(q, xONAFP, yONAFP, data*the_mask, fig=fig, ax=axs[0], frame='ONAFP', 
                     title=f'Data', s=100, normalize=normalize)
    flib.plot_fringes_scatter(q, xONAFP, yONAFP, correct*the_mask, fig=fig, ax=axs[1], frame='ONAFP', 
                     title=f'Data / gains', s=100, normalize=normalize)
    
    # Initial / corrected smooth
    init2D = flib.make2Dfringes_QubicSoft(data*the_mask, q)
    init2D_conv = flib.astropy_convolution(init2D, sigma=0.7)
    flib.plot_fringes_imshow(init2D_conv, normalize=normalize, fig=fig, ax=axs[2], cmap=cmap, 
                             title='Data with Astropy convolution', mask=flib.make_mask2D_thermometers_TD())
    
    correct2D = flib.make2Dfringes_QubicSoft(correct*the_mask, q)
    correct2D_conv = flib.astropy_convolution(correct2D, sigma=0.7)
    flib.plot_fringes_imshow(correct2D_conv, normalize=normalize, fig=fig, ax=axs[3], cmap=cmap, 
                             title='Data / gains with Astropy convolution', mask=flib.make_mask2D_thermometers_TD())
    
    # Fit
    flib.plot_fringes_scatter(q, xONAFP, yONAFP, PowerPhi, frame='ONAFP', fig=fig, ax=axs[4], 
                              title='Fit: Power x Phi', s=100, vmin=-1, vmax=1, normalize=False)
    
    # Residuals
    residu = (correct - PowerPhi) * the_mask
    flib.plot_fringes_scatter(q, xONAFP, yONAFP, residu, frame='ONAFP',
                             fig=fig, ax=axs[5], title='Residuals = Data/gains - Power x Phi', s=100, vmin=-1, vmax=1, normalize=False)
    
    # Pull
    pull = residu / (errors/gains)
    mean = np.nanmean(pull)
    std = np.nanstd(pull)
    axs[6].hist(pull, range=(-15, 15), bins=15, label='{:.5f} +- {:.5f}'.format(mean, std))
    axs[6].axvline(mean, color='r')
    axs[6].axvline(mean+std, color='r', linestyle='--')
    axs[6].axvline(mean-std, color='r', linestyle='--')
    axs[6].set_title('Pull = Residuals / (errors/gains)')
    axs[6].legend()
    plt.axvline
    fig.tight_layout()
    return
```

```{python}
cmap_bwr=flib.make_cmap_nan_black('bwr')
for k in range(nimages):
    plot_residuals(q, xONAFP, yONAFP, BLs[k], fringes[k], the_mask, PowerPhi[k], errs[k], A, 
                   cmap=cmap_bwr, normalize=False)

```

### Correct images not used by the intercalibrations

```{python}
not_used = list(np.arange(12))
for i in myselection[::-1]:
    del not_used[i]
print(myselection, not_used)
```

```{python}
if selection:
    fringes_not_used = [remind_all_fringes[i] for i in not_used]
    
    for k in range(len(not_used)):
        bl = fdict['BLS'][not_used[k]]
        correct = fringes_not_used[k] / A

        fig, axs = plt.subplots(1, 2)
        fig.suptitle(f'BL {bl}')
        flib.plot_fringes_scatter(q, xONAFP, yONAFP, fringes_not_used[k]*the_mask, fig=fig, ax=axs[0], frame='ONAFP', 
                         title=f'Data', s=190, normalize=False)
        flib.plot_fringes_scatter(q, xONAFP, yONAFP, correct*the_mask, fig=fig, ax=axs[1], frame='ONAFP', 
                         title=f'Data / gains', s=190, normalize=False)
        fig.tight_layout()
```

## MCMC

To get errors on the focal length, theta and P_k.

```{python}
os.environ["OMP_NUM_THREADS"] = "1"

ncpu = cpu_count()
print("{0} CPUs".format(ncpu))
```

```{python}
def lnlike(params, allInvCov, alldata, BLs):
    chi2, A, Cov_A = scal.get_chi2(params, allInvCov, alldata, BLs, q, returnA=True)
    LnLike = - 0.5 * chi2
#     print(chi2)
    return LnLike, A, Cov_A

def lnprior(params):
    fl = params[0]
    th = params[1]
    allP = params[2:]

    if fl > 0.:
        return 0.0
    else:
        return -np.inf
    
# Log of the posterior (Posterior = prior x likelihood)
def lnprob(params, allInvCov, alldata, BLs):
    lp = lnprior(params)
    if not np.isfinite(lp):
        return -np.inf
    LnLike, A, Cov_A = lnlike(params, allInvCov, alldata, BLs)
    return lp + LnLike, A, Cov_A

def run(p0, nwalkers, niter, ndim, lnprob, args, withpool=True):
    with Pool() as pool:
        dtype = [("A", ndarray), ("Cov_A", ndarray)]
        if not withpool:
            pool = None
        sampler = emcee.EnsembleSampler(nwalkers, ndim, lnprob, args=args, blobs_dtype=dtype, pool=pool)

        print("\n =========== Running burn-in... ===============")
        p0, _, _, _ = sampler.run_mcmc(p0, 10, progress=True)
        sampler.reset()

        print("\n =========== Running production... ===========")
        start = time.time()
        pos, prob, state, _ = sampler.run_mcmc(p0, niter, progress=True)
        end = time.time()
        multi_time = end - start
        print("Multiprocessing took {0:.1f} seconds".format(multi_time))
        
        blobs = sampler.get_blobs(flat=True)
        blob_A = blobs["A"]
        blob_Cov_A = blobs["Cov_A"]

    return sampler, pos, prob, state, blob_A, blob_Cov_A
```

```{python}
ndim = len(params_guess)
nwalkers = 20

# Initial guess
p0 = [params_guess + 1e-4 * np.random.rand(ndim) for i in range(nwalkers)]
# print(p0)

niter = 200
args = (allInvCov, fringes, BLs)
sampler, pos, prob, state, blob_A, blob_Cov_A = run(p0, nwalkers, niter, ndim, lnprob, args, withpool=False)
```

```{python}
# Look at the full chain
thin = 1
samples = sampler.get_chain(discard=0, thin=thin, flat=False)
print(samples.shape)
flat_samples = sampler.get_chain(discard=0, thin=thin, flat=True)
print(flat_samples.shape)
cut = 1000

plt.subplots(3, 1, figsize=(12, 8))
plt.suptitle('Full chain')

plt.subplot(311)
plt.plot(flat_samples[:, 0])
plt.plot(0, fl_guess, 'ro', label='Guess')
if simu:
    plt.axhline(focal_fake, label='Truth')
plt.axvline(cut, color='r', label='Cut')
plt.ylabel('Focal [m]')
plt.legend()
# plt.ylimfloat(0.29, 0.31)
# plt.xlim(0, 400)

plt.subplot(312)
plt.plot(np.rad2deg(flat_samples[:, 1]))
plt.plot(0, np.rad2deg(th_guess), 'ro', label='Guess')
if simu:
    plt.axhline(np.rad2deg(theta_fake), label='Truth')
plt.axvline(cut, color='r', label='Cut')
plt.ylabel('Theta [deg]')
plt.xlim(30000, 31000)
# plt.ylim(-1, 0.)

plt.subplot(313)
plt.ylabel('P_k')
plt.xlabel('Iteration')
for i in range(len(allP_fake)):
    p=plt.plot(flat_samples[:, 2+i])
    plt.plot(0, allP_guess[i], 'ro', label='Guess')
    if simu:
        plt.axhline(allP_fake[i], color=p[0].get_color(), label='Truth')
plt.axvline(cut, color='r', label='Cut')
# plt.ylim(0.4, 0.6)
```

```{python}
# Cut the chain and get the parameters
flat_samples = sampler.get_chain(discard=100, thin=thin, flat=True)
# flat_samples = sampler.get_chain(discard=cut, thin=5, flat=True)
print(flat_samples)

mean_param = np.mean(flat_samples, axis=0)
std_param = np.std(flat_samples, axis=0)
print(mean_param)

cov_param = np.cov(flat_samples.T)
print(cov_param.shape)
label = ['fl', 'th'] + [f'P{i+1}' for i in range(len(allP_fake))]
lim = np.abs(np.max(cov_param))


fig, ax = plt.subplots(1, 1, figsize=(6, 6))
im = ax.imshow(cov_param, cmap='bwr', vmin=-0.01, vmax=0.01)
ax.set_xticks(np.arange(len(params_guess)))
ax.set_yticks(np.arange(len(params_guess)))
ax.set_xticklabels(label)
ax.set_yticklabels(label)
ax.set_title('Covariance')
fig.colorbar(im)

```

```{python}
import getdist
from getdist import plots, MCSamples

names = ['Focal', 'Theta'] + [f'P{i+1}' for i in range(nimages)]
labels = ['f', r'\theta'] + [f'P_{i+1}' for i in range(nimages)]
samps = MCSamples(samples=flat_samples, names=names, labels=labels,
        ranges={'Focal':(0, None), 'Theta':(None,None)})

g = plots.getSubplotPlotter()
g.triangle_plot(samps, filled=True, title_limit=2, legend_labels='Samples', 
                markers=params_fake)

```

```{python}
print('***** Focal:')
print('Guess:', fl_guess)
if simu:
    print('Fake:', focal_fake)
print('Mean from MCMC:', mean_param[0])
print('STD from MCMC:', std_param[0])

print('\n***** Theta:')
print('Guess:', np.round(np.rad2deg(th_guess), 6))
if simu:
    print('Fake:', np.rad2deg(theta_fake))
print('Mean from MCMC:', np.rad2deg(mean_param[1]))
print('STD from MCMC:', np.rad2deg(std_param[1]))

print('\n***** Power:')
print('Guess:', allP_guess)
if simu:
    print('Fake:', np.round(allP_fake, 4))
    print('Fake / Result:', np.round(allP_fake / mean_param[2:], 4))
print('Mean from MCMC:', mean_param[2:])
print('STD from MCMC:', std_param[2:])

# Reduced: Chi2
nDDL = nimages * ndet - (ndet + nimages + 2)
print('\n***Reduced Chi2:', scal.get_chi2(mean_param, allInvCov, fringes, BLs, q) / nDDL)

```

#### Get A from the fit parameters

```{python}
# Directly, from the mean obtained with the MCMC
q.optics.focal_length = mean_param[0]
allPowerPhi = []
for k in range(nimages):
    model = scal.Model_Fringes_Ana(q, BLs[k], 
                                    theta_source=mean_param[0], 
                                    nu_source=150e9, 
                                    fwhm=20., amp=1., frame='ONAFP')

    x, y, Phi = model.get_fringes(times_gaussian=False)
    
    # Global amplitude
    allPowerPhi.append(Phi * allP_res[k])

# Gain for each detector
A, Cov_A = scal.get_gains(allPowerPhi, allInvCov, fringes)

print('\nA:', np.round(A[:10], 4))
if simu:
    print('\nGains fake:', np.round(gains_fake[:10], 4))
```

```{python}
# Producing params with the covariance found with the MCMC
size = 1000
distrib = np.random.multivariate_normal(mean_param, cov_param, size=size)
allA = np.zeros((size, ndet))
for i in range(size):
    params = distrib[i]
    q.optics.focal_length = params[0]
    allPowerPhi = []
    for k in range(nimages):
        model = scal.Model_Fringes_Ana(q, BLs[k], 
                                        theta_source=params[1], 
                                        nu_source=150e9, 
                                        fwhm=20., amp=1., frame='ONAFP')

        x, y, Phi = model.get_fringes(times_gaussian=False)
        
        # Global amplitude
        allPowerPhi.append(Phi * allP_res[k])


    # Gain for each detector
    allA[i, :], Cov_A = scal.get_gains(allPowerPhi, allInvCov, fringes)

stdA = np.std(allA, axis=0)    
meanA = np.mean(allA, axis=0)    
```

```{python}
# Get A from the blob (A computed and saved during the MCMC) 
blobA_mean = np.mean(blob_A[thin*cut:])
blobA_std = np.std(blob_A[thin*cut:])
plt.figure()
plt.hist(blob_A[thin*cut::100][0])
```

```{python}
xx = np.arange(np.min(gains_fake), np.max(gains_fake), 0.5)
if simu:
    fig, axs = plt.subplots(2, 2, figsize=(13, 13))
    fig.subplots_adjust(wspace=0.3)
    ax1, ax2, ax3, ax4 = np.ravel(axs)
    ax1.errorbar(allP_fake, mean_param[2:], yerr=std_param[2:], fmt='o', color='r', label='Mean, STD')
    ax1.plot([0, 1], [0, 1], 'k--', label='y=x')
    ax1.set_xlabel('P Fake Data')
    ax1.set_ylabel('Fit result')
    ax1.set_title('Power Pk')
    ax1.legend()

    ax2.errorbar(gains_fake, A, yerr=np.sqrt(np.diag(Cov_A)), fmt='o', color='b', label='A, CovA')
    ax2.plot(xx, xx, 'k--', label='y=x')
    ax2.set_xlabel('Gain Fake Data')
#     ax2.set_ylabel('Gain Fit result')
    ax2.set_title('Gain')
    ax2.legend()
    
    ax3.errorbar(gains_fake, meanA, yerr=stdA, fmt='o', color='g', label='mean, STD')
    ax3.plot(xx, xx, 'k--', label='y=x')
    ax3.set_xlabel('Gain Fake Data')
#     ax3.set_ylabel('Gain with Monte Carlo')
    ax3.set_title('Gain with MC')
    ax3.legend()
    
    ax4.errorbar(gains_fake, blobA_mean, yerr=blobA_std, fmt='o', color='r', label='mean, STD')
    ax4.plot(xx, xx, 'k--', label='y=x')
    ax4.set_xlabel('Gain Fake Data')
#     ax4.set_ylabel('Gain with Monte Carlo')
    ax4.set_title('Gains from blob')
    ax4.legend()
    fig.tight_layout()

else:
    vmin=-10
    vmax = 10
    fig, axs = plt.subplots(2, 2, figsize=(13, 10))
    fig.suptitle('Gains and errors found with MCMC')
    ax1, ax2, ax3, ax4 = np.ravel(axs)
    fig.subplots_adjust(wspace=0.4)
    scal.scatter_plot_FP(q, xONAFP, yONAFP, blobA_mean, fig=fig, ax=ax1, frame='ONAFP', title='A', 
                         unit=None, vmin=vmin, vmax=vmax, s=100, cmap='bwr')
    scal.scatter_plot_FP(q, xONAFP, yONAFP, blobA_std, fig=fig, ax=ax2, 
                         frame='ONAFP', title='STD(A)', 
                         unit=None, vmin=vmin/10, vmax=vmax/10, s=100, cmap='bwr')
    
    ax3.hist(A, bins=30, label='{} +- {}'.format(np.mean(blobA_mean), np.std(blobA_mean)))
    ax3.set_xlabel('Gains found with MCMC')
    ax3.axvline(np.mean(blobA_mean), color='r')
    ax3.legend()
    
    fig.tight_layout()
    
#     plt.figure()
#     plt.errorbar(A, meanA, xerr=np.sqrt(np.diag(Cov_A)), yerr=stdA, fmt='o')
#     plt.plot(A, A, label='y=x')
#     plt.xlabel('A')
#     plt.ylabel('Mean A after MC')
# #     plt.axis('equal')
#     plt.legend()
```

#### Residuals and data corrected by inter-calibrations

```{python}
for k in range(nimages):
    plot_residuals(q, xONAFP, yONAFP, BLs[k], 
                   fringes[k], 
                   the_mask, 
                   allPowerPhi[k], 
                   errs[k], 
                   blobA_mean, cmap=cmap_bwr)

```

```{python}

```
