---
jupyter:
  jupytext:
    text_representation:
      extension: .Rmd
      format_name: rmarkdown
      format_version: '1.2'
      jupytext_version: 1.5.0
  kernelspec:
    display_name: Python 3
    language: python
    name: python3
---

## Fit the fringe measurements and intercalibrate the TES

Edited by Louise 16/03/2021

In this notebook, I use an analytical model to simulate the fringes, defined in the library `selfcal_lib.py`. The goal is to fit the fringes measurements and measure the focal length of the combiner f, the off-axis angle of the source theta and the gain of each detectors. This is a good manner to intercalibrate the TES. 

The measurements are .fits files generated by the notebook `scripts/Calibration/Fringes_Switches/Generate-Fringes-Oct-2020-Louise.Rmd` that makes the fringes analysis from the raw TODs.  

```{python}
from __future__ import division, print_function

# %matplotlib inline
# %matplotlib notebook

from multiprocessing import cpu_count, Pool
import time
import os
import glob
import numpy as np

import matplotlib.pyplot as plt
from matplotlib.colors import SymLogNorm
from matplotlib.backends.backend_pdf import PdfPages
from mpl_toolkits.axes_grid1 import make_axes_locatable

import scipy.optimize as sop
from scipy.ndimage import gaussian_filter
import pandas as pd
import emcee
import corner
from iminuit import Minuit

import qubic
from qubic import selfcal_lib as scal
from qubicpack.utilities import Qubic_DataDir
from qubic import fringes_lib as flib
import qubic.fibtools as ft

rc('figure', figsize=(12, 6))
rc('font', size=14)
```

```{python}
# If you want to save plots, set the directory here
save_dir = '/home/lmousset/QUBIC/These_manuscrit/Figures/Plots/'
```

### Choose if you work with real data or with simulations

```{python}
simu = False
```

### Get the measurement


Get the .fits file with the fringes measurement. You must put your personal directory.

```{python}
global_dir = '/home/lmousset/QUBIC/Qubic_work/Calibration/datas/Fringes/'
myfringes = 'Fringes_2020-10-27_12BLs_RemoveSlopePerTES_medianTrue_refTESautomatic_maskbadTES0.75.fits'
```

Read informations saved in the fits file and make a QubicInstrument:

```{python}
header, fdict = flib.read_fits_fringes(global_dir + myfringes)
print(fdict.keys())

allfringes = fdict['FRINGES_1D']
allerr = fdict['ERRORS']

# Normalization 
std = np.std(allfringes)
for k in range(len(allfringes)):
     #std = np.nanstd(allfringes[k])
    allfringes[k] /= std
    allerr[k] /= std

allmask_bad_TES = fdict['MASK_BAD_TES']
BLs = fdict['BLS']
nimages = len(BLs)

xTES = fdict['X_TES']
yTES = fdict['Y_TES']
# print(BLs)

# Make a QUBIC instrument
d = qubic.qubicdict.qubicDict()
d.read_from_file('global_source_oneDet.dict')
d['nf_sub'] = 1
d['Multiband'] = False
q = qubic.QubicInstrument(d)


BLs_sort, BLs_type = scal.find_equivalent_baselines(BLs, q)
```

Plot the baselines. There are sorted by equivalence type.

```{python}
scal.plot_BLs_eq(BLs, BLs_sort, q)
```

### Detect bad detectors in all images

This is also done at theend of the Notebook `scripts/Calibration/Fringes_Switches/Generate-Fringes-Oct-2020-Louise.Rmd`. To be set as bad, the TES must be NAN in at least N images. This N can be chosen. 

```{python}
# Make a loop on N, compute how many bad TES it gives to choose the N you want.
thecond = np.arange(2, 12)
nbad = []

for cond in thecond:
    my_mask = flib.decide_bad_TES(allmask_bad_TES, condition=cond)
#     print(my_mask)
    nbad.append(int(256 - np.nansum(my_mask)))

plt.figure()
plt.plot(thecond, nbad, 'bo')
plt.xlabel('Number of images where the TES is NAN')
plt.ylabel('Number of bad TES')
plt.grid()

```

There is a plateau around N=9,10 which leads to ~30 bad detectors. We will choose N=9.

```{python}
my_mask = flib.decide_bad_TES(allmask_bad_TES, condition=9)
nbad = int(256 - np.nansum(my_mask))
print(nbad)

# print(my_mask)
flib.plot_fringes_scatter(q, xTES, yTES, my_mask, normalize=False, s=140, cbar=False, config='TD')

badTES = flib.give_index_bad_TES(my_mask)
print(badTES.T)

```

#### if you do not want to apply a mask


```{python}
#my_mask = np.ones_like(my_mask)
```

### Plot the fringes measurements. 
We make 2 scatter plots:
* Fringes: normalized by the STD
* Error: Not normalized, fixed between -0.1 and 0.1


```{python}
# Color map whith bad detectors in black
cmap_bwr = flib.make_cmap_nan_black('bwr')
cmap_red = flib.make_cmap_nan_black('Reds')

for k in range(nimages):
    fig, axs = plt.subplots(1, 2, figsize=(14, 6))
    fig.subplots_adjust(wspace=0.5)
    #fig.suptitle(f'k={k} - BL {BLs[k]}')
    fig.suptitle(f'Baseline [{BLs[k][0]}-{BLs[k][1]}]')
    ax0, ax1 = axs.ravel()
    
    # Scatter plot
    flib.plot_fringes_scatter(q, xTES, yTES, allfringes[k] * my_mask, normalize=False, s=200, config='TD',
                              fig=fig, ax=ax0, title='Fringes', vmin=None, vmax=None)
    # Scatter plot
    flib.plot_fringes_scatter(q, xTES, yTES, allerr[k] * my_mask, 
                              normalize=False, vmin=0, vmax=0.1, 
                              s=200, config='TD',
                              fig=fig, ax=ax1, title='Errors', cmap=cmap_red)
    fig.tight_layout()
    #plt.savefig(save_dir + f'fringes_plot_2020-10-27_BL{BLs[k][0]}-{BLs[k][1]}.pdf', bbox_inches='tight')


    # Plot with Astropy convolution (for visual help)
    #fringes2D = flib.make2Dfringes_data(allfringes[k] * my_mask)
    #fringes2D_conv = flib.astropy_convolution(fringes2D, sigma=0.7)
    #flib.plot_fringes_imshow(fringes2D_conv, normalize=True, fig=fig, ax=ax1, cmap=cmap_bwr, 
                             #title='Gaussian convolution', mask=flib.make_mask2D_thermometers_TD())
    
    
```

```{python}
# Scatter plot for papers
# k = 5
# fig = plt.figure(figsize=(7, 7))
# ax = fig.gca()
# flib.plot_fringes_scatter(q, xTES, yTES, allfringes[k] * my_mask, normalize=False, s=350,
#                           fig=fig, ax=ax, vmin=-0.3, vmax=0.3, title=f'Data - Baseline {BLs[k]}', fontsize=20)
# fig.tight_layout()
# fig.savefig('/home/lmousset/QUBIC/Images/Data20201027_fringes_49-51.pdf')
```

### Remove thermometers 

Data contains 256 detectors, 248 are bolometers but 8 are thermometers. To compare with Qubic soft simulations, it is useful to remove thermometers.

```{python}
xdata, ydata, my_mask = flib.remove_thermometers(xTES, yTES, my_mask)

ndet = xdata.shape[0]
print('Number of detectors:', ndet)

data, error = [], []
for k in range(nimages):
    _, _, mydata = flib.remove_thermometers(xTES, yTES, allfringes[k])
    _, _, myerror = flib.remove_thermometers(xTES, yTES, allerr[k])
    data.append(mydata)
    error.append(myerror)


```

### Re-order data as simulations from Qubic soft
TES numbering on the instrument and in simulations are different. To compare the two, we re-order the data following simulation order.

```{python}
xONAFP, yONAFP, _ = scal.get_TEScoordinates_ONAFP(q)
the_mask = flib.reorder_data(my_mask, xdata, ydata, xONAFP, yONAFP)

fringes, errs = [], []
for k in range(nimages):
    fringes.append(flib.reorder_data(data[k], xdata, ydata, xONAFP, yONAFP))
    errs.append(flib.reorder_data(error[k], xdata, ydata, xONAFP, yONAFP))


# Check the re-ordering is correct, the 2 plots for each baseline should be identical.
vmin = None
vmax = None
for k in range(nimages):
    fig, axs = plt.subplots(1, 2, figsize=(12, 6))
    fig.suptitle(f'BL {BLs[k]}')
    fig.subplots_adjust(wspace=0.5)
    ax0, ax1 = axs
    flib.plot_fringes_scatter(q, xdata, ydata, data[k]*my_mask, 
                              normalize=False, vmin=vmin, vmax=vmax,
                              s=100, config='TD', fig=fig, ax=ax0,
                              title='Original order')
    
    flib.plot_fringes_scatter(q, xONAFP, yONAFP, fringes[k]*the_mask, 
                              normalize=False, vmin=vmin, vmax=vmax,
                              s=100, config='TD', fig=fig, ax=ax1,
                              title='Re-ordered')
```

### Make a mask per image for hot detectors

The median absolute deviation computes the median over the absolute deviations from the median. It is a measure of dispersion similar to the standard deviation but more robust to outliers.
$$MAD = median(|X_i - median(X)|)$$

```{python}
def mymedian_absolute_deviation(x):
    median = np.median(x)
    mad = np.median(np.abs(x-median))
    return mad

x = np.random.normal(0, 1., size=1000)
std = np.std(x)
mad = mymedian_absolute_deviation(x)
print(std, mad)

x[0] = 300
std = np.std(x)
mad = mymedian_absolute_deviation(x)
print(std, mad)
```

```{python}
allmask_hot = []
for i in range(nimages):
    mask_hot = np.ones_like(fringes[i])
    mad = mymedian_absolute_deviation(fringes[i])
    print(mad)
    for j, frin in enumerate(fringes[i]):
        if np.abs(frin) > 4*np.abs(mad):
            print(j)
            if np.isnan(the_mask[j]):
                print('deja mask')
            mask_hot[j] = np.nan
    allmask_hot.append(mask_hot)
```

```{python}
vmin = None
vmax = None
for k in range(nimages):
    fig, axs = plt.subplots(1, 2, figsize=(12, 6))
    fig.suptitle(f'BL {BLs[k]}')
    fig.subplots_adjust(wspace=0.5)
    ax0, ax1 = axs
    flib.plot_fringes_scatter(q, xONAFP, yONAFP, fringes[k]*the_mask, 
                                  normalize=False, vmin=vmin, vmax=vmax,
                                  s=100, config='TD', fig=fig, ax=ax0,
                                  title='Old mask')
    flib.plot_fringes_scatter(q, xONAFP, yONAFP, fringes[k]*allmask_hot[k]*the_mask, 
                                  normalize=False, vmin=vmin, vmax=vmax,
                                  s=100, config='TD', fig=fig, ax=ax1,
                                  title='new mask')
```

```{python}
#!!!!!!!!!!!!!!!!!! Cancel the mask
#for k in range(nimages):
 #   allmask_hot[k] = np.ones_like(allmask_hot[k])
```

```{python}
# !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
#ASIClist = [1, 1, 1, 1, 1, 1]
#TESlist = [40, 38, 16, 72, 70, 7]
#for i in range(len(ASIClist)):
 #   _, _, _, idx = scal.TES_Instru2coord(TESlist[i], ASIClist[i], q)
  #  the_mask[idx] = np.nan

```

### Make a selection
If you want to perform the fit on a reduce number of images, you can select them here.

```{python}
selection = True
if selection:
    myselection = [2, 5, 11]
    #myselection = [1, 2, 4, 5, 7, 8, 9, 10, 11]
    #myselection = [0, 1, 2, 4, 5, 11]
    remind_all_fringes = fringes.copy() 
    fringes = [fringes[i] for i in myselection]
    errs = [errs[i] for i in myselection]
    BLs = [BLs[i] for i in myselection]
    allmask_hot = [allmask_hot[i] for i in myselection]
    print('Selected baselines:', BLs)
    
nimages = len(BLs)
print(f'We will work with {nimages} images.')
```

#### Look once more at the data

```{python}
# Color map whith bad detectors in black
cmap_bwr = flib.make_cmap_nan_black('bwr')
cmap_red = flib.make_cmap_nan_black('Reds')

for k in range(nimages):
    fig, axs = plt.subplots(1, 2, figsize=(14, 6))
    fig.subplots_adjust(wspace=0.5)
    #fig.suptitle(f'k={k} - BL {BLs[k]}')
    fig.suptitle(f'Baseline [{BLs[k][0]}-{BLs[k][1]}]')
    ax0, ax1 = axs.ravel()
    
    # Scatter plot
    flib.plot_fringes_scatter(q, xONAFP, yONAFP, fringes[k] * allmask_hot[k]*the_mask, normalize=False, s=200, config='TD',
                              fig=fig, ax=ax0, title='Fringes', vmin=None, vmax=None)
    # Scatter plot
    flib.plot_fringes_scatter(q, xONAFP, yONAFP, errs[k] * allmask_hot[k]*the_mask, 
                              normalize=False, vmin=0, vmax=0.1, 
                              s=200, config='TD',
                              fig=fig, ax=ax1, title='Errors', cmap=cmap_red)
    fig.tight_layout()
    #plt.savefig(save_dir + f'fringes_plot_2020-10-27_BL{BLs[k][0]}-{BLs[k][1]}.pdf', bbox_inches='tight')
```

# Start fitting


#### Make fake data

This is only useful if you work with a simulation and not with real data.

```{python}
rep = Qubic_DataDir(datafile='detcentres.txt', datadir='/home/lmousset/QUBIC/')
print('rep:', rep)
```

```{python}
ndet = 248 
print('ndet:', ndet)

# Parameters for the fit
focal_fake = 0.327
theta_fake = np.deg2rad(0.)
#allP_fake = [0.5] * nimages
allP_fake = list(np.random.rand(nimages))
print('P_k fake:', allP_fake)
params_fake = [focal_fake, theta_fake] + allP_fake


# Gain for each TES (same for each image)
# gains_fake = np.ones(ndet)
gains_fake = np.random.rand(ndet) * 2 # Uniform distribution between 0 and 2
#gains_fake = np.random.normal(1., 1., size=ndet) # Gaussian distribution
gains_fake /= np.mean(gains_fake)
print('gain mean:', np.mean(gains_fake))
print('gains fake:', gains_fake[:10])
print('gains negative:', gains_fake[gains_fake<0.])

sigma = 0.08 # Gaussian noise

fake_fringes = []
allPhi_fake = []
d['focal_length'] = focal_fake
q = qubic.QubicInstrument(d)
for k in range(nimages):
    model_fake_data = scal.Model_Fringes_Ana(q, BLs[k], 
                                            theta_source=theta_fake, 
                                           nu_source=150e9,
                                          frame='ONAFP')
    #model_fake_data = scal.Model_Fringes_Maynooth(q, BLs[k], 
     #                                             rep=rep,
      #                                           theta_source=theta_fake, 
       #                                          nu_source=150e9,
        #                                         frame='ONAFP')

    x, y, Phi = model_fake_data.get_fringes(times_gaussian=False)
    #x, y, Phi = model_fake_data.get_fringes()
    allPhi_fake.append(Phi)
    
    # Multiply by a global amplitude (Calibration source power)
    fake_P = Phi * allP_fake[k]
    
    # Gain
    fake_gain = fake_P * gains_fake
    
    # Add gaussian noise
    noise = np.random.normal(loc=0., scale=sigma, size=ndet)
    print('Gaussian noise:', noise[:10])
    fake_noise = fake_gain + noise
    
    fake_fringes.append(fake_noise)
    
    fig, axs = plt.subplots(2, 2, figsize=(12, 12))
    fig.subplots_adjust(wspace=0.5)
    ax0, ax1, ax2, ax3 = np.ravel(axs)
    scal.scatter_plot_FP(q, xONAFP, yONAFP, Phi, frame='ONAFP', 
                         fig=fig, ax=ax0, title='Pure fringes', unit=None, s=50, cmap='bwr', config='TD')
    scal.scatter_plot_FP(q, xONAFP, yONAFP, fake_P, frame='ONAFP', 
                         fig=fig, ax=ax1, title='Fringes x Power', unit=None, s=50, cmap='bwr', config='TD')
    scal.scatter_plot_FP(q, xONAFP, yONAFP, fake_gain, frame='ONAFP', 
                         fig=fig, ax=ax2, title='With Gains', unit=None, s=50, cmap='bwr', config='TD')
    scal.scatter_plot_FP(q, xONAFP, yONAFP, fake_noise, frame='ONAFP',
                         fig=fig, ax=ax3, title='Adding noise', unit=None, s=50, cmap='bwr', config='TD')

if simu:
    fringes = fake_fringes
    errs = list(np.ones_like(fake_fringes) * sigma)
```

#### Look at the data once more compared to simu

```{python}
for k in [2]:#range(nimages):
    fig, axs = plt.subplots(1, 3, figsize=(14, 4))
    fig.subplots_adjust(wspace=0.5)
    #fig.suptitle(f'k={k} - BL {BLs[k]}')
    fig.suptitle(f'Baseline [{BLs[k][0]}-{BLs[k][1]}]')
    ax0, ax1, ax2 = axs.ravel()
    
    #Simu
    flib.plot_fringes_scatter(q, xONAFP, yONAFP, allPhi_fake[k], 
                         normalize=True, vmin=-1, vmax=1,
                         fig=fig, ax=ax0, title='Simulation', s=60, cmap='bwr', config='TD')
    
    # Data
    flib.plot_fringes_scatter(q, xONAFP, yONAFP, fringes[k] * allmask_hot[k]*the_mask, 
                              normalize=False, 
                              s=60, config='TD',
                              fig=fig, ax=ax1, title='Data', vmin=-0.4, vmax=0.4)
    # Error
    flib.plot_fringes_scatter(q, xONAFP, yONAFP, errs[k] * allmask_hot[k]*the_mask, 
                              normalize=False, vmin=0, vmax=0.1, 
                              s=60, config='TD',
                              fig=fig, ax=ax2, title='Errors', cmap=cmap_red)
    fig.tight_layout()
    plt.savefig(save_dir + f'fringes_plot_2020-10-27_BL{BLs[k][0]}-{BLs[k][1]}.pdf', bbox_inches='tight')
```

```{python}
fig, axs = plt.subplots(1, 3, figsize=(14, 4))
fig.subplots_adjust(wspace=0.5)
#fig.suptitle(f'k={k} - BL {BLs[k]}')
fig.suptitle(f'Simulations')
axs = axs.ravel()
for k in range(nimages): 
    #Simu
    flib.plot_fringes_scatter(q, xONAFP, yONAFP, allPhi_fake[k], 
                         normalize=True, vmin=-1, vmax=1,
                         fig=fig, ax=axs[k], title=f'Baseline [{BLs[k][0]}-{BLs[k][1]}]', s=60, cmap='bwr', config='TD')
fig.tight_layout()
plt.savefig(save_dir + f'fringes_plot_simu.pdf', bbox_inches='tight')
```

#### Covariance matrix of the noise

To eliminate bad TES, we put a very high error on them => very small weight in the fit.

Then we make a list with an inverse covariance matrix for each image.

```{python}
allInvCov = []
for k in range(nimages):
    errs[k][np.isnan(the_mask)] *= 1e20 # Mask global to all images
    errs[k][np.isnan(allmask_hot[k])] *= 1e20 # Hot detector mask

    allInvCov.append(scal.make_inverse_covariance(errs[k], verbose=True))
```

#### Explore the chi2 to find guess parameters

```{python}
def myget_gains(allPowerPhi, allInvCov, allData):
    """
    Compute a gain for each detector analytically.
    Parameters
    ----------
    allPowerPhi: list
        List with fringes models Phi multiply by a global power P.
    allInvCov: list
        List with the inverse covariance matrices, one for each image.
    allData: list
        List with the fringe images.
    Returns
    -------
    Gains A and their covariance matrix Cov_A, normalized such as <A> = 1.
    """
    # Number of fringe images
    nimages = len(allPowerPhi)

    InvCov_A = np.zeros_like(allInvCov[0])
    Term = np.zeros_like(allData[0])
    for k in range(nimages):
        print('\n', k)
        # Make a diagonal matrix
        PowerPhi_mat = np.diag(allPowerPhi[k])

        InvCov_A += PowerPhi_mat.T @ allInvCov[k] @ PowerPhi_mat
        print('Alldata', np.any(np.isnan(allData[k])))
        print('PowerPhimat', np.any(np.isnan(PowerPhi_mat)))
        print('allInvCov[k]', np.any(np.isnan(allInvCov[k])))
        Term += PowerPhi_mat.T @ allInvCov[k] @ allData[k]
        print('Term', Term, np.any(np.isnan(Term)))
    Cov_A = np.linalg.inv(InvCov_A)
    print('CovA', Cov_A, np.any(np.isnan(Cov_A)))

    A = Cov_A @ Term
    print('A', A, np.any(np.isnan(A)))

    # Normalization
    weights = 1 / np.diag(Cov_A) # To cancel bad detectors
    avgA = np.average(A, weights=weights) # Weighted mean
    A /= avgA
    Cov_A /= avgA ** 2

    return A, Cov_A

def myget_chi2(params, allInvCov, allData, BLs, q, nu_source=150e9, returnA=False):
    """
    Compute the Chi^2 for a list of fringe images (several baselines) and a model M.
    M_k = P_k Phi_k(focal, source angle) @ A
    where k is the image index, P_k a global power, Phi_k the fringes model given by Model_Fringes_Ana
    and A contains the gains of the detectors.
    For now, we use the analytical model but it could be adapted to a more complex model (QubicSoft or Maynooth).

    Parameters
    ----------
    params: list
        Focal length, source off-axis angle, log_10 of global powers P_k
    allInvCov: list
        List with the inverse covariance matrices, one for each image.
    allData: list
        List with the fringe images.
    BLs: list
        List of the baselines, for example [25, 57] is one baseline.
    q: a Qubic instrument
    nu_source: float
        Frequency of the calibration source
    returnA: bool
        If True, it will return the detector gains and their covariance.

    Returns
    -------
    The Chi^2.
    """

    nimages = len(BLs)
    focal = params[0]
    theta_source = params[1]
    logP = params[2:]
    q.optics.focal_length = focal
    allPowerPhi = []
    for k in range(nimages):
        model = scal.Model_Fringes_Ana(q,
                                  BLs[k],
                                  theta_source=theta_source,
                                  nu_source=nu_source)

        x, y, Phi = model.get_fringes(times_gaussian=False)

        # Global amplitude
        allPowerPhi.append(Phi * 10**logP[k])

    # Gain for each detector
    A, Cov_A = myget_gains(allPowerPhi, allInvCov, allData)

    chi2 = 0.
    for k in range(nimages):
        # Compute the chi2
        M = np.diag(allPowerPhi[k]) @ A
        R = M - allData[k]
        chi2 += R.T @ allInvCov[k] @ R

    if returnA:
        return chi2, A, Cov_A
    else:
        return chi2
    
    
def mymake_chi2_grid(allInvCov, fringes, BLs, q, nval_fl=30, nval_th=30, fl_min=0.25, fl_max=0.35,
                   th_min=np.deg2rad(-1.), th_max=np.deg2rad(1), LogPower=-1, fixPower=True):
    """Loop over the parameters (focal length and source off-axis angle) to explore the chi2.
    Global powers are fixed to Log_10(Power)=-1 or optimized at each step by minimizing a temporary chi2 (longer)."""
    nimages = len(BLs)
    chi2_grid = np.zeros((nval_fl, nval_th))

    all_fl = np.linspace(fl_min, fl_max, nval_fl)
    all_th = np.linspace(th_min, th_max, nval_th)

    # Fast method
    if fixPower:
        # Global powers are fixed to initPower and we loop on fl and th.
        for i, fl in enumerate(all_fl):
            for j, th in enumerate(all_th):
                params = [fl, th] + [LogPower] * nimages
                chi2_grid[i, j] = myget_chi2(params, allInvCov, fringes, BLs, q)
        return all_fl, all_th, chi2_grid

    # Slow method but more rigorous
    else:
        # Loop on fl and th and at each step, minimize the chi2 to find the best global powers.
        power_optimize = np.zeros((nval_fl, nval_th, nimages))
        step = 0
        for i, fl in enumerate(all_fl):
            for j, th in enumerate(all_th):
                print(fl, th)
                def chi2_temporary(mypower, allInvCov, fringes, BLs, q):
                    params = [fl, th] + list(mypower)
                    chi2_temp = scal.get_chi2(params, allInvCov, fringes, BLs, q)
                    return chi2_temp

                bounds = [[-8, 1] ]* nimages
                print(bounds)
                
                result = sop.minimize(chi2_temporary,
                                      x0=[LogPower] * nimages,
                                      args=(allInvCov, fringes, BLs, q),
                                      method='L-BFGS-B', bounds=bounds,
                                      options={'maxiter': 500})
                chi2_grid[i, j] = result['fun']
                power_optimize[i, j, :] = result['x']
                
                print(f'\n***Step {step + 1}/{nval_fl * nval_th}')
                print('Chi2 min:', result['fun'])
                print('with powers =', result['x'])
                print(result)
                step += 1
        return all_fl, all_th, chi2_grid, power_optimize

```

```{python}
all_fl, all_th, chi2_grid = mymake_chi2_grid(allInvCov, fringes, BLs, q, 
                                   nval_fl=3, nval_th=3, 
                                   fl_min=0.25, fl_max=0.35,
                                   th_min=np.deg2rad(-1), th_max=np.deg2rad(1), 
                                   LogPower=-1,
                                   fixPower=True)

```

```{python}
print(np.log10(allP_fake), 0.5*np.pi/180)
```

```{python}
all_fl, all_th, chi2_grid, popt = mymake_chi2_grid(allInvCov, fringes, BLs, q, 
                                 nval_fl=10, nval_th=10, 
                                 fl_min=0.25, fl_max=0.35,
                                 th_min=np.deg2rad(-1), th_max=np.deg2rad(1), 
                                 LogPower=-1,
                                 fixPower=False)
```

```{python}
# Smooth with a gaussian to avoid loosing the min in random pixel very low (not always necessary).
smooth = False
step_fl = all_fl[1] - all_fl[0]
step_th = all_th[1] - all_th[0]
if smooth:
    chi2_grid = gaussian_filter(chi2_grid, sigma=[step_fl*2e3, step_th*2e3])
```

```{python}
# Find the min and take it as a guess for the following
min_indices = np.unravel_index(np.argmin(chi2_grid), chi2_grid.shape)
print(f'Chi2 min = {np.min(chi2_grid)} at {min_indices}')

fl_guess = all_fl[min_indices[0]]
th_guess = all_th[min_indices[1]]
allP_guess = list(popt[min_indices[0], min_indices[1], :])

#allP_guess = [0.5] * nimages


params_guess = [fl_guess, th_guess] + allP_guess

print('Guess:', params_guess)
if simu:
    print('Fake:', params_fake)
```

```{python}
# Plot the chi2 map 
def plot_chi2_map(all_th, all_fl, chi2_grid,
                  vmin=0, vmax=1e10, norm=None, 
                  thetas=[], focals=[], labels=[]):
    fig, ax = plt.subplots(figsize=(8, 8))
    colorlist = ['orange', 'r', 'g', 'y']
    c = ax.pcolor(np.rad2deg(all_th), all_fl, chi2_grid, vmin=vmin, vmax=vmax, shading='auto', norm=norm)
    for i in range(len(thetas)):
        ax.scatter(np.rad2deg(thetas[i]), focals[i],  marker='o', color=colorlist[i], s=100, label=labels[i])
    ax.set_xlabel(r'Angle $\theta$ [deg]', fontsize=16)
    ax.set_ylabel(r'Focal length $f$ [m]', fontsize=16)
    clb = fig.colorbar(c, ax=ax)
    clb.ax.set_title(r'$\chi^2$')
    ax.legend()
    
    return

if simu:
    plot_chi2_map(all_th, all_fl, chi2_grid,
                  vmin=0, vmax=8e3, norm=None,
                  thetas=[th_guess, theta_fake], 
                  focals=[fl_guess, focal_fake], 
                  labels=['Minimum', 'Input data'])
    #plt.savefig(save_dir + 'chi2_map_simu.pdf', bbox_inches='tight')
else:
    plot_chi2_map(all_th, all_fl, chi2_grid,
                  vmin=0, vmax=3e4, norm=None,
                  thetas=[th_guess], 
                  focals=[fl_guess], 
                  labels=['Minimum'])

```

```{python}
th_source = th_guess
q.optics.focal_length = fl_guess

PowerPhi = []
for k in range(nimages):
    model = scal.Model_Fringes_Ana(q, BLs[k], 
                                   theta_source=th_source, 
                                   nu_source=150e9, 
                                   frame='ONAFP')
    

    x, y, Phi = model.get_fringes(times_gaussian=False)
    # Global amplitude
    PowerPhi.append(Phi * allP_guess[k])
    

# Gain for each detector
A, Cov_A = scal.get_gains(PowerPhi, allInvCov, fringes)

print('Gains found:\n', np.round(A[:10], 4))
print('Diagonal Cov_A:\n', np.diag(Cov_A[:10]))
if simu:
    print('\nGains fake:\n', np.round(gains_fake[:10], 4))
```

```{python}
def make_colorbar(ax, image):
    divider = make_axes_locatable(ax)
    cax = divider.append_axes('right', size='5%', pad=0.05)
    clb = fig.colorbar(image, cax=cax)
    return

def get_pull(data, errors, gains, PowerPhi, mask):
    
    #mydata = np.copy(data)
    #if mask is not None:
     #   mydata *= mask
    correct = data/gains
    residu = correct - PowerPhi
    # Compute the pull only on unmasked detectors
    pull = residu[~np.isnan(mask)] / (errors[~np.isnan(mask)] /gains[~np.isnan(mask)] )
    
    return correct, residu, pull
    
def plot_residuals(q, xONAFP, yONAFP, BL, data, the_mask, PowerPhi, errors, gains, cmap='bwr', 
                   normalize=True, vmin=-1, vmax=1, s=120, save_plot=False, title='Fringes_corrected.pdf'):
    """Make all plots, data, correction, residuals, model...
    1D plots can only work with diagonal fringes."""
    
    # Orientation of the baseline
    theta, _, _ = scal.give_bs_pars(q, BL)
    if int(theta)== -45:
        anti_diag = True
    else:
        anti_diag = False
    print(int(theta))
    
    # Compute residuals, pull and mask the data
    correct, residu, pull = get_pull(data, errors, gains, PowerPhi, mask=the_mask)
    
    fig, axs = plt.subplots(2, 2, figsize=(12, 8))
    fig.suptitle(f'Baseline {BL}')
    axs = np.ravel(axs)
    
    # Initial / corrected 
    flib.plot_fringes_scatter(q, xONAFP, yONAFP, data*the_mask, 
                              fig=fig, ax=axs[0], cmap=cmap, title=r'Data $D_k$', s=s, 
                              normalize=normalize, vmin=vmin, vmax=vmax, config='TD')

    flib.plot_fringes_scatter(q, xONAFP, yONAFP, correct*the_mask, 
                              fig=fig, ax=axs[1], cmap=cmap, title=r'Corrected data $D_k / A$', s=s, 
                              normalize=normalize, vmin=vmin, vmax=vmax, config='TD')
    
    # Plot fringes and corrected fringes in 1D diagonal
#     data2D = flib.make2Dfringes_QubicSoft(data, q, nan2zero=True)
#     flib.plot_fringes_diagonal(data2D, idiag=[-3, -4, -2, -1, 0, 1, 2, 3, 4], anti_diag=anti_diag,
#                           fig=fig, ax=axs[2], ylim=(-0.2, 0.2), title='Data')
    
#     correct2D = flib.make2Dfringes_QubicSoft(correct, q, nan2zero=True)
#     flib.plot_fringes_diagonal(correct2D, idiag=[-3, -4, -2, -1, 0, 1, 2, 3, 4], anti_diag=anti_diag, 
#                           fig=fig, ax=axs[3], ylim=(-0.2, 0.2), title='Data / gains')
        
    # Fit
    flib.plot_fringes_scatter(q, xONAFP, yONAFP, PowerPhi*the_mask,
                              fig=fig, ax=axs[2], cmap=cmap, title=r'Fit $P_k \times \Phi_k$', s=s,
                              normalize=normalize, vmin=vmin, vmax=vmax, config='TD')
    
    # Residuals
    flib.plot_fringes_scatter(q, xONAFP, yONAFP, residu*the_mask,
                             fig=fig, ax=axs[3], cmap=cmap, title=r'Residuals $R = D_k / A - P_k \times \Phi_k$', s=s,
                             normalize=False, vmin=-0.1, vmax=0.1, config='TD')
    
    # Plot model and residuals 1D diagonal
#     PowerPhi2D = flib.make2Dfringes_QubicSoft(PowerPhi, q, nan2zero=True)
#     flib.plot_fringes_diagonal(PowerPhi2D, idiag=[-3, -4, -2, -1, 0, 1, 2, 3, 4], anti_diag=anti_diag,
#                           fig=fig, ax=axs[6], title='Fit')
    
#     residu2D = flib.make2Dfringes_QubicSoft(residu, q, nan2zero=True)
#     flib.plot_fringes_diagonal(residu2D, idiag=[-3, -4, -2, -1, 0, 1, 2, 3, 4], anti_diag=anti_diag,
#                           fig=fig, ax=axs[7], ylim=(-0.2, 0.2), title='Residuals')
    fig.tight_layout()
    if save_plot:
        plt.savefig(title, bbox_inches='tight')
    return

def plot_pull(BL, pull, therange=(-3, 3), bins=20, title='Pull.pdf', fig=None, ax=None):
    
    if fig is None:
        fig = plt.figure(figsize=(6, 4))
        ax = plt.gca()

    mean_pull = np.nanmean(pull)
    std_pull = np.nanstd(pull)
    ax.hist(pull, range=therange, bins=bins)
    ax.axvline(mean_pull, color='r', label=fr'$ \mu \pm \sigma = {mean_pull:.3f} \pm {std_pull:.3f}$')
    ax.axvline(mean_pull+std_pull, color='r', linestyle='--')
    ax.axvline(mean_pull-std_pull, color='r', linestyle='--')
    ax.set_title(f'Baseline {BL}')
    ax.set_xlabel('Pull')
    ax.set_ylabel('Count')
    ax.set_ylim(0, 50)
    ax.legend()
    
    fig.tight_layout()
    return
    
def plot_hist_residuals(BL, correct, residu):
    
    ig = plt.figure(figsize=(6, 4))
    ax = plt.gca()
    fig.suptitle(f'BL {BL}')
    
    # Histogram Data/Gain and Residuals
    ax.hist(correct*the_mask, bins=20, alpha=0.2, label='Data/Gain', range=(-0.3, 0.3))
    ax.hist(residu*the_mask, bins=20, alpha=0.2, label='Residuals', range=(-0.3, 0.3))
    ax.legend()
    ax.set_title(f'STD(data/gain) / STD(Residus) = {np.nanstd(correct/residu):.3f}')
    fig.tight_layout()
    return
```

```{python}
cmap_bwr=flib.make_cmap_nan_black('bwr')
allmean_pull, allstd_pull = [], []
for k in range(nimages):
    BL = BLs[k]
    plot_residuals(q, xONAFP, yONAFP, BL, fringes[k], the_mask*allmask_hot[k], PowerPhi[k], errs[k], A, 
                   cmap=cmap_bwr, normalize=False, vmin=None, vmax=None, s=60, 
                   save_plot=False, title=save_dir + f'fringes_corrected_minuit_BL{BL[0]}-{BL[1]}.pdf')
    
    correct, residu, pull = get_pull(fringes[k], errs[k], A, PowerPhi[k], mask=the_mask*allmask_hot[k])
    allmean_pull.append(np.mean(pull))
    allstd_pull.append(np.std(pull))
    
    plot_pull(BL, pull, therange=(-2000, 2000))
    plot_hist_residuals(BLs[k], correct, residu)
    
print(allstd_pull)
```

## Minimize the chi2 

Using `scipy.optimize.minimize`

```{python}
# params_guess = [0.30, np.deg2rad(-0.5)] + [0.5]*3
# result = sop.minimize(scal.get_chi2, 
#                       x0=params_guess, 
#                       args=(allInvCov, fringes, BLs, q), 
#                       method='Nelder-Mead',
#                       options={'maxiter':10000})
# print(result)
```

#### Using iMinuit

We can change:
   * the guess
   * fix: fix parameters to a given value
   * error: the step it moves around the parameter during minimization
   * limit: bounds for the parameters (ex: focal and Pk positive)

```{python}
params_guess_grid = params_guess.copy()
params_guess_grid
```

```{python}
def chi2_minuit(params):
    chi2 = scal.get_chi2(params, allInvCov, fringes, BLs, q, nu_source=150e9, returnA=False)
    return chi2

# Choose a guess by hand
#params_guess = [0.3, np.deg2rad(0.4)] + [-3] * nimages
params_guess = params_guess_grid  
# Initialize iMinuit
m = Minuit.from_array_func(chi2_minuit, 
                           params_guess, 
                           errordef=1, print_level=2,
                           error=[2e-2, np.deg2rad(0.2)] + [0.1] * nimages,
                           fix=[False, False] + [False]*(nimages),
                           limit=[(0.25, 0.35), (np.deg2rad(-2), np.deg2rad(2))] + [(-5, 1)] * nimages)
# Run the minimization
m.migrad()
```

```{python}
# Get the parameters
chi2_Minuit = m.fcn(m.np_values())

fl_minuit = m.np_values()[0]
th_minuit = m.np_values()[1]
LogPk_minuit = m.np_values()[2:]
Pk_minuit = 10**(LogPk_minuit)

print('***** Focal:')
print('Result:', fl_minuit)
print('Guess:', params_guess[0])
if simu:
    print('Fake:', focal_fake)
    print('Fake / Result:', focal_fake/fl_minuit)

print('\n***** Theta:')
print('Result:', np.round(np.rad2deg(th_minuit), 6))
print('Guess:', np.round(np.rad2deg(params_guess[1]), 6))
if simu:
    print('Fake:', np.rad2deg(theta_fake))
    print('Fake/Result:', np.rad2deg(theta_fake) / np.rad2deg(th_minuit) )

print('\n***** Power Pk:')
print('Guess:', [10**a for a in params_guess[2:]])
print('Result:', Pk_minuit)
if simu:
    print('Fake:', np.round(allP_fake, 4))
    print('Fake/Result:', np.round(allP_fake / Pk_minuit, 4))

NDDL = nimages * ndet - (ndet + nimages + 2)
print('\nReduce Chi2:', chi2_Minuit / NDDL)
```

```{python}
# scal.get_chi2([0.3, np.deg2rad(0.5), 1.6e-4, 2.6e-2], allInvCov, fringes, BLs, q, nu_source=150e9, returnA=True)
```

```{python}
fl_guess = params_guess[0]
th_guess = params_guess[1]
if simu:
    plot_chi2_map(all_th, all_fl, chi2_grid,
                  vmin=0, vmax=5e4, norm=None,
                  thetas=[th_guess, theta_fake, th_minuit], 
                  focals=[fl_guess, focal_fake, fl_minuit], 
                  labels=['Guess', 'Fake', 'Minuit'])
else:
    plot_chi2_map(all_th, all_fl, chi2_grid,
                  vmin=0, vmax=5e4, norm=None,
                  thetas=[th_guess, th_minuit], 
                  focals=[fl_guess, fl_minuit], 
                  labels=['Guess', 'Minuit'])
```

#### Get the intercalibrations
We compute the detector gains using the result of the minimisation.

```{python}
# Using minimize
# th_source = result['x'][1]
# q.optics.focal_length = result['x'][0]
# allP_res = result['x'][2:]

#Using Minuit
th_source = th_minuit
q.optics.focal_length = fl_minuit

PowerPhi = []
for k in range(nimages):
    model = scal.Model_Fringes_Ana(q, BLs[k], 
                                   theta_source=th_source, 
                                   nu_source=150e9, 
                                   frame='ONAFP')

    x, y, Phi = model.get_fringes(times_gaussian=False)
    
    # Global amplitude
    PowerPhi.append(Phi * Pk_minuit[k])
    

# Gain for each detector
A, Cov_A = scal.get_gains(PowerPhi, allInvCov, fringes)

print('Gains found:\n', np.round(A[:10], 4))
print('Diagonal Cov_A:\n', np.diag(Cov_A[:10]))
if simu:
    print('\nGains fake:\n', np.round(gains_fake[:10], 4))
    
plt.figure(figsize=(12, 6))
plt.errorbar(x=np.arange(ndet), y=A, yerr=np.sqrt(np.diag(Cov_A)), fmt='o')
plt.errorbar(x=np.arange(ndet)[np.isnan(the_mask)], y=A[np.isnan(the_mask)], 
             yerr=np.sqrt(np.diag(Cov_A))[np.isnan(the_mask)],
             fmt='o', color='k')
plt.ylim(-20, 20)
plt.xlabel('Detector index')
plt.ylabel('Gains')
plt.grid()
```

```{python}
# Average A, it should be 1
weights = 1/np.diag(Cov_A)
avgA = np.average(A, weights=weights)
print(avgA)

print('Max A', np.nanmax(A*the_mask))
print('Min A', np.nanmin(A*the_mask))

# print(np.sort(A*the_mask))
```

```{python}
if simu:
    fig, axs = plt.subplots(2, 2, figsize=(12, 8))
    ax1, ax2, ax3, ax4 = np.ravel(axs)
    fig.subplots_adjust(wspace=0.4)
    scal.scatter_plot_FP(q, xONAFP, yONAFP, gains_fake, fig=fig, ax=ax1, frame='ONAFP', title='Gains fake', 
                         unit=None, vmin=None, vmax=None, s=50, cmap='bwr', config='TD')
    scal.scatter_plot_FP(q, xONAFP, yONAFP, A, fig=fig, ax=ax2, frame='ONAFP', title='Gains found', 
                         unit=None, vmin=None, vmax=None, s=50, cmap='bwr', config='TD')
    scal.scatter_plot_FP(q, xONAFP, yONAFP, A-gains_fake, fig=fig, ax=ax3, frame='ONAFP', title='Residuals', 
                         unit=None, vmin=None, vmax=None, s=50, cmap='bwr', config='TD')
    mean = np.mean(A-gains_fake)
    std = np.std(A-gains_fake)
    ax4.hist(A-gains_fake, range=(-1, 1), bins=30)
    ax4.axvline(mean, color='r')
    ax4.axvline(mean+std, color='r', linestyle='--')
    ax4.axvline(mean-std, color='r', linestyle='--')
    ax4.set_title(f'Residuals: {mean:.3f} +- {std:.3f}')
    fig.tight_layout()
else:

    fig, axs = plt.subplots(1, 2, figsize=(13, 4))
    ax1, ax2 = np.ravel(axs)
    flib.plot_fringes_scatter(q, xONAFP, yONAFP, A*the_mask, 
                              fig=fig, ax=ax1, title='Gains found', 
                              vmin=-10, vmax=10, normalize=False,
                              s=50, config='TD')
    
    ax2.hist(A*the_mask, bins=30, range=(-100, 100))
    ax2.set_xlabel('Gains found')
    ax2.axvline(avgA, color='r', label=f'Mean = {avgA:.3f}')
    ax2.legend()
    fig.tight_layout()
```

```{python}
if simu:
    fig, axs = plt.subplots(1, 2, figsize=(12, 6))
    ax1, ax2 = np.ravel(axs)

    ax1.errorbar(gains_fake, A, yerr=np.sqrt(np.diag(Cov_A)), fmt='o', color='b')
    # ax2.plot(gains_fake, A, 'b.')
    ax1.plot(gains_fake, gains_fake, 'r', label='y=x')
    ax1.set_ylim(-1, 5)
    ax1.set_xlim(0, 2)
    #ax1.axis('square')
    ax1.set_xlabel(r'$A_d$ input data', fontsize=16)
    ax1.set_ylabel(r'$A_d$ iminuit result', fontsize=16)
    ax1.legend()
    
    mean = np.mean(A-gains_fake)
    std = np.std(A-gains_fake)
    ax2.hist(A - gains_fake, range=(-1, 1), bins=20)
    ax2.axvline(mean, color='r', label=fr' $\mu \pm \sigma={mean:.3f} \pm {std:.3f}$')
    ax2.axvline(mean+std, color='r', linestyle='--')
    ax2.axvline(mean-std, color='r', linestyle='--')
    ax2.set_xlabel(f'$A_d$ residuals', fontsize=16)
    ax2.set_ylabel('Counts', fontsize=16)
    ax2.set_ylim(0, 90)
    ax2.legend(loc='upper left')
    
    fig.tight_layout()
    #fig.savefig(save_dir + 'gains_iminuit_simu.pdf', bbox_inches='tight')
```

#### Residuals and correction by intercalibrations (gains)

```{python}
cmap_bwr=flib.make_cmap_nan_black('bwr')
allmean_pull, allstd_pull = [], []
for k in range(nimages):
    BL = BLs[k]
    plot_residuals(q, xONAFP, yONAFP, BL, fringes[k], the_mask*allmask_hot[k], PowerPhi[k], errs[k], A, 
                   cmap=cmap_bwr, normalize=True, vmin=-1, vmax=1, s=60, 
                   save_plot=False, title=save_dir + f'fringes_corrected_minuit_BL{BL[0]}-{BL[1]}.pdf')
    
    correct, residu, pull = get_pull(fringes[k], errs[k], A, PowerPhi[k], mask=the_mask*allmask_hot[k])
    allmean_pull.append(np.mean(pull))
    allstd_pull.append(np.std(pull))
    
    plot_pull(BL, pull, therange=(-10, 10))
    plot_hist_residuals(BLs[k], correct, residu)
    
print(allstd_pull)
```

### Correct the errors to have std(Pull) = 1

```{python}
#condition = np.any([np.abs(i - 1) > 0.5 for i in allstd_pull])
#condition
```

```{python}
i = 0
while condition:
    i += 1
    print(f'\n***** Run {i} ************* STD Pull:', allstd_pull)
    # Correction a posteriori (bidouille to have STD(Pull) = 1)
    allInvCov = []
    for k in range(nimages):
        errs[k] *= allstd_pull[k]
        allInvCov.append(scal.make_inverse_covariance(errs[k], verbose=False))

    # Minimization
    m = Minuit.from_array_func(chi2_minuit, 
                               params_guess, 
                               errordef=1, print_level=2,
                               error=[2e-3, np.deg2rad(0.01)] + [0.001] * nimages,
                               fix=[False]*(nimages+2),
                               limit=[(None, None), (None, None)] + [(None, None)] * nimages)
    m.migrad()
    fl_minuit = m.np_values()[0]
    th_minuit = m.np_values()[1]
    Pk_minuit = 10**(m.np_values()[2:])

    #Using Minuit
    th_source = th_minuit
    q.optics.focal_length = fl_minuit

    PowerPhi = []
    for k in range(nimages):
        model = scal.Model_Fringes_Ana(q, BLs[k], 
                                       theta_source=th_source, 
                                       nu_source=150e9, 
                                       frame='ONAFP')

        x, y, Phi = model.get_fringes(times_gaussian=False)

        # Global amplitude
        PowerPhi.append(Phi * Pk_minuit[k])


    # Gain for each detector
    A, Cov_A = scal.get_gains(PowerPhi, allInvCov, fringes)

    print('Gains found:\n', np.round(A[:10], 4))
    print('Diagonal Cov_A:\n', np.diag(Cov_A[:10]))
    if simu:
        print('\nGains fake:\n', np.round(gains_fake[:10], 4))


    cmap_bwr=flib.make_cmap_nan_black('bwr')
    allmean_pull, allstd_pull = [], []
    for k in range(nimages):
        _, _, pull = get_pull(fringes[k], errs[k], A, PowerPhi[k])
        allmean_pull.append(np.mean(pull))
        allstd_pull.append(np.std(pull))
    
    condition = np.any([np.abs(i - 1) > 0.5 for i in allstd_pull])

for k in range(nimages):
    plot_residuals(q, xONAFP, yONAFP, BLs[k], fringes[k], the_mask, PowerPhi[k], errs[k], A, 
                   cmap=cmap_bwr, s=60, normalize=True, vmin=-1, vmax=1)

```

### Correct images not used by the intercalibrations

```{python}
not_used = list(np.arange(12))
for i in myselection[::-1]:
    del not_used[i]
print(myselection, not_used)
```

```{python}
if selection:
    fringes_not_used = [remind_all_fringes[i] for i in not_used]
    
    for k in range(len(not_used)):
        bl = fdict['BLS'][not_used[k]]
        correct = fringes_not_used[k] / A

        fig, axs = plt.subplots(1, 2)
        fig.suptitle(f'BL {bl}')
        flib.plot_fringes_scatter(q, xONAFP, yONAFP, fringes_not_used[k]*the_mask, fig=fig, ax=axs[0], frame='ONAFP', 
                         title=f'Data', s=190, normalize=True)
        flib.plot_fringes_scatter(q, xONAFP, yONAFP, correct*the_mask, fig=fig, ax=axs[1], frame='ONAFP', 
                         title=f'Data / gains', s=190, normalize=True)
        fig.tight_layout()
```

## MCMC

To get errors on the focal length, theta and P_k.

```{python}
os.environ["OMP_NUM_THREADS"] = "1"

ncpu = cpu_count()
print("{0} CPUs".format(ncpu))
```

```{python}
from qubic.mcmc import MCMC

def lnlike(params, allInvCov, alldata, BLs):
    chi2, A, _ = scal.get_chi2(params, allInvCov, alldata, BLs, q, returnA=True)
    LnLike = - 0.5 * chi2
#     print('A:', A[:20])
    print('chi2:', chi2)
    return LnLike, A

def lnprior(params, bounds):   
    in_bounds = True
    for npar, par in enumerate(params):
        if par < bounds[npar][0] or par > bounds[npar][1]:
            in_bounds = False
            break
    if in_bounds:
        return 0.
    return -np.inf
    

def lnprob(params, allInvCov, alldata, BLs, bounds):
    lp = lnprior(params, bounds)
    #print('Prior', lp)
    ndet = alldata[0].shape[0]
    if not np.isfinite(lp):
        return -np.inf, np.ones(248)*(-np.inf)
    LnLike, A = lnlike(params, allInvCov, alldata, BLs)
    #print(LnLike)
    return lp + LnLike, A

```

```{python}
#params_guess = [fl_minuit, th_minuit] + list(LogPk_minuit)
#params_guess = [0.3, np.deg2rad(0.)] + [-3] * nimages
params_guess = params_guess_grid
print('Guess:', params_guess)

```

```{python}
ndim = len(params_guess)
nwalkers = 40

# Initial guess
p0 = [params_guess + 1e-2 * np.random.rand(ndim) for i in range(nwalkers)]
# print(p0)

niter = 30005
axis_names = [r'f', 'Theta'] + [f'LogP{i+1}' for i in range(nimages)]

#mcmc = MCMC(nwalkers, niter, ndim, p0, burnin=600, axis_names=axis_names, withpool=False, 
 #           emcee_filename='MCMC_simu_BL2-5-11.h5')
#bounds = [[-np.inf, +np.inf]] * (nimages +2) # No bounds

#!!!!!!! Celui qui a marché sur les données
mcmc = MCMC(nwalkers, niter, ndim, p0, burnin=5000, axis_names=axis_names, withpool=False, 
            emcee_filename='newmask_img2-5-11_v7.h5')
bounds = [[0.25, 0.35], [np.deg2rad(-2), np.deg2rad(2)]] + [[-5, 1]]*nimages

args = (allInvCov, fringes, BLs, bounds)
```

```{python}
# Run the MCMC and save a backend
sampler = mcmc.run(lnprob, args, backend=True)
```

```{python}
mcmc.read_backends()
chain_validity = mcmc.set_chain_validity()
print(np.sum(chain_validity))
```

```{python}
mcmc.plot_chains_chi2()
```

```{python}
mcmc.convergence_tests(xlim=(mcmc.burnin, 4400))
```

```{python}
chi2_reduce = mcmc.get_reduce_chi2(nimages, ndet)

print(f'Reduce Chi2: {chi2_reduce:.4f}')
```

```{python}
mcmc.get_params_errors()
from qubic.AnalysisMC import cov2corr
# Covariance between parameters
lim = 1#np.abs(np.max(mcmc.params_cov)/100)

fig, ax = plt.subplots(1, 1, figsize=(6, 6))
im = ax.imshow(cov2corr(mcmc.params_cov), cmap='bwr', vmin=-lim, vmax=lim)
ax.set_xticks(np.arange(nimages+2))
ax.set_yticks(np.arange(nimages+2))
ax.set_xticklabels(mcmc.axis_names)
ax.set_yticklabels(mcmc.axis_names)
ax.set_title('Correlation')
fig.colorbar(im)

```

```{python}
import corner
labels = ['f', r'\theta'] + [fr'P_{i+1}' for i in range(nimages)]
fig = corner.corner(mcmc.chains_flat, labels=labels)
```

```{python}
stop = 4300
mysamples = mcmc.chains[mcmc.burnin:, mcmc.valid_chains, :].copy()
mysamples[:, :, 1] = np.rad2deg(mysamples[:, :, 1]) #Theta in deg
for i in range(len(params_guess) - 2):
    mysamples[:, :, 2+i] = 10**mysamples[:, :, 2+i]
```

```{python}
import getdist
from getdist import plots, MCSamples

labels = ['f', r'\theta'] + [fr'P_{i+1}' for i in range(nimages)]
samps = MCSamples(samples=mysamples, names=mcmc.axis_names, labels=labels,
                  ranges={'Focal':(None, None), 'Theta':(None,None)})

g = plots.getSubplotPlotter()
g.triangle_plot(samps, filled=True, title_limit=2,
                markers={'f':params_fake[0], 'Theta':np.rad2deg(params_fake[1]), 
                        'LogP1':params_fake[2], 'LogP2':params_fake[3], 'LogP3':params_fake[4]})
#g.export(save_dir + 'corner_plot_BL2-5-11_simu.pdf')
```

#### Get A from the fit parameters

```{python}
# Producing params with the covariance found with the MCMC
# The distribution is considered as gaussian
size = 1000
distrib = np.random.multivariate_normal(mcmc.params, mcmc.params_cov, size=size)
allA = np.zeros((size, ndet))
for i in range(size):
    params = distrib[i]
    q.optics.focal_length = mcmc.params[0]
    allPowerPhi = []
    for k in range(nimages):
        model = scal.Model_Fringes_Ana(q, BLs[k], 
                                        theta_source=mcmc.params[1], 
                                        nu_source=150e9, 
                                        fwhm=20., amp=1., frame='ONAFP')

        x, y, Phi = model.get_fringes(times_gaussian=False)
        
        # Global amplitude
        allPowerPhi.append(Phi * 10**mcmc.params[2+k])


    # Gain for each detector
    allA[i, :], Cov_A = scal.get_gains(allPowerPhi, allInvCov, fringes)

mcmcA_std = np.std(allA, axis=0)    
mcmcA = np.mean(allA, axis=0)    
```

```{python}
# Get A from the blob (A computed and saved during the MCMC) 
blobA = mcmc.blobs[mcmc.burnin:, :, :]
blobA = np.reshape(blobA, ((mcmc.niter-mcmc.burnin)*mcmc.nwalkers, 248))

# Mean and STD along the chain
blobA_std = np.nanstd(blobA, axis=0)
print(blobA_std.shape)

blobA_mean = np.nanmean(blobA, axis=0)
# print(blobA_man)


Cov_A = np.cov(blobA.T)
# print(Cov_A)
weights = 1 / np.diag(Cov_A)
weights = np.nan_to_num(weights, nan=1e-10)
avgA = np.average(np.nan_to_num(blobA_mean, nan=1), weights=weights)
print(avgA)
```

```{python}
blobA_mean
```

```{python}
xx = np.arange(np.min(gains_fake), np.max(gains_fake), 0.01)
if simu:
    fig, axs = plt.subplots(1, 2, figsize=(12, 6))
    fig.subplots_adjust(wspace=0.3)
    ax1, ax2 = np.ravel(axs)
    
    ax1.errorbar(gains_fake, mcmcA, yerr=mcmcA_std, fmt='o', color='g', label='mean, STD')
    ax1.plot(xx, xx, 'k--', label='y=x')
    ax1.set_xlabel('Gain Fake Data')
    ax1.set_title('Gain with MC')
    ax1.legend()
    
    ax2.errorbar(gains_fake, blobA_mean, yerr=blobA_std, fmt='o', color='r', label='mean, STD')
    ax2.plot(xx, xx, 'k--', label='y=x')
    ax2.set_xlabel('Gain Fake Data')
    ax2.set_title('Gains from blob')
    ax2.legend()
    fig.tight_layout()

else:
    vmin=-40
    vmax =40
    fig, axs = plt.subplots(1, 2, figsize=(12, 6))
    #fig.suptitle('Gains and errors found with MCMC')
    ax1, ax2 = np.ravel(axs)
    fig.subplots_adjust(wspace=0.4)
    flib.plot_fringes_scatter(q, xONAFP, yONAFP, blobA_mean*the_mask*allmask_hot[k], 
                              fig=fig, ax=ax1, title='Gains', 
                              normalize=False, vmin=vmin, vmax=vmax, 
                              s=130, config='TD')

    flib.plot_fringes_scatter(q, xONAFP, yONAFP, blobA_std*the_mask*allmask_hot[k], 
                              fig=fig, ax=ax2, title='Errors', 
                              normalize=False, vmin=0, vmax=15, 
                              s=130, config='TD', cmap=cmap_red)
    
   # ax3.hist(blobA_mean, bins=30, range=(-10, 10))
   # ax3.set_xlabel('Gains found with MCMC')
#     ax3.axvline(np.nanmean(blobA_mean), color='r')
    
    fig.tight_layout()
    fig.savefig(save_dir + 'gains_MCMC_realdata.pdf', bbox_inches='tight')
    
#     plt.figure()
#     plt.errorbar(A, meanA, xerr=np.sqrt(np.diag(Cov_A)), yerr=stdA, fmt='o')
#     plt.plot(A, A, label='y=x')
#     plt.xlabel('A')
#     plt.ylabel('Mean A after MC')
# #     plt.axis('equal')
#     plt.legend()
```

```{python}
if simu:
    xx = [-0.1, 2.1]
    fig, axs = plt.subplots(1, 2, figsize=(12, 6))
    ax1, ax2 = axs.ravel()

    ax1.errorbar(gains_fake, blobA_mean, yerr=blobA_std, fmt='o', color='b')
    ax1.plot(xx, xx, 'r', label='y=x')
    ax1.set_xlabel(r'$A_d$ input data')
    ax1.set_ylabel(r'$A_d$ MCMC result')
    ax1.legend()

    mean = np.mean(blobA_mean-gains_fake)
    std = np.std(blobA_mean-gains_fake)
    ax2.hist(blobA_mean - gains_fake, range=(-0.5, 0.5), bins=20)
    ax2.axvline(mean, color='r', label=fr' $\mu \pm \sigma={mean:.3f} \pm {std:.3f}$')
    ax2.axvline(mean+std, color='r', linestyle='--')
    ax2.axvline(mean-std, color='r', linestyle='--')
    ax2.set_xlabel(f'$A_d$ residuals', fontsize=16)
    ax2.set_ylabel('Counts', fontsize=16)
    ax2.set_ylim(0, 60)
    ax2.legend(loc='upper left')

    fig.tight_layout()
    fig.savefig(save_dir + 'gains_MCMC_simu.pdf', bbox_inches='tight')

```

#### Residuals and data corrected by inter-calibrations

```{python}
mycmap = flib.make_cmap_nan_black('bwr')
for k in range(nimages):
    BL = BLs[k]
    plot_residuals(q, xONAFP, yONAFP, BL, 
                   fringes[k], the_mask*allmask_hot[k], 
                   allPowerPhi[k], errs[k], 
                   blobA_mean, cmap=mycmap,
                   normalize=True, vmin=-1, vmax=1, s=60, 
                   save_plot=False, title=save_dir + f'fringes_corrected_MCMC_BL{BL[0]}-{BL[1]}.pdf')
    correct, residu, pull = get_pull(fringes[k], errs[k], blobA_mean, allPowerPhi[k], the_mask*allmask_hot[k])
    plot_pull(BLs[k], pull, therange=(-5, 5))
    plot_hist_residuals(BLs[k], correct, residu)

```

```{python}
fig, axs = plt.subplots(2, 3, figsize=(15, 8))
axs = np.ravel(axs)
    #fig.suptitle(f'Baseline {BL}')
for k in range(nimages):
    BL = BLs[k]
    correct, residu, pull = get_pull(fringes[k], errs[k],  blobA_mean, allPowerPhi[k], 
                                     mask=the_mask*allmask_hot[k])
    
    
    # Initial / corrected 
    flib.plot_fringes_scatter(q, xONAFP, yONAFP, fringes[k]*the_mask*allmask_hot[k], 
                              fig=fig, ax=axs[k], cmap=mycmap, title=fr'Data - Baseline [{BL[0]}-{BL[1]}] ', s=70, 
                              normalize=True, vmin=-1, vmax=1, config='TD')

    flib.plot_fringes_scatter(q, xONAFP, yONAFP, correct*the_mask*allmask_hot[k], 
                              fig=fig, ax=axs[k+3], cmap=mycmap, title=r'Data / Gains', s=70, 
                              normalize=True, vmin=-1, vmax=1, config='TD')
fig.tight_layout()
#fig.savefig(save_dir + 'data_corrected_real_data.pdf', bbox_inches='tight')
```

```{python}
fig, axs = plt.subplots(3, 3, figsize=(15, 12))
axs = np.ravel(axs)
    #fig.suptitle(f'Baseline {BL}')
for k in range(nimages):
    BL = BLs[k]
    correct, residu, pull = get_pull(fringes[k], errs[k],  blobA_mean, allPowerPhi[k], 
                                     mask=the_mask*allmask_hot[k])
    
    
    # Initial / corrected 
    flib.plot_fringes_scatter(q, xONAFP, yONAFP, fringes[k]*the_mask*allmask_hot[k], 
                              fig=fig, ax=axs[k], cmap=mycmap, title=fr'Data - Baseline [{BL[0]}-{BL[1]}] ', s=70, 
                              normalize=False, vmin=-0.6, vmax=0.6, config='TD')

    flib.plot_fringes_scatter(q, xONAFP, yONAFP, correct*the_mask*allmask_hot[k], 
                              fig=fig, ax=axs[k+3], cmap=mycmap, title=r'Data / Gains', s=70, 
                              normalize=False, vmin=-0.6, vmax=0.6,config='TD')
    
    flib.plot_fringes_scatter(q, xONAFP, yONAFP, residu*the_mask*allmask_hot[k], 
                              fig=fig, ax=axs[k+6], cmap=mycmap, title=r'Residuals', s=70, 
                              normalize=False, vmin=-0.2, vmax=0.2, config='TD')
fig.tight_layout()
fig.savefig(save_dir + 'data_corrected_simu.pdf', bbox_inches='tight')
```

```{python}
fig, axs = plt.subplots(1, 3)
axs=np.ravel(axs)

for k in range(nimages):
    correct, residu, pull = get_pull(fringes[k], errs[k], blobA_mean, allPowerPhi[k], the_mask*allmask_hot[k])
    plot_pull(BLs[k], pull, therange=(-2.5, 2.5), fig=fig, ax=axs[k])

fig.tight_layout()
fig.savefig(save_dir + 'pull_MCMC_simu.pdf', bbox_inches='tight')
```

```{python}

```
