---
jupyter:
  jupytext:
    text_representation:
      extension: .Rmd
      format_name: rmarkdown
      format_version: '1.1'
      jupytext_version: 1.2.1
  kernelspec:
    display_name: Python 3
    language: python
    name: python3
---

```{python}
from __future__ import division, print_function

import glob
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd

# %matplotlib notebook
# %matplotlib inline
from matplotlib import rc
rc('figure',figsize=(9, 4.5))
rc('font',size=12)
rc('text',usetex=False)

from qubic import selfcal_lib as sc
from qubicpack.utilities import Qubic_DataDir
import qubic

from qubicpack import qubicpack as qp
from qubicpack.qubicfp import qubicfp
import qubic.fibtools as ft

from pysimulators import FitsArray

import scipy.ndimage.filters as f
import scipy.optimize as spo
import string

from importlib import reload

from qubicpack.pix2tes import assign_tes_grid
tes_grid = assign_tes_grid()
```

```{python}
global_dir = '/home/louisemousset/QUBIC/Qubic_work/Calibration/datas/'
# June measurement
# data_dir = global_dir + '2019-06-07/'

# December measurement
# data_dir = global_dir + 'fringes2019-12-19/'

# January measurement
data_dir = global_dir + '2020-01-13/'

dirs = np.sort(glob.glob(data_dir+'*switch*'))
print('# simu:', len(dirs))

labels = []
for i, d in enumerate(dirs):
    bla = str.split(d,'/')
    labels.append(bla[-1])
    print(i, labels[i])
```

```{python slideshow={'slide_type': '-'}}
def get_data(dirs, nf, asic, tes, doplot=True):
    asic = str(asic)
    thedir = dirs[nf]
    # print(thedir)

    # Qubicpack object
    a = qubicfp()
    a.verbosity = 0
    a.read_qubicstudio_dataset(thedir)
    data = a.azel_etc(TES=None)
    
    # Signal for one TES
    t0 = data['t_data ' + asic][0]
    t_data = data['t_data ' + asic] - t0
    data = data['data ' + asic]
    
    if doplot :
        fig, axs = plt.subplots(1, 2, figsize=(15,3))
        plt.subplots_adjust(wspace=0.5)

        axs[0].plot(t_data, data[tes-1, :])
        axs[0].set_title(thedir[-5:])

        axs[1].plot(t_data, data[tes-1, :])
        axs[1].set_title(thedir[-5:])
        axs[1].set_xlim(0, 40)  
    
    return t_data, data


    
```

```{python}
# Look at all simulations for one TES
TESNum = 28 #105#39
asic = 1

for nf in range(6, 28):
    t_data, data = get_data(dirs, nf, asic, TESNum)
```

```{python}
# Select a simulation
nf = 8
TESNum = 28 #105#39
asic = 1

t_data, data = get_data(dirs, nf, asic, TESNum)

```

```{python}
# Cut the data
def cut_data(tstart, tend, t_data, data):
    ok = (t_data > tstart) & (t_data < tend)
    t_data_cut = t_data[ok] - tstart
    data_cut = data[:, ok]
    
    return t_data_cut, data_cut

tstart =  4 #5.1 #+6.075*10# 41.7# 5.1
tend =  1750 #400 #tdeb+6.075*10

t_data_cut, data_cut = cut_data(tstart, tend, t_data, data)

plt.plot(t_data_cut, data_cut[TESNum-1, :])
plt.xlim(0, 30)
```

```{python}
def make_spectrum(t_data, data_oneTES, period):
    # Sampling frequency
    npoints = len(t_data)
    t0, tf = t_data[0], t_data[-1]
    f_sampling = npoints / (tf - t0)

    # Spectrum
    spectrum_f, freq_f = mlab.psd(data_oneTES, 
                                  Fs=f_sampling, 
                                  NFFT=2**int(np.log(len(data_oneTES)) / np.log(2)), 
                                  window=mlab.window_hanning)
    plt.plot(freq_f, spectrum_f)
    plt.loglog()
    plt.xlim(0.1, 10)
    for i in range(1, 10):
        plt.axvline(x=i/period, color='orange')
    plt.grid()
    
    return spectrum_f, freq_f

# Filter the data (just to give an idea because it is done when folding)
lowcut = 0.001
highcut = 10.
nharm = 10
notch = np.array([[1.724, 0.005, nharm]])

newdata = ft.filter_data(t_data_cut, data_cut[TESNum-1, :], lowcut, highcut, notch=notch, 
                         rebin=True, verbose=True, order=5)

spectrum_f, freq_f = make_spectrum(t_data_cut, data_cut[TESNum-1, :], period)

spectrum_f2, freq_f2 = make_spectrum(t_data_cut, newdata, period)

# compute spectrum with fibtools
spectrum_f3, freq_f3 = ft.power_spectrum(t_data_cut, newdata, rebin=True)

plt.subplot(2,1,1)
plt.plot(freq_f, spectrum_f, label='Original')
plot(freq_f2, spectrum_f2, label='filtered')
plot(freq_f3, spectrum_f3, label='filtered2')
legend()
plt.loglog()
ylim(1e1, 1e17)

subplot(2,1,2)
plot(t_data_cut, data_cut[TESNum-1, :], label='Original')
plot(t_data_cut, newdata, label='Filtered')
plt.xlim(200, 1700)
plt.legend()
```

```{python}
# Find the right period
def find_right_period(guess, t_data, data_oneTES):
    ppp = np.linspace(guess-1.5, guess+1.5, 250)
    rms = np.zeros(len(ppp))
    for i in range(len(ppp)):
        xin = t_data % ppp[i]
        yin = data_oneTES
        xx, yy, dx, dy, o = ft.profile(xin, yin, nbins=100, plot=False)
        rms[i] = np.std(yy)
    period = ppp[np.argmax(rms)]
    
    return ppp, rms, period

ppp, rms, period = find_right_period(18, t_data_cut, data_cut[TESNum-1, :])
print('period : ', ppp[np.argmax(rms)])
    
plt.figure()
rc('figure',figsize=(9, 4.5))
plt.subplots_adjust(wspace=2)

plt.subplot(211)
plot(ppp, rms, '.')
plt.axvline(x=period, color='orange')

plt.subplot(212)
plt.plot(t_data % period, data[TESNum-1, :],'.')
plt.xlim(0, period)
```

```{python}
# Fold and filter the data using the period determined before
lowcut = 0.001
highcut = 10.
nharm = 10
notch = np.array([[1.724, 0.005, nharm]])

nbins = 120
med = False
folded, t, folded_nonorm, truc = ft.fold_data(t_data_cut, 
                                              data_cut, 
                                              period, 
                                              lowcut, 
                                              highcut,
                                              nbins, 
                                              notch=notch,
                                              median=med)

plt.subplot(211)
plt.plot(t_data_cut, data_cut[TESNum-1, :])
plt.xlim(0, period)

plt.subplot(212)
plt.plot(t, folded[TESNum-1, :])
plt.xlim(0, period/6)
```

```{python}
# x = np.linspace(0., 20, 100)
# amp = [1, 2, 3, 4, 5]
# stable_time = 4
# signal = np.zero_like(x)
# for i in x:
#     signal = 
    



# pars = [0.001, 5., 20., 2]
# x = np.linspace(0., 100, 100)
# print(x)
# simsig = ft.simsig(x, pars)
# plot(x, simsig)

# import numpy as np
# from scipy.signal import lti
# from scipy.optimize import curve_fit


# def model1(x, gain1, tau1):
#     y = lti(gain1, [tau1, 1]).step(T=x)[1]
#     return y

# time_interval = np.linspace(1,100,100)

# output1 = model1(time_interval, 10, 4)

# # par1 = curve_fit(model1, t[0:period/6], folded[TESNum-1, 0:period/6])

# plt.plot(output1)


from scipy.ndimage.filters import gaussian_filter1d

def simsig(x, pars):
    dx = x[1] - x[0]
    npoints = len(x)
    tf = x[-1]
    pp = np.nan_to_num(pars[0])
    ctime = np.nan_to_num(pars[1])
    x0 = np.nan_to_num(pars[2])
    amp = pars[3]
    sim_init = np.zeros(len(x))
    
    for i in range(6):
        a = int(npoints/tf * 3 * i) 
        b = int((3 * i + 3) * npoints/tf)
        print(a, b)
#         ok = ((pp * i * np.max(x)) < x)  and (x < (pp * (i+1) * np.max(i)))
        sim_init[a : b] = amp[i]
    
    # Add a phase
    sim_init_shift = np.interp((x - x0) % max(x), x, sim_init)
    
#     # Convolved by a filter
    thesim = -1 * gaussian_filter1d(sim_init_shift, ctime, mode='wrap')
#     thesim = -1 * ft.exponential_filter1d(sim_init_shift, ctime / dx, mode='wrap')
    
    return thesim#sim_init_shift#np.nan_to_num(thesim)

pars = [3., 1, 2, [1., 2., 3., 2, 5, 7]]
x = np.linspace(0., 18., 18 * 10)
thesim = simsig(x, pars)
plt.plot(x, thesim, '.')
```

```{python}
# w is made to make the combination to see fringes
tm1 = 8
tm2 = 2
ph = 5
w = np.zeros_like(t)
wcheck = np.zeros_like(t)
print(len(w))
per = len(w) / 6
for i in range(len(w)):
#         print(i)
        if (((i-ph) % per) >= tm1) and (((i-ph) % per) < per-tm2):
            if ((((i-ph)//per) == 0) | (((i-ph)//per) == 3)) : w[i]=-1.
            if ((((i-ph)//per) == 1) | (((i-ph)//per) == 2)) : w[i]=1.
            if (((i-ph)//per) == 2) : wcheck[i]=-1.
            if (((i-ph)//per) == 4) : wcheck[i]=1.
                
npts = np.sum(w!=0.) / 4.
# w = w / npts
# wcheck = wcheck / npts
print(npts)
print(np.sum(np.abs(w[int(per+ph):int(2*per+ph)])))
print(np.sum(w))

themax = np.max(folded[TESNum-1, :])
```

```{python}
plt.plot(t, folded[TESNum-1, :])
plt.plot(t, w * themax, 'o')
plt.plot(t, wcheck * themax, 'x')
plt.xlim(0, period)
plt.grid()
```

```{python}
# Analysis for both ASICs
allres = np.zeros(256)
allrescheck = np.zeros(256)

for asic in [1, 2]:
    t_data, data = get_data(dirs, nf, asic, TESNum, doplot=False)
    t_data_cut, data_cut = cut_data(tstart, tend, t_data, data)

    folded, t, folded_nonorm, truc = ft.fold_data(t_data_cut, 
                                                  data_cut,
                                                  period, 
                                                  lowcut, 
                                                  highcut, 
                                                  nbins, 
                                                  median=med)
    for TESNum in range(1, 129):
        TESindex = (TESNum - 1) + 128 * (asic - 1)
        allres[TESindex] = np.sum(folded[TESNum-1, :] * w)
        allrescheck[TESindex] = np.sum(folded[TESNum-1, :] * wcheck)
        
        plt.plot(t, folded[TESNum-1, :])
        plt.plot(t, w, '+')
        plt.plot(t, wcheck, 'x')
        plt.plot(t, folded[TESNum-1, :] * w)
        
        plt.grid()
        plt.xlim(0, period)
        plt.title('ASIC {}, TES {}'.format(asic, TESNum))
        plt.pause(0.1)
```

```{python}
fringe = ft.image_asics(all1=allres)
fringecheck = ft.image_asics(all1=allrescheck)

lim = 1.8
plt.figure()

plt.subplot(121)
plt.imshow(fringe, vmin=-lim, vmax=lim)
plt.title('with w')
colorbar(orientation ='horizontal')

plt.subplot(122)
plt.imshow(fringecheck, vmin=-lim, vmax=lim)
plt.title('with wcheck')
colorbar(orientation ='horizontal')


```

### Try different masks

```{python}
# Mask to remove the 8 thermometer pixels
mask = np.ones_like(fringe)
mask[0, 12:] = np.nan
mask[1:5, 16] = np.nan

# Mask to remove bad pixels
# bad1 = np.array([1,2,3,29,30,31,32,33,34,35,61,62,63,64,65,66,67,93,
#                94,95,96,97,98,99,125,126,127,128,108,105,116,7,17,47,102,114,28,25])-1
# bad2 = np.array([1,2,3,29,30,31,32,33,34,35,61,62,63,64,65,66,67,93,
#                94,95,96,97,98,99,125,126,127,128,120,122,24,55,123,118,112,114,113,18,28,41,104,102,116,107])+127

bad1 = np.array([4, 5, 11, 12, 15, 17, 18, 19, 20, 21, 23, 29, 30, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 
                46, 47, 48, 49, 50, 51, 52, 58, 63, 65, 66, 68, 69, 78, 79, 80, 82, 83, 89, 90, 91, 92, 93, 97, 100,
                102, 104, 108, 111, 112, 114, 115, 116, 119, 121, 122, 124, 126])-1
bad2 = np.array([2, 4, 6, 8, 11, 12, 16, 21, 22, 23, 26, 27, 28, 29, 31, 33, 36, 37, 40, 46, 49, 51, 53, 55, 58, 62,
                63, 64, 68, 69, 74, 76, 78, 80, 83, 89, 92, 94, 95, 98, 99, 100, 101, 102, 103, 104, 107, 108, 
                109, 110, 117, 119, 120, 121, 125, 126, 127])+127

maskres = np.ones_like(allres)
maskres[bad1] = np.nan
maskres[bad2] = np.nan

mask2 = ft.image_asics(all1 = maskres)

# Mask to remove max values from check
lim = 10000
mask3 = np.ones_like(fringe) 
mask3[np.abs(fringe)<lim] = np.nan
plt.imshow(mask2, vmin=-1e5, vmax=1e5)
plt.title('mask3')
colorbar()
```

```{python}
# Apply masks on fringes

rcParams["image.cmap"]='viridis'
# rcParams["image.cmap"]='bwr'
plt.imshow(fringe * mask * mask3, vmin=-1e5, vmax=1e5)#,interpolation='bicubic')

```

```{python}
# Good if the fringes are vertical or horizontal
plt.plot(np.nanmean(fringe*mask4, axis=0), label='Med axis 0 norm')
plt.plot(np.nanmean(fringe*mask4, axis=1), label='Med axis 1 norm')
#plt.ylim(-3000,3000)
plt.grid()
plt.legend()
plt.title(labels[nf])
```

### Fit with an analytical function

```{python}
# Analytical function
def sim_fringe(param):
    Amp = param[0]
    focal = param[1]
    phase = param[2]
    alpha = param[3]
        
    yc = 0.
    xc = 0. 
    
    nu = 150.e9
    lam = 3.e8/nu
    alpha_rad = np.deg2rad(alpha)
    
    det_dist = 3e-3
    baseline = 14.e-3*4.
    
    ndet = 17
    fringe = np.zeros((ndet, ndet))
    i, j = np.mgrid[0:ndet, 0:ndet]
    
    w = 40.87e-3 # From Creidhe
    #w=np.sqrt(2*(12.9*np.pi/180*f/2.355)**2)
    
    gaussian = np.exp(-((16-i+xc)**2 + (j-yc)**2) * det_dist**2 / (w**2))
    xprime = (i * np.cos(alpha_rad) + j * np.sin(alpha_rad)) * det_dist
    interfrange = lam * focal / baseline
    fringe = Amp * np.cos((2. * np.pi / interfrange * xprime) + phase)# * gaussian
    
    return fringe
```

```{python}
def sim_fringe_flat(param):
    fff = sim_fringe(param)
    return fff.ravel()

def sim_fringe_flat2(param):
    fff = sim_fringe(param)
    res = np.zeros(256)
    for xx in range(17):
        for yy in range(17):
            TESNum=int(tes_grid[xx,yy])
            AsicNum = int(10.*(tes_grid[xx,yy]-TESNum))+1
            TESindex = (TESNum-1) + 128 *(AsicNum -1)
            res[TESindex] = fff[xx,yy]
    return res
```

```{python}
def compute_residuals(param, observation):
    """
    Return array: observation - model
    """
    model = sim_fringe_flat(param)
    err = 2000
    residual = (observation - model) / err
    print("residual: ", np.nansum(residual**2))
    
    return residual.astype(np.float64)
```

```{python}
param = [13e3, 300e-3, 0., -45.]#,40.87e-3]#,0.]
lim = 1e4
plt.imshow(sim_fringe(param), vmin=-lim, vmax=lim)
```

```{python}
# Fit the measurement with the analytical model
param_guess = [13e3, 300e-3, 0, -50.]

tofit = (fringe * mask4).ravel()
tofit[np.isnan(tofit)] = 0.

param_est, cov_x, infodict, mesg_result, ret_value = spo.leastsq(compute_residuals, 
                                                                 param_guess, 
                                                                 args=(tofit.astype(np.float64)),
                                                                 full_output=True, 
                                                                 maxfev=10000, 
                                                                 epsfcn=np.finfo(np.float32).eps)

sigma_param_est = np.sqrt(np.diagonal(cov_x))

print("Return value:", ret_value)
print("Return message:", mesg_result)

if ret_value not in (1, 2, 3, 4):
    raise RuntimeError(mesg_result)

print("guess    :", param_guess)
print("solution :", param_est)
print("Error :", sigma_param_est)
print("Precision (%):",sigma_param_est/param_est*100)
```

```{python}
rcParams["image.cmap"]='viridis'
# rcParams["image.cmap"]='bwr'

lim = 1e5

subplot(121)
imshow(sim_fringe(param_est), vmin=-lim,vmax=lim)

subplot(122)
imshow(fringe * mask * mask4, vmin=-lim, vmax=lim)
# plt.title(labels[nf])
# plt.colorbar()
```

```{python}
maskresp = fringe / sim_fringe(param_est) * mask3 * mask
```

```{python}
rcParams["image.cmap"]='viridis'
# rcParams["image.cmap"]='bwr'
imshow(maskresp, vmin=-10, vmax=10)#,interpolation='bicubic')
plt.title(labels[nf])
plt.colorbar()
```

# Fit with the simulation

```{python}
def get_quadrant3(q, signal_perTES, doplot=False):
    quadrant3 = signal_perTES[496:744]
    indice = -(q.detector.center // 0.003)

    img = np.zeros((17, 17))
    for k in range(248):
        i = int(indice[k, 0])
        j = int(indice[k, 1])
        img[i-1, j-1] = quadrant3[k]
    img[img==0.] = np.nan
    img = np.rot90(img)
    
    if doplot :
        plt.figure()
        plt.imshow(img)
    
    return img

def get_simulation(param, q, baseline, horn_transpose, files, labels, nn=241, doplot=True):
    
    theta_source = param[0]
    freq_source = param[1]

    allampX = np.empty((2, nn, nn))
    allphiX = np.empty((2, nn, nn))
    allampY = np.empty((2, nn, nn))
    allphiY = np.empty((2, nn, nn))
    for i, swi in enumerate(baseline):
        # Phase calculation
        horn_x = q.horn.center[swi - 1, 0]
        horn_y = q.horn.center[swi - 1, 1]
        dist = np.sqrt(horn_x ** 2 + horn_y ** 2)  # distance between the horn and the center
        phi = - 2 * np.pi / 3e8 * freq_source * 1e9 * dist * np.sin(np.deg2rad(theta_source))

        thefile = files[horn_transpose[swi - 1]]
        print('Horn ', swi, ': ', thefile[98:104])
        data = pd.read_csv(thefile, sep='\t', skiprows=0)

        allampX[i, :, :] = np.reshape(np.asarray(data['MagX']), (nn, nn)).T
        allampY[i, :, :] = np.reshape(np.asarray(data['MagY']), (nn, nn)).T

        allphiX[i, :, :] = np.reshape(np.asarray(data['PhaseX']), (nn, nn)).T + phi
        allphiY[i, :, :] = np.reshape(np.asarray(data['PhaseY']), (nn, nn)).T + phi

    # Electric field for each open horn
    Ax = allampX * (np.cos(allphiX) + 1j * np.sin(allphiX))
    Ay = allampY * (np.cos(allphiY) + 1j * np.sin(allphiY))

    # Sum of the electric fields
    sumampx = np.sum(Ax, axis=0)
    sumampy = np.sum(Ay, axis=0)

    # Power on the focal plane
    power = np.abs(sumampx) ** 2 + np.abs(sumampy) ** 2

    if doplot:
        plt.figure()
        plt.subplot(121)
        q.horn.plot()
        plt.axis('off')

        plt.subplot(122)
        plt.imshow(power, origin='lower')
        plt.title('Power at the sampling resolution')
        plt.colorbar()
    
    counts_perTES, sum_perTES, mean_perTES = sc.fulldef2tespixels(power, labels)
    
    img = get_quadrant3(q, mean_perTES, doplot=doplot)

    return img

def compute_diff(param, q, baseline, horn_transpose, files, labels, observation):
    """
    Return array: observation - model
    """
    model = get_simulation(param, q, baseline, horn_transpose, files, labels, doplot=False)
    err = 200
    residual = (observation - np.ravel(model)) / err
    residual[np.isnan(residual)] = 0.
    print('param :', param)
    print("residual sum: ", np.nansum(residual**2))
    
    return residual.astype(np.float64)

```

```{python}
# Use a tool from qubicpack to get a path
basedir = Qubic_DataDir(datafile='instrument.py', ) 
print('basedir : ', basedir)
dictfilename = basedir + '/dicts/global_source_oneDet.dict'

# Get a dictionary
d = qubic.qubicdict.qubicDict()
d.read_from_file(dictfilename)

# Create an object
baseline = [25, 57]
ca = sc.SelfCalibration(baseline, [], d)

# Path to the simulated files 
rep = Qubic_DataDir(datafile='detcentres.txt')
print('rep:', rep)
```

```{python}
# Get simulation files
files = sorted(glob.glob(rep + '/*.dat'))

# This is done to get the right file for each horn
horn_transpose = np.arange(64)
horn_transpose = np.reshape(horn_transpose, (8, 8))
horn_transpose = np.ravel(horn_transpose.T)

# Get the sample number from the first file
data0 = pd.read_csv(files[0], sep='\t', skiprows=0)
nn = data0['X_Index'].iloc[-1] + 1
print('Sampling number = {}'.format(nn))

# Make an instrument
q = qubic.QubicInstrument(d)
q.horn.open = False
q.horn.open[np.asarray(baseline) - 1] = True

# Make labels
readv, labels = sc.make_labels(rep)
```

```{python}
# Example
fringes = ca.get_power_fp_aberration(rep, theta_source=0., doplot=False)

counts_perTES, sum_perTES, mean_perTES = sc.fulldef2tespixels(fringes, labels)

print(len(mean_perTES))
fig = sc.make_plot_real_fp(readv, mean_perTES)
plt.title('Baseline {} with aberrations'.format(baseline))

img = get_quadrant3(q, mean_perTES, doplot=True)
```

```{python}
param = [0., 150.]
img = get_simulation(param, q, baseline, horn_transpose, files, labels, doplot=False)

residual = compute_diff(param, q, baseline, horn_transpose, files, labels, np.ravel(fringe))
```

```{python}
# Fit
param_guess = [5., 150.]

tofit = np.ravel(fringe)
tofit[np.isnan(tofit)] = 0.
tofit = tofit.astype(np.float64)

# Method 1
# param_est, cov_x, infodict, mesg, flag  = spo.leastsq(compute_diff, 
#                      param_guess,
#                      args=(q, baseline, horn_transpose, files, labels, tofit),
#                      factor=1.,
#                      full_output=True,
#                      epsfcn=np.finfo(np.float32).eps)
# sigma_param_est = np.sqrt(np.diagonal(cov_x))

# print("Return value:", param_est)
# print('Flag', flag)
# print("Return message:", mesg)
# print("Error :", sigma_param_est)
# print("Precision (%):", sigma_param_est / param_est * 100)

# Method 2
myfit = spo.least_squares(compute_diff,
                         param_guess,
                         args=(q, baseline, horn_transpose, files, labels, tofit),
#                          method='lm',
                         bounds=([-30., 30.], [130., 170.]),
                         ftol=1e-9)
print('Estimation:', myfit.x)
print('Cost:', myfit.cost)
# print('Residuals:', myfit.fun)
print('Cost fct gradient:', myfit.grad)
print('Message:', myfit.message)
print('Success:', myfit.success)
```

#### truc qui pourraient Ãªtre utiles

```{python}
# Weighting factor to have just 1 difference
tm1=5
tm2=0
w=np.zeros_like(t)
per = len(w)/6.
for i in range(len(w)):
        if ((i % per) >= tm1) and ((i % per) < per-tm2):
            if ((i//per) == 1): w[i]=1.
            if ((i//per) == 0) : w[i]=-1.
npts=np.sum(w<>0.)
print(npts)
print(np.sum(w))
```

```{python}
# T stability
plot(a.hk['MMR_HK']['MMR3_CH2_X'])
```

```{python}
spectrum_f, freq_f = mlab.psd(a.hk['MMR_HK']['MMR3_CH1_X'], Fs=1., NFFT=len(a.hk['MMR_HK']['MMR3_CH3_X']), 
                              window=mlab.window_hanning,detrend='mean')
plot(freq_f, np.sqrt(spectrum_f))
yscale('log')
xscale('log')
grid()
#xlim(0.001, 1)
```

```{python}
a.max_bias
```

```{python}
a.hk['MMR_HK'].keys()
```

```{python}
tMMR=a.hk['MMR_HK']['ComputerDate']
print(tMMR[21]-tMMR[20])
plot(np.diff(tMMR))
print(np.median(np.diff(tMMR)))
```

```{python}

```
