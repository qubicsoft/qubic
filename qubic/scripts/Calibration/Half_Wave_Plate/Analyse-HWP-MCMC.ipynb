{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43669e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%matplotlib notebook\n",
    "%matplotlib inline\n",
    "from matplotlib import rc\n",
    "rc('figure',figsize=(9,4.5))\n",
    "rc('font',size=12)\n",
    "rc('text',usetex=False)\n",
    "\n",
    "from qubicpack.qubicfp import qubicfp\n",
    "import qubic.fibtools as ft\n",
    "import qubic.plotters as p\n",
    "import qubic.lin_lib as ll\n",
    "import qubic.demodulation_lib as dl\n",
    "import satorchipy as stpy\n",
    "from pysimulators import FitsArray\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib.pyplot import *\n",
    "import matplotlib.mlab as mlab\n",
    "import scipy.ndimage.filters as f\n",
    "import glob\n",
    "import string\n",
    "import scipy.signal as scsig\n",
    "from scipy import interpolate\n",
    "import datetime as dt\n",
    "import pickle\n",
    "from importlib import reload\n",
    "import corner\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e714c90",
   "metadata": {},
   "source": [
    "# Location of the Data\n",
    "### 2019-12-23: 4\n",
    "- Modulator: Amplitude = 2V. Offset = 1.5 V\n",
    "- Nice data although source data does not have the same shape as TES data, probably the source measurement was not configured correctly. The data can however be exploited using Simulated Cal Src.\n",
    "\n",
    "### 2019-12-24: 0\n",
    "- Modulator: Amplitude = 500 mV ; Offest = 250 mV\n",
    "- Nice data with 180 sec/pos and 3 cycles.\n",
    "- SrcData not there...\n",
    "- Can be used with Simulated Cal Src\n",
    "\n",
    "### 2019-12-26: 0\n",
    "- Modulator: Amplitude: 500mV, Offset 2. V\n",
    "- Only one cycle but good quality data, The source is ON and seems weell configured\n",
    "\n",
    "### 2019-12-26: 1\n",
    "- Modulator: Amplitude: 500mV, Offset 2.5 V\n",
    "- Long overnight acquisition - to be looked at closely\n",
    "\n",
    "### 2019-12-27: 2\n",
    "- Modulator: Amplitude = 500mV ; Offest = 2.5 V\n",
    "- Excellent data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "562b57cf",
   "metadata": {},
   "source": [
    "***Important Remark:\n",
    "The mount has moved on Dec. 26th 18h30 CET, so this means that the data [2019-12-23_Dataset_4, 2019-12-24_Dataset_0, 2019-12-26_Dataset_0] have the same pointing while [2019-12-26_Dataset_1, 2019-12-27_Dataset_2] are with another pointing.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92291dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/Users/hamilton/Qubic/Calib-TD/HWP-Fitting/'\n",
    "\n",
    "### We put them in the order of the offset for Cal Src\n",
    "\n",
    "subdirs = ['2019-12-24_Dataset_0',\n",
    "           '2019-12-23_Dataset_4',\n",
    "           '2019-12-26_Dataset_0',\n",
    "           '2019-12-26_Dataset_1',\n",
    "           '2019-12-27_Dataset_2']\n",
    "\n",
    "ptg = [0,0,0,1,1]\n",
    "mod_amp = [0.5, 2., 0.5, 0.5, 0.5]\n",
    "mod_off = [0.25, 1.5, 2., 2.5, 2.5]\n",
    "\n",
    "data_allth = []\n",
    "data_uniqueth = []\n",
    "fit_uniqueth = np.zeros((len(subdirs), 256, 2, 4))\n",
    "\n",
    "for idir in range(len(subdirs)):\n",
    "    ### Look at 1st TES to get the dimensions of the arrays\n",
    "    TESNum = 1\n",
    "    bla0 = np.loadtxt(data_dir+subdirs[idir]+'/Data/hwp_measurement_AllTh_TES_{}.txt'.format(TESNum)).T\n",
    "    bla1 = np.loadtxt(data_dir+subdirs[idir]+'/Data/hwp_measurement_UniqueTh_TES_{}.txt'.format(TESNum)).T\n",
    "    print(idir, bla0.shape, bla1.shape)\n",
    "\n",
    "    data_allth_subd = np.zeros((256, bla0.shape[0], bla0.shape[1]))\n",
    "    data_uniqueth_subd = np.zeros((256, bla1.shape[0], bla1.shape[1]))\n",
    "\n",
    "    for TESNum in range(1,256):\n",
    "        data_allth_subd[TESNum-1,:,:] = np.loadtxt(data_dir+subdirs[idir]+'/Data/hwp_measurement_AllTh_TES_{}.txt'.format(TESNum)).T\n",
    "        data_uniqueth_subd[TESNum-1,:,:] = np.loadtxt(data_dir+subdirs[idir]+'/Data/hwp_measurement_UniqueTh_TES_{}.txt'.format(TESNum)).T\n",
    "        fit_uniqueth[idir,TESNum-1,:,:] = np.loadtxt(data_dir+subdirs[idir]+'/Data/hwp_measurement_Fit_UniqueTh_TES_{}.txt'.format(TESNum)).T\n",
    "    \n",
    "    data_allth.append(data_allth_subd)\n",
    "    data_uniqueth.append(data_uniqueth_subd)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "371244ed",
   "metadata": {},
   "source": [
    "Plot the data for a given TES and show that the fir can be redone here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81e8fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "rc('figure',figsize=(6,6))\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "reload(dl)\n",
    "\n",
    "TESNum = 96\n",
    "iii = (TESNum-1)\n",
    "idir = 0\n",
    "\n",
    "figure()\n",
    "errorbar(data_uniqueth[idir][TESNum-1,0,:], data_uniqueth[idir][TESNum-1,1,:], \n",
    "         yerr = data_uniqueth[idir][TESNum-1,2,:], label='Data', fmt='ro')\n",
    "legend(loc='upper left')\n",
    "xlabel('HWP Angle [Deg.]')\n",
    "ylabel('signal')\n",
    "title('TES #{}'.format(TESNum))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f50fde0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rc('figure',figsize=(6,6))\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "reload(dl)\n",
    "\n",
    "TESNum = 95\n",
    "iii = (TESNum-1)\n",
    "idir = 0\n",
    "\n",
    "### First a minuit Fit\n",
    "myguess = np.array([np.max(abs(data_uniqueth[idir][iii,1,:])), 0., 0., 5.])\n",
    "resfit = dl.hwp_fitpol(data_uniqueth[idir][TESNum-1,0,:], data_uniqueth[idir][TESNum-1,1,:], data_uniqueth[idir][TESNum-1,2,:], \n",
    "                       doplot=False, str_title='Demodulation TES{}'.format(iii+1), \n",
    "                       saturation=True, myguess=myguess, force_chi2_ndf=False, verbose=False)\n",
    "print(resfit)\n",
    "if np.prod(resfit[2])!=0:\n",
    "    ### Then a MCMC sampling\n",
    "    myguess = resfit[1]\n",
    "    myrange = [[0., 3*resfit[1][0]], \n",
    "               [0.,1.], \n",
    "               [resfit[1][2]-10*resfit[2][2], resfit[1][2]+10*resfit[2][2]],\n",
    "               [0, 10*resfit[1][3]]]\n",
    "\n",
    "    samples, valbest, intervals, intervals_CL, res_str = dl.hwp_fitpol_MCMC(data_uniqueth[idir][TESNum-1,0,:], data_uniqueth[idir][TESNum-1,1,:], data_uniqueth[idir][TESNum-1,2,:], \n",
    "                           doplot=True, str_title='Demodulation TES{} (MCMC)'.format(iii+1), \n",
    "                           saturation=True, myguess=myguess, force_chi2_ndf=False, myrange=myrange, upperlims=True, verbose=False)\n",
    "    tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111383cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getdist\n",
    "from getdist import plots, MCSamples\n",
    "\n",
    "names = ['Xpol%', 'Ang', 'Sat']\n",
    "labels = ['Xpol[$%$]', 'Ang', 'Sat']\n",
    "samps = MCSamples(samples=samples, names=names, labels=labels,\n",
    "                  ranges={'Xpol%':(0, None), 'Sat':(0,None)})\n",
    "\n",
    "g = plots.getSubplotPlotter()\n",
    "g.triangle_plot(samps, filled=True,title_limit=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4314c538",
   "metadata": {},
   "outputs": [],
   "source": [
    "rc('figure',figsize=(6,6))\n",
    "rc('font',size=18)\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "reload(dl)\n",
    "\n",
    "TESNum = 95\n",
    "iii = (TESNum-1)\n",
    "idir = 0\n",
    "\n",
    "### First a minuit Fit\n",
    "myguess = np.array([np.max(abs(data_uniqueth[idir][iii,1,:])), 0., 0., 5.])\n",
    "resfit = dl.hwp_fitpol(data_uniqueth[idir][TESNum-1,0,:], data_uniqueth[idir][TESNum-1,1,:], data_uniqueth[idir][TESNum-1,2,:], \n",
    "                       doplot=False, str_title='Demodulation TES{}'.format(iii+1), \n",
    "                       saturation=True, myguess=myguess, force_chi2_ndf=False, verbose=False)\n",
    "print(resfit)\n",
    "if np.prod(resfit[2])!=0:\n",
    "    ### Then a MCMC sampling\n",
    "    myguess = resfit[1]\n",
    "    myrange = [[0., 3*resfit[1][0]], \n",
    "               [0.,1.], \n",
    "               [resfit[1][2]-10*resfit[2][2], resfit[1][2]+10*resfit[2][2]],\n",
    "               [0, 10*resfit[1][3]]]\n",
    "\n",
    "    samples, valbest, intervals, intervals_CL, res_str = dl.hwp_fitpol_MCMC(data_uniqueth[idir][TESNum-1,0,:], data_uniqueth[idir][TESNum-1,1,:], data_uniqueth[idir][TESNum-1,2,:], \n",
    "                           doplot=True, \n",
    "                           saturation=True, myguess=myguess, force_chi2_ndf=False, myrange=myrange, upperlims=True, verbose=False)\n",
    "    tight_layout()\n",
    "    savefig('/users/hamilton/Downloads/hwp_plot_tes95.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a03ed6c",
   "metadata": {},
   "source": [
    "### Loop over bolometers\n",
    "\n",
    "1) Run the chains:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28affca",
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(dl)\n",
    "res_dir = '/Users/hamilton/Google Drive/QUBIC/Calib-TD/HWP-MCMC/TES-Results'\n",
    "idir = 0\n",
    "mydir = res_dir+'/'+subdirs[idir]\n",
    "os.makedirs(mydir, exist_ok=True)\n",
    "os.makedirs(mydir+'/Figs', exist_ok=True)\n",
    "os.makedirs(mydir+'/Pkl', exist_ok=True)\n",
    "\n",
    "for TESNum in range(1, 257):\n",
    "    figure()\n",
    "    print('Doing TES#{}'.format(TESNum))\n",
    "    ### First a minuit Fit\n",
    "    myguess = np.array([np.max(abs(data_uniqueth[idir][iii,1,:])), 0., 0., 5.])\n",
    "    resfit = dl.hwp_fitpol(data_uniqueth[idir][TESNum-1,0,:], data_uniqueth[idir][TESNum-1,1,:], \n",
    "                           data_uniqueth[idir][TESNum-1,2,:], \n",
    "                           doplot=False, str_title='Demodulation TES{}'.format(TESNum), \n",
    "                           saturation=True, myguess=myguess, force_chi2_ndf=False, verbose=False)\n",
    "\n",
    "    if np.prod(resfit[2]!=0):\n",
    "        ### Then a MCMC sampling\n",
    "        myguess = resfit[1]\n",
    "        myrange = [[0., 3*resfit[1][0]], \n",
    "                   [0.,1.], \n",
    "                   [resfit[1][2]-10*resfit[2][2], resfit[1][2]+10*resfit[2][2]],\n",
    "                   [0, 10*resfit[1][3]]]\n",
    "\n",
    "        samples, valbest, intervals, intervals_CL, res_str = dl.hwp_fitpol_MCMC(data_uniqueth[idir][TESNum-1,0,:], data_uniqueth[idir][TESNum-1,1,:], \n",
    "                                              data_uniqueth[idir][TESNum-1,2,:], \n",
    "                               doplot=True, str_title='Demodulation TES{} (MCMC)'.format(TESNum), \n",
    "                               saturation=True, myguess=myguess, force_chi2_ndf=False, \n",
    "                                myrange=myrange, upperlims=True, verbose=False,\n",
    "                                savecontour = mydir+'/Figs/Contours_TES_{}.pdf'.format(TESNum))\n",
    "        tight_layout()\n",
    "        print(resmcmc)\n",
    "        \n",
    "        #### Save successful ones\n",
    "        savefig(mydir+'/Figs/Result_TES_{}.pdf'.format(TESNum))\n",
    "        pickle.dump( [resfit[1:], samples, valbest, intervals, intervals_CL, res_str], open( mydir+'/Pkl/TES_{}.pk'.format(TESNum), \"wb\" ) )\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c07bfced",
   "metadata": {},
   "source": [
    "2) Read the chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6de90b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_dir = '/Users/hamilton/Google Drive/QUBIC/Calib-TD/HWP-MCMC/TES-Results'\n",
    "idir = 0\n",
    "mydir = res_dir+'/'+subdirs[idir]\n",
    "\n",
    "allsamples = []\n",
    "allvalbest = []\n",
    "allintervals = []\n",
    "allintervals_CL = []\n",
    "allres_str = []\n",
    "for TESNum in range(1, 257):\n",
    "    chain_file = mydir+'/Pkl/TES_{}.pk'.format(TESNum)\n",
    "    ff = glob.glob(chain_file)\n",
    "    if len(ff) != 0:\n",
    "        resfit, samples, valbest, intervals, intervals_CL, res_str = pickle.load(open(chain_file,'rb'))\n",
    "    allsamples.append(samples)\n",
    "    allvalbest.append(valbest)\n",
    "    allintervals.append(intervals)\n",
    "    allintervals_CL.append(intervals_CL)\n",
    "    allres_str.append(res_str)\n",
    "allsamples = np.array(allsamples)\n",
    "allvalbest = np.array(allvalbest)\n",
    "allintervals = np.array(allintervals)\n",
    "allintervals_CL = np.array(allintervals_CL)\n",
    "allres_str = np.array(allres_str)\n",
    "print(np.shape(allsamples))\n",
    "print(np.shape(allvalbest))\n",
    "print(np.shape(allintervals))\n",
    "print(np.shape(allintervals_CL))\n",
    "print(np.shape(allres_str))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb7f4d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "has_upperlimit = allintervals_CL[:,0] == 0.95\n",
    "print('We have {} upperlimits out of 256: {}%'.format(has_upperlimit.sum(), has_upperlimit.sum()/256*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b195684a",
   "metadata": {},
   "outputs": [],
   "source": [
    "means = np.mean(allsamples, axis=1)\n",
    "errs = np.std(allsamples, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ebd30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "varnames = ['Xpol %', 'Phase', 'Sat']\n",
    "rc('figure',figsize=(16,8))\n",
    "for i in range(3):\n",
    "    subplot(2,3,i+1)\n",
    "    hist(means[:,i], bins=100)    \n",
    "    xlabel('Mean '+varnames[i])\n",
    "    subplot(2,3,i+1+3)\n",
    "    hist(errs[:,i], bins=100)\n",
    "    xlabel('Std '+varnames[i])\n",
    "tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcab4c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94c817b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "def DBSCAN_cut(values, errors, doplot=False, min_samples=40, parnames=None):\n",
    "    norm_values = np.zeros_like(values)\n",
    "    norm_errors = np.zeros_like(errors)\n",
    "    sh = np.shape(values)\n",
    "    results = np.zeros((sh[0], sh[1]*2))\n",
    "    for i in range(sh[1]):\n",
    "        results[:,i] = normalize(values[:,i])\n",
    "        results[:,i+sh[1]] = normalize(errors[:,i])\n",
    "    \n",
    "    clustering = DBSCAN(eps=1.3, min_samples=min_samples).fit(results)\n",
    "    labels = clustering.labels_\n",
    "    nfound = len(np.unique(np.sort(labels)))\n",
    "    unique_labels = unique(labels)  \n",
    "    mycolors = [plt.cm.jet(each)\n",
    "              for each in np.linspace(0, 1, len(unique_labels))]\n",
    "    print(mycolors)\n",
    "    \n",
    "    if doplot:\n",
    "        for i in range(sh[1]):\n",
    "            if parnames is None:\n",
    "                pn = 'Param {}'.format(i)\n",
    "            else:\n",
    "                pn = parnames[i]\n",
    "                \n",
    "            subplot(2,sh[1], i+1)\n",
    "            for k in range(len(unique_labels)):\n",
    "                thisone = labels == unique_labels[k]\n",
    "                scatter(values[thisone,i],errors[thisone,i],c=mycolors[k],\n",
    "                        label='Type {} : n={}'.format(unique_labels[k],thisone.sum()))\n",
    "                xlabel(pn)\n",
    "                ylabel('Error '+pn)\n",
    "                if i==0:\n",
    "                    legend()\n",
    "    return (labels == 0)\n",
    "\n",
    "def normalize(x):\n",
    "    return (x-np.nanmean(x))/np.nanstd(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb3916ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "ok = DBSCAN_cut(means, errs, doplot=True, min_samples=55, parnames=varnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "459065c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "has_upperlimit = allintervals_CL[ok,0] == 0.95\n",
    "print('We have {} upperlimits out of {}: {}%'.format(has_upperlimit.sum(), ok.sum(), has_upperlimit.sum()/ok.sum()*100))\n",
    "\n",
    "\n",
    "rc('figure',figsize=(16,8))\n",
    "nbins = 30\n",
    "for i in range(3):\n",
    "    mm, ss = ft.weighted_mean(means[ok,i], errs[ok,i], dispersion=True)\n",
    "    subplot(2,4,i+1)\n",
    "    hist(means[ok,i], bins=nbins, label='Mean over {0:} TES:\\n{1:5.3f} +/- {2:5.3f}'.format(np.sum(ok),mm,ss))    \n",
    "    xlabel('Mean '+varnames[i])\n",
    "    legend(loc='upper right')\n",
    "    subplot(2,4,i+1+4)\n",
    "    hist(errs[ok,i], bins=nbins)\n",
    "    xlabel('Std '+varnames[i])\n",
    "tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5afe3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rc('figure',figsize=(16,8))\n",
    "myok = ok.copy()\n",
    "subplot(1,2,1)\n",
    "a=hist(means[myok,0]/errs[myok,0], range=[0,5], bins=30)\n",
    "subplot(1,2,2)\n",
    "a=hist(means[myok,0]/errs[myok,0], range=[0,3], bins=30, cumulative=True, density=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188f1d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "rc('figure',figsize=(12,8))\n",
    "xx = 0.5 * (a[1][1:]+a[1][0:-1])\n",
    "plot(xx,a[0])\n",
    "val2sig = np.interp(2., xx,a[0])\n",
    "plot([2,2],[0,val2sig],':',color='g')\n",
    "plot([0,2],[val2sig,val2sig],':',color='g', label='Compatible with XPol=0 at 2 $\\sigma$: {0:3.1f}% '.format(val2sig*100))\n",
    "legend()\n",
    "xlim(0,3)\n",
    "ylim(0,1.)\n",
    "xlabel('Xpol/$\\sigma$(Xpol)')\n",
    "ylabel('Cumulative counts')\n",
    "title('Passing cuts: {} TES out of 256'.format(np.sum(ok)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1789ca2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "numdets = np.arange(256)+1\n",
    "selected_dets = numdets[ok]\n",
    "\n",
    "has_xpol = ok & (allintervals_CL[:,0] == 0.68)\n",
    "print(np.sum(has_xpol))\n",
    "\n",
    "selected_dets\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d5111a",
   "metadata": {},
   "outputs": [],
   "source": [
    "numdets[has_xpol]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bfcae98",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = ft.image_asics(all1=has_xpol)\n",
    "imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c89f1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = ft.image_asics(all1=ok)\n",
    "imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "694d6133",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
