{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bffb3ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import matplotlib as mp#.pyplot as plt\n",
    "#!conda install -c conda-forge matplotlib\n",
    "#!conda activate qubic_python38\n",
    "#!source qubic_python38/bin/activate\n",
    "#!conda env list\n",
    "#import matplotlib\n",
    "#matplotlib.use('Agg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2416b84",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "rc('figure',figsize=(9,4.5))\n",
    "rc('font',size=12)\n",
    "rc('text',usetex=False)\n",
    "rc('axes', facecolor = 'white')\n",
    "rc('savefig', facecolor = 'white')\n",
    "\n",
    "from qubicpack.qubicfp import qubicfp\n",
    "import qubicpack as qp\n",
    "from pysimulators import FitsArray\n",
    "from qubicpack.utilities import TES_index, figure_window_title\n",
    "from qubicpack.timeline import timeline_timeaxis\n",
    "from qubicpack.utilities import qc_utc_date\n",
    "\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import warnings\n",
    "import matplotlib.cm as cm\n",
    "import warnings\n",
    "\n",
    "# To fit===================================\n",
    "# everything in iminuit is done through the Minuit object, so we import it\n",
    "from iminuit import Minuit\n",
    "\n",
    "#import pywt\n",
    "\n",
    "# we also need a cost function to fit and import the LeastSquares function\n",
    "from iminuit.cost import LeastSquares\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.interpolate import interp1d\n",
    "#==========================================\n",
    "#import string\n",
    "import scipy.signal as scsig\n",
    "from scipy import interpolate\n",
    "from astropy.io import fits as pyfits\n",
    "\n",
    "#from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import datetime as dt\n",
    "import pickle\n",
    "from importlib import reload\n",
    "import datetime\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bdb03df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def verbosity_files(day, dirs, kwd0, ifile, setup = True):\n",
    "    if setup:\n",
    "        if ifile == 0:\n",
    "            print('===================================')\n",
    "            print('day {} - has {} files of {} test'. format(day, \n",
    "                                                         len(dirs), \n",
    "                                                         kwd0))\n",
    "        else:\n",
    "            if dirs[ifile][57:70] != kwd0:\n",
    "                kwd0 = dirs[ifile][57:70]\n",
    "                print('===================================')\n",
    "                print('day {} - has {} files of {} test'. format(day, \n",
    "                                                         len(dirs), \n",
    "                                                         dirs[ifile][57:])) \n",
    "        return\n",
    "    else:\n",
    "        return\n",
    "# Fit\n",
    "#model\n",
    "# our line model, unicode parameter names are supported :)\n",
    "def line(x, a, b):\n",
    "    return b + x * a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7416aeb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#words = ['timeconstant', 'TimeCst']\n",
    "#keyword = ['*{}*'.format(word) for word in words]\n",
    "#print(keyword)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2b23a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### === Check the existence of old calsource datasets\n",
    "## =====\n",
    "##\n",
    "\n",
    "#day = '2019-04-12'\n",
    "#keyword = '*ScanFreq*'\n",
    "#data_dir = '/sps/qubic/Data/Calib-TD/'+day+'/'\n",
    "#dirs = np.sort(glob.glob(data_dir+keyword))\n",
    "##print(dirs)        \n",
    "#thedir = dirs[0]\n",
    "\n",
    "#a = qubicfp()\n",
    "#a.read_qubicstudio_dataset(thedir)\n",
    "#datacal = '/sps/qubic/Data/Calib-TD/calsource/*'\n",
    "##glob.glob(datacal + \"*{}*.fits\".format('2019-06-'.replace(\"-\", \"\")))\n",
    "##glob.glob('/sps/qubic/Data/Calib-TD/calsource/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "695a813f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#def read_calsource_data(qubic_fp, date = None, \n",
    "#\t\t\t\t\t\tkeyword = None, datadir = None,\n",
    "#\t\t\t\t\t\tdatacal = None, verbose = False):\n",
    "##\n",
    "#\t\"\"\"\n",
    "#\tThis method read the calibration source data using qubicpack. The data was stored in a different way before \n",
    "#\tNov 2019 and after Nov 2019 that's why you will find there are two ways to find and read the data.\n",
    "#\n",
    "#\tqubic_fp: \n",
    "#\t\t\tqubicfp class. Focal plane of QUBIC build using qubicpack\n",
    "#\tdate: \n",
    "#\t\t\tstring. YYYY-MM-DD of the scan\n",
    "#\tkeyword:\n",
    "#\t\t\tstring. keyword used in the scan\n",
    "#\tdatadir: \n",
    "#\t\t\tstring. Root directory where RAW TOD is placed (the one where dirs for each scan are).\n",
    "#\tdatacal:\n",
    "#\t\t\tstring. Root directory where calibration data is placed. This argument is only need it\n",
    "#\t\t\twhen you are reading data before Nov 2019 (arround 10th) and this data is usually saved in\n",
    "#\t\t\t\"calsource\" directory. The format of the files are \"calsource_YYYYMMDDTHHMMSS.fits\"\n",
    "#\t===============\n",
    "#\treturn:\n",
    "#\t\t\tcalsource_time and calsource_data. Time and data of the calibration source\n",
    "#\t\"\"\"\n",
    "\n",
    "#\tif not isinstance(date, str) or not isinstance(keyword, str) or not isinstance(datadir, str):\n",
    "#\t\traise ValueError(\"date, key or datadir is not {} class\".format(str))\n",
    "#\tif not isinstance(qubic_fp, qubicfp):\n",
    "#\t\traise ValueError(\"qubic_fp is not the right class: {}\".format(qubicfp().__class__))\n",
    "\n",
    "#\ttry:\n",
    "#\t\tos.path.isdir(datadir)\n",
    "#\texcept:\n",
    "#\t\traise ValueError(\"[path problem] datadir does not exist in your machine: {}\".format(datadir))\n",
    "\n",
    "#\tdirs = np.sort(glob.glob(datadir + keyword))\n",
    "\n",
    "#\tif int(date.replace(\"-\", \"\")) > 20191110:\n",
    "#\t\tif verbose: print(\"Reading calibration source. Date: {}\".format(date))\n",
    "#\t\tcalsource_time = qubic_fp.calsource()[0]\n",
    "#\t\tcalsource_data = qubic_fp.calsource()[1]\n",
    "\n",
    "#\t\treturn calsource_time, calsource_data\n",
    "#\t\t\n",
    "#\telif int(date.replace(\"-\", \"\")) < 20191110:\n",
    "#\t\tif verbose: print(\"Reading calibration source. Date: {}\".format(date))\n",
    "#\t\twarnings.warn(\"The format of this kind of files has some tricks to read and plot, keep that in mind.\",\n",
    "#\t\t\t\t\t\tUserWarning, stacklevel=2)\n",
    "#\t\tif datacal == None: \n",
    "#\t\t\traise ValueError(\"[path problem] You have to provide a directory where the calsource data is.\")\n",
    "#\t\ttry:\n",
    "#\t\t\tos.path.isdir(datacal)\n",
    "#\t\texcept:\n",
    "#\t\t\traise ValueError(\"[path problem] datacal does not exist in your machine: {}\".format(datacal))\n",
    "\n",
    "#\t\tfilesname = glob.glob(datacal + \"*{}*.fits\".format(date.replace(\"-\", \"\")))\n",
    "#\t\tcalsource_time, calsource_data = [], []\n",
    "\n",
    "#\t\tfor j, eachfile in enumerate(filesname):\n",
    "#\t\t\thdufile = pyfits.open(eachfile)\n",
    "#\t\t\tif j == 0: \n",
    "#\t\t\t\tif verbose: print (\"Creating 'CALSOURCE' key in Qubic Focal Plane object \")\n",
    "#\t\t\thdu = qubic_fp.read_calsource_fits(hdufile[1])\n",
    "#\t\t\tcalsource_time.append(qubic_fp.hk['CALSOURCE']['timestamp'])\n",
    "#\t\t\tcalsource_data.append(qubic_fp.hk['CALSOURCE']['Value'])\n",
    "#\t\n",
    "#\t\treturn np.concatenate(calsource_time[:]), np.concatenate(calsource_data[:])\n",
    "#\telse:\n",
    "#\t\traise ValueError(\"The day argument is not in the correct format 'YYYY-MM-DD'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376f2d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tt,dat = read_calsource_data(a, date = day, \n",
    "#                    keyword = keyword, datadir = data_dir,\n",
    "#                    datacal = data_dir+'../calsource/', verbose = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd1bc499",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.figure(figsize = (12,6))\n",
    "#plt.title('Calsource data - day = {}'.format(day))\n",
    "#plt.plot(tt, dat, 'r.')\n",
    "#plt.xlabel(\"time\")\n",
    "#plt.ylabel(\"value\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b94a9c6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#days = ['2022-{}-{}'.format(str(i).zfill(2), str(j).zfill(2))) for i in range(7,9) for j in range(13,32)]\n",
    "start = datetime.datetime.strptime(\"14-07-2022\", \"%d-%m-%Y\")\n",
    "end = datetime.datetime.strptime(\"14-07-2022\", \"%d-%m-%Y\")\n",
    "date_generated = pd.date_range(start, end = end)# periods=5)\n",
    "days = date_generated.strftime(\"%Y-%m-%d\").to_list() \n",
    "print('Days to read data', days)\n",
    "\n",
    "words = ['MoonScan']#, 'hwp']\n",
    "keywords = ['*{}*'.format(word) for word in words]\n",
    "#keywords = ['*']\n",
    "#filenames = []\n",
    "\n",
    "addfile = 0\n",
    "\n",
    "# container of data\n",
    "DataContainer = {}\n",
    "alldays = []\n",
    "onlycountfiles = True\n",
    "for keyword in keywords:\n",
    "    for day in days:\n",
    "        #data_dir = '/sps/qubic/Data/Calib-TD/'+day+'/'\n",
    "        data_dir = '/home/mgamboa/qubic/Data/Calib-TD/'+day+'/'\n",
    "        dirs = np.sort(glob.glob(data_dir+keyword))\n",
    "        #print (dirs)\n",
    "        if len(dirs) == 0:\n",
    "            pass\n",
    "        else:\n",
    "            # Create a keyword with the day within the container\n",
    "            DataContainer['{}'.format(day)] = {}\n",
    "            auxdata = []\n",
    "\n",
    "            # Load the focal plane\n",
    "            #loop in dirs\n",
    "            kwd0 = dirs[0][57:]\n",
    "            filenames = []\n",
    "            for ifile in range(0, len(dirs)):\n",
    "                #ifile = 4 if day == '2022-07-13' else 0\n",
    "                print(ifile)\n",
    "                #loop in keyword for same day\n",
    "                # Printout\n",
    "                verbosity_files(day, dirs, kwd0, ifile, setup = True)\n",
    "\n",
    "                addfile += 1\n",
    "\n",
    "                thedir = dirs[ifile]\n",
    "                if keyword == '*':\n",
    "                    #print('================', thedir[57:],) if ifile == 0 else None\n",
    "                    auxdata = None\n",
    "                    filenames.append(thedir[57:])\n",
    "                else:\n",
    "                    locals()['qfp{}_{}'.format(day.replace('-',''),ifile)] = qubicfp()\n",
    "                    locals()['qfp{}_{}'.format(day.replace('-',''),ifile)].assign_verbosity(1)\n",
    "                    locals()['qfp{}_{}'.format(day.replace('-',''),ifile)].read_qubicstudio_dataset(thedir)\n",
    "                    auxdata.append(locals()['qfp{}_{}'.format(day.replace('-',''),ifile)])\n",
    "                    filenames.append(thedir)\n",
    "            alldays.append(day)\n",
    "            DataContainer.update({'{}'.format(day): auxdata, 'fnames{}'.format(day): filenames})\n",
    "DataContainer.update({'kwdays': alldays})\n",
    "\n",
    "print('There are {} files'.format(addfile))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c46784",
   "metadata": {},
   "source": [
    "See what keys() do we have into DataContainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa940bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## If you searched for all datasets to count filenames comment out this cell to \n",
    "##know the names of each daily campaing and datasets\n",
    "\n",
    "#allfilenames = []\n",
    "#for istr in filenames:\n",
    "#    emp_str = \"\"\n",
    "#    for m in istr:\n",
    "#        if not m.isdigit():\n",
    "#            emp_str = emp_str + m\n",
    "#    allfilenames.append(emp_str)\n",
    "#print(\"Total files\", len(allfilenames))\n",
    "#for i in set(allfilenames):\n",
    "#    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a53167",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(DataContainer.keys())\n",
    "#len(DataContainer['2022-08-18'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa09103",
   "metadata": {},
   "source": [
    "### Plot 300mK temperatures for each dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361c007c",
   "metadata": {},
   "outputs": [],
   "source": [
    "####\n",
    "###\n",
    "##\n",
    "##     Sketchplot\n",
    "## \n",
    "#x = np.linspace(0,300,num = 200)\n",
    "#y = 300 + 150*np.random.rand(x.shape[0],)\n",
    "#threshold = 345\n",
    "#maski = y < threshold\n",
    "#masku = y >= threshold\n",
    "\n",
    "#plt.text(10,380, 'flag_i = 0.', backgroundcolor = 'w', bbox=dict(facecolor='white', alpha=1), fontsize = 'large')\n",
    "#plt.axhline(threshold, ls = '--', lw = 3, color = 'k')\n",
    "#plt.plot(x[maski],y[maski],color = 'darkgreen', marker = 'o', ls = '', alpha = 0.7)\n",
    "\n",
    "#plt.plot(x[masku],y[masku],color = 'darkred', marker = 'o', ls = '', alpha = 0.7)\n",
    "#plt.text(10,320, 'flag_ = 1.', backgroundcolor = 'w', bbox=dict(facecolor='white', alpha=1), fontsize = 'large')\n",
    "#plt.ylabel('Temperature (T)')\n",
    "#plt.xlabel('time')\n",
    "\n",
    "#ylim = plt.gca().get_ylim()\n",
    "#plt.axhspan(threshold, ylim[1], color = 'r', alpha = 0.1)\n",
    "\n",
    "#plt.savefig('example')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "400a55c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "listdays = list(set(DataContainer['kwdays']))\n",
    "print(listdays)\n",
    "wit = DataContainer[listdays[0]][0]\n",
    "ax = plt.subplot(111)\n",
    "fa = wit.plot_300mKtemperatures(ax = ax)\n",
    "axleg = ax.get_legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8908c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### ax = plt.subplot(111)\n",
    "#from qubicpack.utilities import qc_utc_date\n",
    "\n",
    "##wit.plot_temperatures(ax,{'AVS47_1_CH6': '0.3K fridge CH'},'300mK Temperatures',12) \n",
    "## get time\n",
    "#time_hk = wit.get_hk(data='RaspberryDate',hk='EXTERN_HK')\n",
    "#data_hk = wit.get_hk('AVS47_1_CH6')\n",
    "#tdate = []\n",
    "## qubic-central was changed to UTC on 2020-02-27\n",
    "#if time_hk[0] > float(qc_utc_date.strftime('%s.%f')):\n",
    "#    for tstamp in time_hk:\n",
    "#        tdate.append(dt.datetime.utcfromtimestamp(tstamp))\n",
    "#ax.plot(time_hk,data_hk, 'D',markersize=0.4*12)\n",
    "#ax.set_ylabel('Temperature / K',fontsize=12)\n",
    "#ax.set_xlabel('Date / UT',fontsize=12)\n",
    "#linepars, linecov = curve_fit(line, time_hk, data_hk)\n",
    "#ax.plot(time_hk, line(time_hk, linepars[0], linepars[1]), 'k-', lw =2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db699715",
   "metadata": {},
   "source": [
    "iminuit does not work (error when computing hesse and migrad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "196207e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## iminuit contains a LeastSquares class to conveniently generate a least-squares cost function.\n",
    "## We will revisit how to write this by hand in a later section.\n",
    "#yerr = 0.1 * np.random.randn(len(data_hk))\n",
    "#least_squares = LeastSquares(time_hk, data_hk, 1, line)\n",
    "#m = Minuit(least_squares, a = 0., b = 0.)  # starting values for α and β\n",
    "#m.migrad()  # finds minimum of least_squares function\n",
    "#m.hesse()   # accurately computes uncertainties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82af4ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (15,9))\n",
    "\n",
    "for j, day in enumerate(list(set(DataContainer['kwdays']))):\n",
    "    locals()['ax{}'.format(j)] = plt.subplot(len(set(DataContainer['kwdays'])), 1, j+1)\n",
    "    auxax = locals()['ax{}'.format(j)]\n",
    "    print('index, day', j, day)\n",
    "    for idata in DataContainer['{}'.format(day)]:\n",
    "        idata.plot_temperatures(auxax,{'AVS47_1_CH6': '0.3K fridge CH'},'300mK Temperatures',12)   \n",
    "        #idata.plot_temperatures(auxax,{'AVS47_1_ch1': '1K stage'},'1K stage',12)   \n",
    "        #idata.plot_azel(ax = auxax)\n",
    "    auxax.get_legend().remove()\n",
    "    #auxax.set_ylim(0.910,1.365)\n",
    "    auxax.set_ylim(0.310,0.365)\n",
    "    auxax.axhspan(0.330,0.340, color = 'r', alpha = 0.05)\n",
    "    auxax.axhspan(0.340,0.350, color = 'r', alpha = 0.1)\n",
    "    auxax.axhspan(0.350,0.365, color = 'r', alpha = 0.2)\n",
    "    \n",
    "    #auxax.axhline(0.345, ls = '--', color = 'k', alpha = 0.4)\n",
    "    #auxax.plot()\n",
    "    auxax.set_title('{}'.format(day))\n",
    "    \n",
    "plt.tight_layout()\n",
    "#plt.savefig('300mKStage_{}_diffDays'.format(words[0]) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b00d9911",
   "metadata": {},
   "source": [
    "## Fit data and plot 300mK or 1K stage\n",
    "\n",
    "### 300mK stage (channels)\n",
    "* ['AVS47_1_CH2'] = 'TES stage RIRT'\n",
    "* ['AVS47_1_CH5'] = 'Film breaker'\n",
    "* ['AVS47_1_CH6'] = '0.3K fridge CH'\n",
    "\n",
    "### 1K stage (channels)\n",
    "* ['AVS47_1_ch1'] = '1K stage'\n",
    "* ['AVS47_1_ch3'] = 'M1'\n",
    "* ['AVS47_1_ch4'] = '1K fridge CH'\n",
    "* ['AVS47_1_ch7'] = 'M2'\n",
    "* ['AVS47_2_ch0'] = 'PT2 S2 CH'\n",
    "* ['AVS47_2_ch2'] = 'Fridge plate MHS'\n",
    "* ['AVS47_2_ch3'] = '1K stage back'\n",
    "* ['AVS47_2_ch4'] = '4K shield Cu braids'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f7ea26",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save dict with channels and labels\n",
    "labeldict = {'AVS47_1_CH2': 'TES stage RIRT', 'AVS47_1_CH5': 'Film breaker', 'AVS47_1_CH6': '0.3K fridge CH',\n",
    "    'AVS47_1_ch1': '1K stage', 'AVS47_1_ch3': 'M1', 'AVS47_1_ch4': '1K fridge CH', 'AVS47_1_ch7': 'M2', 'AVS47_2_ch0': 'PT2 S2 CH',\n",
    "    'AVS47_2_ch2': 'Fridge plate MHS', 'AVS47_2_ch3': '1K stage back', 'AVS47_2_ch4': '4K shield Cu braids'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ed370c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flag_bathtemp(dataset, T_bit37 = 0.330, T_bit38 = 0.340, T_bit39 = 0.350, verbose = False):\n",
    "    \n",
    "    \"\"\"\n",
    "    ======================\n",
    "    Arguments:\n",
    "        dataset: TOD\n",
    "        T_bitXX [in K]: Temperature from which the sample is flagged. XX is the corresponding bit for that flag.\n",
    "    Returns:\n",
    "        Flagged array [same size as TOD]\n",
    "        \n",
    "    The flags are set for each timesample and considering if the temperature is above 330mK, above 340mK and above 350mK.\n",
    "    The corresponding flagid is 37, 38 and 39 respectively and the computation is\n",
    "    flag_i = bit37*2**37 + bit38*2**38 + bit39*2**39\n",
    "    \"\"\"\n",
    "    \n",
    "    def bitid_300mK(T):\n",
    "        # Return an integer\n",
    "        return (int(T > T_bit37) & int(T < T_bit38)) * 2**37 + \\\n",
    "               (int(T > T_bit38) & int(T < T_bit39)) * 2**38 + \\\n",
    "               int(T > T_bit39) * 2**39\n",
    "\n",
    "    flags300mK = list(map(bitid_300mK, dataset))\n",
    "    \n",
    "    return np.array(flags300mK, dtype = np.int64)\n",
    "\n",
    "def flag_bathtemp_rise(dataset, verbose = False):\n",
    "    \n",
    "    \"\"\"\n",
    "    ======================\n",
    "    Arguments:\n",
    "        dataset: TOD\n",
    "        Verbose: boolean\n",
    "    Returns:\n",
    "        Flagged array [same size as TOD]. The last value is equal to the previous one in ordcer to have the same dimenssion of arrays\n",
    "        \n",
    "    A timestamp is flagged if the timestamp has a higher temperature compared with the previous timestamp value (interpolated using tod()[0].\n",
    "    The corresponding flagid is 36,\n",
    "    flag_i = bit36*2**36\n",
    "    \"\"\"\n",
    "\n",
    "    signflag = np.zeros_like(dataset)\n",
    "    # Compute the difference in temperature between consecutive timestamps\n",
    "    #  + Get the sign (+ --> temperature rising, - --> temperature decreasing)\n",
    "    signflag[:-1] = np.sign(np.diff(dataset))\n",
    "    signflag[-1] = signflag[-2]\n",
    "    # \n",
    "    \n",
    "    def bitid_rise300mK(T):\n",
    "        # Return an integer\n",
    "        return (int(T > 0) * 2**36)\n",
    "    \n",
    "    flag300mKRise = list(map(bitid_rise300mK, signflag))\n",
    "    \n",
    "    return np.array(flag300mKRise, dtype = np.int64)\n",
    "\n",
    "def flag_1Ktemp(dataset, T_bit31 = 1.1, T_bit32 = 1.2, T_bit33 = 1.3, verbose = False):\n",
    "    \n",
    "    \"\"\"\n",
    "    ======================\n",
    "    Arguments:\n",
    "        dataset: TOD\n",
    "        T_bitXX [in K]: Temperature from which the sample is flagged. XX is the corresponding bit for that flag.\n",
    "    Returns:\n",
    "        Flagged array [same size as TOD]\n",
    "        \n",
    "    The flags are set for each timesample and considering if the temperature is above 1.1K, above 1.2K and above 1.3K.\n",
    "    The corresponding flagid is 31, 32 and 33 respectively and the computation is\n",
    "    flag_i = bit31*2**31 + bit32*2**32 + bit33*2**39\n",
    "    \"\"\"\n",
    "\n",
    "    def bitid_1K(T):\n",
    "        # Return an integer\n",
    "        return (int(T > T_bit31) & int(T < T_bit32)) * 2**31 + \\\n",
    "               (int(T > T_bit32) & int(T < T_bit33)) * 2**32 + \\\n",
    "               int(T > T_bit33) * 2**33\n",
    "\n",
    "    flags1K = list(map(bitid_1K, dataset))\n",
    "    \n",
    "    return np.array(flags1K, dtype = np.int64)\n",
    "\n",
    "def flag_1Ktemp_rise(dataset, verbose = False):\n",
    "    \n",
    "    \"\"\"\n",
    "    ======================\n",
    "    Arguments:\n",
    "        dataset: TOD\n",
    "        Verbose: boolean\n",
    "    Returns:\n",
    "        Flagged array [same size as TOD]. The last value is equal to the previous one in ordcer to have the same dimenssion of arrays\n",
    "        \n",
    "    A timestamp is flagged if the timestamp has a higher temperature compared with the previous timestamp value (interpolated using tod()[0].\n",
    "    The corresponding flagid is 30,\n",
    "    flag_i = bit30*2**30\n",
    "    \"\"\"\n",
    "\n",
    "    signflag = np.zeros_like(dataset)\n",
    "    # Compute the difference in temperature between consecutive timestamps\n",
    "    #  + Get the sign (+ --> temperature rising, - --> temperature decreasing)\n",
    "    signflag[:-1] = np.sign(np.diff(dataset))\n",
    "    signflag[-1] = signflag[-2]\n",
    "    # \n",
    "    \n",
    "    def bitid_rise1K(T):\n",
    "        # Return an integer\n",
    "        return (int(T > 0) * 2**30)\n",
    "    \n",
    "    flag1KRise = list(map(bitid_rise1K, signflag))\n",
    "    \n",
    "    return np.array(flag1KRise, dtype = np.int64)\n",
    "\n",
    "class FlagToMask(): \n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        This method aims to mask the data according to user requirements. \n",
    "\n",
    "        The posible flags are:  'saturation', 'cosmic ray', 'uncorrelated flux jumps', 'end of scan',\n",
    "                    'Tbath above 330mK', 'Tbath above 340mK', 'Tbath above 350mK', 'Tbath rising',\n",
    "                    '1K above 1.1K', '1K above 1.2K', '1K above 1.3K', '1K rising',\n",
    "                    'correlated flux jumps'\n",
    "\n",
    "        ==============\n",
    "        Arguments:\n",
    "            flagarray: \n",
    "                    Array of 64-bit integers for a specific flag. It can be use an array of flags.\n",
    "            userflag: Default values for each key = False\n",
    "                    Dictionary with boolean values with user requirements \n",
    "        =========================\n",
    "        Return:\n",
    "            maskedata: \n",
    "                    Masked dataset\n",
    "\n",
    "        =========================\n",
    "        Example:\n",
    "            If we have just five timesamples with the following features: \n",
    "                    saturated + Tbath 335mK, Tbath 380mK, 1K rising, no flag data, Tbath 345mK\n",
    "\n",
    "            #Consider you read the files with the flagged arrays and add each array properly (TBD), you would get \n",
    "\n",
    "            flagarray = np.array([2**63 + 2**37, 2**39, 2**30, 0, 2**38])\n",
    "\n",
    "            #or\n",
    "\n",
    "            flagarray = np.array([9223372174293729280, 549755813888, 1073741824, 0, 274877906944])\n",
    "\n",
    "            # Now, you requirements for the flagged array are: Not saturated TES and Tbath below 350mK:\n",
    "\n",
    "            maskdict = {'saturation': True, 'Tbath above 350mK': True}\n",
    "\n",
    "            maskarray = MaskDataWithFlags(flagarray, maskdict) \n",
    "            #--> returns a mask with the timesamples that satisfy the requirements\n",
    "            print(maskarray)\n",
    "            out: np.array([0, 0, 1, 1, 1])\n",
    "        \"\"\"\n",
    "\n",
    "        # Testing initialization \n",
    "        self.FullFlags = {'saturation': False, 'cosmic ray': False, 'uncorrelated flux jumps': False, 'end of scan': False,\n",
    "                    'Tbath above 330mK': False, 'Tbath above 340mK': False, 'Tbath above 350mK': False, 'Tbath rising': False,\n",
    "                    '1K above 1.1K': False, '1K above 1.2K': False, '1K above 1.3K': False, '1K rising': False,\n",
    "                    'correlated flux jumps': False}\n",
    "        # Bit correspondance\n",
    "        self.BitFlags = {'saturation': 63, 'cosmic ray': 57, 'uncorrelated flux jumps': 51, 'end of scan': 45,\n",
    "                    'Tbath above 350mK': 39, 'Tbath above 340mK': 38, 'Tbath above 330mK': 37, 'Tbath rising': 36,\n",
    "                    '1K above 1.1K': 31, '1K above 1.2K': 32, '1K above 1.3K': 33, '1K rising': 30,\n",
    "                    'correlated flux jumps': 27}\n",
    "    def __call__(self, flagarray, userflags):#, **newflags):)\n",
    "        # Update dictionary with user requirements\n",
    "        self.FullFlags.update(userflags)\n",
    "\n",
    "        # Create an empty mask as it's all data OK (= 0 for each timesample)\n",
    "        # Loook at the requirements\n",
    "        BitIds = []\n",
    "        for iflag in self.FullFlags.keys():\n",
    "            if self.FullFlags[iflag]:\n",
    "                BitIds.append(self.BitFlags[iflag])\n",
    "\n",
    "        #Mask one sample through a function\n",
    "        def masksample(iflagarray, BitIds = BitIds):\n",
    "            return [not bool((int(iflagarray) & int(2**bit)) >> int(bit)) for bit in BitIds]\n",
    "\n",
    "        MaskData = list(map(masksample, flagarray))\n",
    "\n",
    "        return np.prod(MaskData, axis = 1, dtype = bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2832b183",
   "metadata": {},
   "outputs": [],
   "source": [
    "flagarray = np.array([int(9223372174293729280), int(549755813888), int(1073741824), int(0), int(274877906944)])\n",
    "maskdict = {'saturation': False, 'Tbath above 350mK': True}\n",
    "testclass = FlagToMask()\n",
    "\n",
    "testclass(flagarray, maskdict)\n",
    "print(type(testclass(flagarray, maskdict)[1]))\n",
    "#[bool((egflag & bidflag[j]) >> bidbit[j]) for j in range(2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "501479b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with real dataset\n",
    "#\n",
    "# Read dataset\n",
    "iday = days[0]\n",
    "testime = np.copy(DataContainer[iday][0].get_hk(data='RaspberryDate',hk='EXTERN_HK'))\n",
    "label300mK = 'AVS47_1_CH6' #300mK\n",
    "label1K = 'AVS47_1_ch1' # 1K\n",
    "testdata300mK = np.copy(DataContainer[iday][0].get_hk(label300mK))\n",
    "testdata1K = np.copy(DataContainer[iday][0].get_hk(label1K))\n",
    "\n",
    "flags300mK = flag_bathtemp(testdata300mK)\n",
    "flags1K = flag_1Ktemp(testdata1K)\n",
    "\n",
    "totalflags = flags300mK + flags1K\n",
    "#remove outliers to fit\n",
    "maskdict = {'saturation': False, 'Tbath above 330mK': True}\n",
    "initmask = FlagToMask()\n",
    "MaskedTemp = initmask(totalflags, maskdict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "563cad43",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Compare LOOP vs map. Map is slower but probably better when run in parallel CPU's\n",
    "#arrsize = [1e1,1e2,1e3,1e4,1e5,1e6,1e7,1e8] \n",
    "#tloop, tmap = [], []\n",
    "#for i in arrsize:\n",
    "#    fakedata = 300 + 150*np.random.rand((int(i)),)\n",
    "#    bb, itloop, itmap = flag_bathtemp(fakedata)\n",
    "#    tloop.append(itloop)\n",
    "#    tmap.append(itmap)\n",
    "#plt.plot(arrsize, tloop, 'r-', lw = 2, label = 'loop')\n",
    "#plt.plot(arrsize, tmap, 'b-', lw = 2, label = 'map')\n",
    "#plt.xscale(\"log\")\n",
    "#plt.yscale(\"log\")\n",
    "#plt.xlabel(\"Array size [log]\", fontsize = 16)\n",
    "#plt.ylabel(\"time[sec]\", fontsize = 16)\n",
    "#plt.legend(fontsize = 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b76ee70",
   "metadata": {},
   "outputs": [],
   "source": [
    "#OLD CODE\n",
    "#if len(maskl) == 0:\n",
    "#        if verbose: print(r'There are no samples with themperature lower than T_L = {:4.3f}. \\n BAD DATASET'.format(Tlim))\n",
    "#        pass\n",
    "#    else:\n",
    "#        flag_i[maskl] = 0\n",
    "#        #print('low', np.mean(scores_i[maskl]))\n",
    "#        \n",
    "#    maskh = np.where(dataset >= Tlim)[0]\n",
    "#    if len(maskh) == 0:\n",
    "#        if verbose: print(r'There are no samples with themperature higher than T_L = {:4.3f}. \\n GOOD DATASET'.format(Tlim))\n",
    "#        pass\n",
    "#    else:\n",
    "#       flag_i[maskh] = 1.\n",
    "#       #print('high', np.mean(scores_i[maskh]))\n",
    "#    \n",
    "#    return flag_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbbe50d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_tilttemp(timeset, dataset, verbose = False, maxfev = 8000):\n",
    "    linepars, linecov = curve_fit(line, timeset, dataset, maxfev = maxfev)\n",
    "    score = np.cos(np.arctan(linepars[0]))\n",
    "    if verbose: print(score)\n",
    "    return linepars, score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a85a1c",
   "metadata": {},
   "source": [
    "Take a look to a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da11fea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_outliers(timeset, dataset, channel):\n",
    "    \n",
    "    if channel == 'AVS47_1_CH6': #300mK stage\n",
    "        threshold = 10.\n",
    "    elif channel == 'AVS47_1_ch1': #1K stage\n",
    "        threshold = 1000.\n",
    "    else: \n",
    "        raise ValueError('No channel programed into this method. Possible values: \"AVS47_1_CH6\" or \"AVS47_1_ch1\"')\n",
    "    # Create mask\n",
    "    \n",
    "    mask = dataset > threshold\n",
    "    \n",
    "    # interpolation\n",
    "    ynew = np.interp(timeset[mask],timeset[~mask], dataset[~mask])\n",
    "    \n",
    "    # supplant values\n",
    "    dataset[mask] = ynew\n",
    "    if sum(mask) > 0:\n",
    "        warnings.warn('Outliers values detected')\n",
    "    return mask, dataset\n",
    "\n",
    "#### Example of what is implemented in detect_outliers\n",
    "#x = np.arange(0, 15, 1)\n",
    "#y = 300 + 150*np.random.rand(x.shape[0],)\n",
    "#y[5] = 1000\n",
    "#y[1] = 607\n",
    "#ith = 600\n",
    "#maskara = y > ith\n",
    "#plt.figure(figsize = (20,4))\n",
    "#plt.subplot(141)\n",
    "#plt.title('raw data')\n",
    "#plt.plot(x, y, 'ko')\n",
    "#plt.subplot(142)\n",
    "#plt.title('mark outlier')\n",
    "#plt.plot(x[~maskara], y[~maskara], 'ko')\n",
    "#plt.plot(x[maskara], y[maskara], 'ro', label = 'outlier')\n",
    "## interpolation\n",
    "#plt.subplot(143)\n",
    "#plt.title('show correction')\n",
    "#plt.plot(x[~maskara], y[~maskara], 'ko')\n",
    "#plt.plot(x[maskara], y[maskara], 'ro', label = 'outlier')\n",
    "#ynew = np.interp(x[maskara],x[~maskara],y[~maskara])\n",
    "#plt.plot(x[maskara], ynew, 'yo', label = 'outlier corrected')\n",
    "#plt.legend(fontsize = 'large')\n",
    "#ylim = plt.gca().get_ylim()\n",
    "## Supplant\n",
    "#plt.subplot(144)\n",
    "#plt.title('array corrected')\n",
    "#y[maskara] = ynew\n",
    "#plt.gca().set_ylim(ylim)\n",
    "#plt.plot(x, y, 'ko')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e06485b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(DataContainer[iday])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f3e8c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flag and score computation\n",
    "\n",
    "iday = days[0]\n",
    "\n",
    "# 'AVS47_1_CH6' 300mK or 'AVS47_1_ch1' 1K stage\n",
    "#label = 'AVS47_1_CH6'\n",
    "label = 'AVS47_1_ch1'\n",
    "if label == 'AVS47_1_ch1':\n",
    "    labelw = '1Kstage'\n",
    "    Tlim1 = 1.1 #K\n",
    "    Tlim2 = 1.2 #K\n",
    "    Tlim3 = 1.3 #K\n",
    "    yliml = 1.\n",
    "    ylimf = 1.4\n",
    "elif label == 'AVS47_1_CH6':\n",
    "    labelw = '300mKstage'\n",
    "    Tlim1 = 0.33 #mK\n",
    "    Tlim2 = 0.34 #mK\n",
    "    Tlim3 = 0.35 #mK\n",
    "    yliml = 0.31\n",
    "    ylimf = 0.36\n",
    "else: \n",
    "    labelw = 'Not specified labelw'\n",
    "    sys.exit()\n",
    "\n",
    "fig = plt.figure(figsize = (20,12))\n",
    "plt.suptitle('Experiment: {} - {} - {}'.format(words[0], labelw, iday))\n",
    "\n",
    "colors2 = cm.get_cmap('rainbow', len(DataContainer[iday]))(range(len(DataContainer[iday])))\n",
    "ylim = []\n",
    "for indx in range(len(DataContainer[iday])):\n",
    "    #indx = 0\n",
    "    testime = np.copy(DataContainer[iday][indx].get_hk(data='RaspberryDate',hk='EXTERN_HK'))\n",
    "    testdata = np.copy(DataContainer[iday][indx].get_hk(label))\n",
    "   \n",
    "    # Regular time (used to interpolate flags)\n",
    "    regtime = DataContainer[iday][indx].tod()[0]\n",
    "    # 1st/2nd Step\n",
    "    if label == 'AVS47_1_CH6':\n",
    "        flags300mK = flag_bathtemp(testdata)\n",
    "        # Flag rising temperature\n",
    "        flags300mK_rise = flag_bathtemp_rise(testdata)\n",
    "        \n",
    "        # Interpolation of the flags\n",
    "        flags_interp_300mK = np.max(np.array([interp1d(testime, flags300mK, kind='previous', fill_value='extrapolate')(regtime), \n",
    "                                              interp1d(testime, flags300mK, kind='next', fill_value='extrapolate')(regtime)]), axis=0)\n",
    "        flags_interp_300mK_rise = np.max(np.array([interp1d(testime, flags300mK_rise, kind='previous', fill_value='extrapolate')(regtime), \n",
    "                                              interp1d(testime, flags300mK_rise, kind='next', fill_value='extrapolate')(regtime)]), axis=0)\n",
    "        totalflags = flags300mK + flags300mK_rise\n",
    "        totalflags_interp = flags_interp_300mK + flags_interp_300mK_rise\n",
    "        \n",
    "    elif label == 'AVS47_1_ch1':\n",
    "        flags1K = flag_1Ktemp(testdata)\n",
    "        # Flag rising temperature\n",
    "        flags1K_rise = flag_1Ktemp_rise(testdata)\n",
    "\n",
    "        # Interpolation of the flags\n",
    "        flags_interp_1K = np.max(np.array([interp1d(testime, flags1K, kind='previous', fill_value='extrapolate')(regtime), \n",
    "                                              interp1d(testime, flags1K, kind='next', fill_value='extrapolate')(regtime)]), axis=0)\n",
    "        flags_interp_1K_rise = np.max(np.array([interp1d(testime, flags1K_rise, kind='previous', fill_value='extrapolate')(regtime), \n",
    "                                              interp1d(testime, flags1K_rise, kind='next', fill_value='extrapolate')(regtime)]), axis=0)\n",
    "        totalflags = flags1K + flags1K_rise\n",
    "        totalflags_interp = flags_interp_1K + flags_interp_1K_rise\n",
    "    \n",
    "    #totalflags = flags300mK + flags1K\n",
    "    #totalflags_interp = flags_interp_300mK + flags_interp_1K\n",
    "\n",
    "    ##remove outliers to fit\n",
    "    # 1st Step\n",
    "    # Detect and mask the outliers \n",
    "    maskoutliers, newdata = detect_outliers(testime, testdata, label)\n",
    "    lpars, Stilt = score_tilttemp(testime, newdata)\n",
    "    \n",
    "    #plt.figure()\n",
    "    plt.subplot(221)\n",
    "    plt.plot(testime, testdata, 'o', color = colors2[indx],)\n",
    "    plt.ylim(yliml,ylimf)\n",
    "    plt.ylabel('Temperature [K]')\n",
    "    if indx == len(DataContainer[iday])-1:\n",
    "        plt.axhspan(Tlim1, Tlim2, color = 'r', alpha = 0.05) #, label = 'flag zone = 0')\n",
    "        plt.axhspan(Tlim2, Tlim3, color = 'r', alpha = 0.1) #, label = 'flag zone = 0')\n",
    "        plt.axhspan(Tlim3, ylimf, color = 'r', alpha = 0.2) #, label = 'flag zone = 0')\n",
    "\n",
    "    plt.subplot(222)\n",
    "    plt.title('tod() timestamps')\n",
    "    plt.ylabel('Temperature flag value')\n",
    "    if label == 'AVS47_1_CH6':\n",
    "        plt.scatter(regtime, flags_interp_300mK, color = colors2[indx], label='Interpolated Flags' if indx == 0 else ' ')\n",
    "        plt.scatter(testime, flags300mK, color = 'b', label='Initial Flags' if indx == 0 else ' ')\n",
    "    elif label == 'AVS47_1_ch1':\n",
    "        plt.scatter(regtime, flags_interp_1K, color = colors2[indx], label='Interpolated Flags' if indx == 0 else ' ')\n",
    "        plt.scatter(testime, flags1K, color = 'r', label='Initial Flags' if indx == 0 else ' ')\n",
    "    plt.xlabel('Time (sec)')\n",
    "    #plt.legend(loc = 'upper right')\n",
    "    plt.subplot(223)\n",
    "    plt.title('is the temp rising?')\n",
    "    plt.ylabel('Flag value')\n",
    "    if label == 'AVS47_1_CH6':\n",
    "        plt.plot(regtime, flags_interp_300mK_rise, color = 'b', marker = '.', alpha =0.3, label='300mK' if indx ==0 else ' ', linestyle = ' ')\n",
    "    elif label == 'AVS47_1_ch1':\n",
    "        plt.plot(regtime, flags_interp_1K_rise, color = 'r', marker ='.', alpha = 0.3, label='1K' if indx == 0 else ' ', linestyle = ' ')\n",
    "    plt.xlabel('Time (sec)')\n",
    "    plt.subplot(224)\n",
    "    plt.title('Total flag for {}'.format(labelw))\n",
    "    plt.ylabel('Flag value')\n",
    "    if label == 'AVS47_1_CH6':\n",
    "        plt.plot(regtime, totalflags_interp, color = 'b', marker = '.', alpha =0.3, label='300mK' if indx ==0 else ' ', linestyle = ' ')\n",
    "    elif label == 'AVS47_1_ch1':\n",
    "        plt.plot(regtime, totalflags_interp, color = 'r', marker ='.', alpha = 0.3, label='1K' if indx == 0 else ' ', linestyle = ' ')\n",
    "    plt.xlabel('Time (sec)')\n",
    "    \n",
    "fig.tight_layout(pad=1.0)\n",
    "#plt.savefig('Flags_{}_{}_ind{}.png'.format(words[0], labelw, indx))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11284f9d",
   "metadata": {},
   "source": [
    "## Now flag 300mK and 1K jointly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74cc37be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Flag and score computation\n",
    "\n",
    "iday = days[0]\n",
    "\n",
    "# 'AVS47_1_CH6' 300mK or 'AVS47_1_ch1' 1K stage\n",
    "bothlabels = ['AVS47_1_CH6', 'AVS47_1_ch1']\n",
    "bothlabelw = ['300mKstage', '1Kstage']\n",
    "\n",
    "fig = plt.figure(figsize = (14,6))\n",
    "plt.suptitle('Experiment: {} - Total flags (300mK + 1K stages) - '.format(words[0]))\n",
    "\n",
    "totalflags = []\n",
    "totalflags_interp = []\n",
    "totaltime_interp = []\n",
    "rawtime = []\n",
    "\n",
    "colors2 = cm.get_cmap('rainbow', len(DataContainer[iday]))(range(len(DataContainer[iday])))\n",
    "for indx in range(len(DataContainer[iday])):\n",
    "    # Regular time (used to interpolate flags)\n",
    "    regtime = DataContainer[iday][indx].tod()[0]\n",
    "    totaltime_interp.append(regtime)\n",
    "\n",
    "    testime = np.copy(DataContainer[iday][indx].get_hk(data='RaspberryDate',hk='EXTERN_HK'))\n",
    "    rawtime.append(testime)\n",
    "    \n",
    "    for label in bothlabels: # loop in channels\n",
    "        #indx = 0\n",
    "        testdata = np.copy(DataContainer[iday][indx].get_hk(label))\n",
    "        \n",
    "        # 1st/2nd Step\n",
    "        if label == 'AVS47_1_CH6':\n",
    "            flags300mK = flag_bathtemp(testdata)\n",
    "            # Flag rising temperature\n",
    "            flags300mK_rise = flag_bathtemp_rise(testdata)\n",
    "\n",
    "            # Interpolation of the flags\n",
    "            flags_interp_300mK = np.max(np.array([interp1d(testime, flags300mK, kind='previous', fill_value='extrapolate')(regtime), \n",
    "                                                  interp1d(testime, flags300mK, kind='next', fill_value='extrapolate')(regtime)], dtype = np.int64), axis=0)\n",
    "            flags_interp_300mK_rise = np.max(np.array([interp1d(testime, flags300mK_rise, kind='previous', fill_value='extrapolate')(regtime), \n",
    "                                                  interp1d(testime, flags300mK_rise, kind='next', fill_value='extrapolate')(regtime)], dtype = np.int64), axis=0)\n",
    "            totalflags_300mK = flags300mK + flags300mK_rise\n",
    "            totalflags_300mK_interp = flags_interp_300mK + flags_interp_300mK_rise\n",
    "\n",
    "        elif label == 'AVS47_1_ch1':\n",
    "            flags1K = flag_1Ktemp(testdata)\n",
    "            # Flag rising temperature\n",
    "            flags1K_rise = flag_1Ktemp_rise(testdata)\n",
    "\n",
    "            # Interpolation of the flags\n",
    "            flags_interp_1K = np.max(np.array([interp1d(testime, flags1K, kind='previous', fill_value='extrapolate')(regtime), \n",
    "                                                  interp1d(testime, flags1K, kind='next', fill_value='extrapolate')(regtime)], dtype = np.int64), axis=0)\n",
    "            flags_interp_1K_rise = np.max(np.array([interp1d(testime, flags1K_rise, kind='previous', fill_value='extrapolate')(regtime), \n",
    "                                                  interp1d(testime, flags1K_rise, kind='next', fill_value='extrapolate')(regtime)], dtype = np.int64), axis=0)\n",
    "            totalflags_1K = flags1K + flags1K_rise\n",
    "            totalflags_1K_interp = flags_interp_1K + flags_interp_1K_rise\n",
    "\n",
    "    totalflags.append(totalflags_300mK + totalflags_1K)\n",
    "    totalflags_interp.append(totalflags_300mK_interp + totalflags_1K_interp)\n",
    "\n",
    "print(np.shape(rawtime), np.shape(totalflags), np.shape(totaltime_interp), np.shape(totalflags_interp))\n",
    "plt.ylabel('Flag value')\n",
    "plt.step(np.concatenate(rawtime), np.concatenate(totalflags), color = 'orange', alpha =0.3, label='no interp' if indx ==0 else ' ', linestyle = '-', lw = 3)\n",
    "plt.step(np.concatenate(totaltime_interp), np.concatenate(totalflags_interp), color = 'b', alpha = 0.3, label='interp' if indx == 0 else ' ', linestyle = '-', lw = 3)\n",
    "plt.xlabel('Time (sec)')\n",
    "#plt.legend(loc = 'upper right')\n",
    "\n",
    "fig.tight_layout(pad=1.0)\n",
    "#plt.savefig('Flags_Total300mK1K_{}.png'.format(iday))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f1f189",
   "metadata": {},
   "outputs": [],
   "source": [
    "#totalflags_interp = np.array(totalflags_interp, dtype = np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a8e377",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loop and save fits file with flags\n",
    "for i in range(1):\n",
    "    # Take filename\n",
    "    filename = DataContainer['fnames2022-07-14'][i].split('/')[-1]\n",
    "\n",
    "    # construct the name of the flag for that file\n",
    "    fileflag = 'TemperaturesFlags_{}.fits'.format(filename)\n",
    "\n",
    "    # Save\n",
    "    FitsArray(totalflags_interp[i]).save(fileflag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c9bfb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read flags from file\n",
    "allflagsread = []\n",
    "for i in range(1):\n",
    "    filename = DataContainer['fnames2022-07-14'][i].split('/')[-1]\n",
    "\n",
    "    # construct the name of the flag for that file\n",
    "    fileflag = 'TemperaturesFlags_{}.fits'.format(filename)\n",
    "    allflagsread.append(FitsArray(fileflag))\n",
    "    \n",
    "flagread = np.concatenate(allflagsread)\n",
    "plt.ylabel('Flag value')\n",
    "plt.step(np.arange(len(flagread)), flagread, color = 'b', alpha = 0.3)\n",
    "plt.xlabel('Index')\n",
    "#Instantiate the flagtomask\n",
    "maskflag = FlagToMask()\n",
    "\n",
    "print(maskflag.FullFlags)\n",
    "\n",
    "maskdict = {'saturation': False, 'Tbath above 350mK': True, '1K above 1.2K': True, '1K rising': True}\n",
    "\n",
    "mask = maskflag(flagread, maskdict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9c4478",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(mask, 'k.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "694cd943",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(idata[TESNum + 1][mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf67b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See in a TES\n",
    "TESNum = 50\n",
    "asic = 1\n",
    "\n",
    "fig, ax = plt.subplots(nrows = 1, ncols = 1, figsize = (15,10) ) \n",
    "fig.suptitle('DataMasked using Flags- TES = {}'.format(TESNum))\n",
    "\n",
    "itime, idata = DataContainer[iday][0].tod()\n",
    "print(np.shape(itime), np.shape(idata), )\n",
    "\n",
    "ax.plot(itime, idata[TESNum + 1], label = 'raw data TES ={}'.format(TESNum))\n",
    "ax.plot(itime[mask], idata[TESNum + 1][mask], ls = '-', color = 'r',label = 'masked data',)\n",
    "ax.legend()\n",
    "#plt.savefig('FlaggToMask_exampleTES{}'.format(TESNum))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede7088a",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "#Loop and save flags file for each datasets\n",
    "\n",
    "for i in range(len(DataContainer['fnames2022-08-23'])):\n",
    "    print(DataContainer['fnames2022-08-23'][i])\n",
    "    testime = DataContainer['2022-08-23'][i].get_hk(data='RaspberryDate',hk='EXTERN_HK')\n",
    "    # 'AVS47_1_CH6' 300mK or 'AVS47_1_ch1' 1K stage\n",
    "    label = 'AVS47_1_CH6'\n",
    "    if label == 'AVS47_1_ch1':\n",
    "        labelw = '1Kstage'\n",
    "        Tlim = 1.6 #K\n",
    "    elif label == 'AVS47_1_CH6':\n",
    "        labelw = '300mKstage'\n",
    "        Tlim = 0.345 #mK\n",
    "    else: \n",
    "        labelw = 'Not specified labelw'\n",
    "        sys.exit()\n",
    "    testdata = DataContainer['2022-08-23'][i].get_hk(label)\n",
    "\n",
    "    si = flag_bathtemp(testdata, Tlim)\n",
    "    #np.savetxt(DataContainer['fnames2022-08-23'][i]+'/BathTemp_{}_{}.txt'.format(labelw, Tlim), si)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c5250df",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (15,9))\n",
    "\n",
    "channel = 'AVS47_1_ch1'#'AVS47_1_CH6'#\n",
    "filename = '300mK' if channel == 'AVS47_1_CH6' else '1K'\n",
    "fit = False\n",
    "wfit = 'fit' if fit else 'nofit'\n",
    "\n",
    "fig.suptitle('{} - {} ({})'.format(words[0], channel, labeldict[channel]))\n",
    "\n",
    "#fig, ax = plt.subplots(nrows = len(set(DataContainer['kwdays'])), ncols = 1, figsize = (15,9))\n",
    "for j, day in enumerate(list(set(DataContainer['kwdays']))):\n",
    "    locals()['ax{}'.format(j)] = plt.subplot(len(set(DataContainer['kwdays'])), 1, j+1)\n",
    "    auxax = locals()['ax{}'.format(j)]\n",
    "    print('index, day', j, day)\n",
    "    cumtime, cumdata = [], []\n",
    "    for idata in DataContainer['{}'.format(day)]:\n",
    "        time_hk = idata.get_hk(data='RaspberryDate',hk='EXTERN_HK')\n",
    "        print(time_hk[0], time_hk[-1])\n",
    "        data_hk = idata.get_hk(channel)\n",
    "        tdate = []\n",
    "        # qubic-central was changed to UTC on 2020-02-27\n",
    "        if time_hk[0] > float(qc_utc_date.strftime('%s.%f')):\n",
    "            for tstamp in time_hk:\n",
    "                tdate.append(dt.datetime.utcfromtimestamp(tstamp))\n",
    "        auxax.plot(time_hk,data_hk, 'D',markersize=0.4*12)\n",
    "        auxax.set_ylabel('Temperature / K',fontsize=12)\n",
    "        auxax.set_xlabel('Date / UT',fontsize=12)\n",
    "        cumtime.append(time_hk)\n",
    "        cumdata.append(data_hk)\n",
    "    if fit:\n",
    "        cumtime = np.concatenate(cumtime).ravel()\n",
    "        cumdata = np.concatenate(cumdata).ravel()\n",
    "        linepars, linecov = curve_fit(line, cumtime, cumdata)\n",
    "        auxax.plot(cumtime, line(cumtime, linepars[0], linepars[1]), 'k-', lw =2,\n",
    "              label = 'a = {:3.2e}, b = {:3.2f}'.format(linepars[0], linepars[1]))\n",
    "        #idata.plot_temperatures(auxax,{'AVS47_1_CH6': '0.3K fridge CH'},'300mK Temperatures',12)        \n",
    "        #auxax.get_legend().remove()\n",
    "        auxax.legend(loc = 'upper left')\n",
    "    auxax.set_title('{}'.format(day))\n",
    "\n",
    "plt.tight_layout()\n",
    "#plt.savefig('{}Stage_{}_{}_{}'.format(filename, words[0], wfit, day) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff163af7",
   "metadata": {},
   "source": [
    "Plot timeline for a given TES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e814fb2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate color palette\n",
    "\n",
    "colors = cm.get_cmap('bwr', 60)(range(60))\n",
    "colors2 = cm.get_cmap('cividis', 60)(range(30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03fc7fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(DataContainer['2022-08-18']), len(DataContainer['2022-08-23']), len(DataContainer['2022-08-24'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32de1360",
   "metadata": {},
   "outputs": [],
   "source": [
    "TESNum = 50\n",
    "asic = 1\n",
    "zoom = False\n",
    "fig, ax = plt.subplots(nrows = 3, ncols = 1, figsize = (15,10),sharex = True ) \n",
    "fig.suptitle('{} - TES = {}'.format(words[0], TESNum))\n",
    "plt.subplots_adjust(hspace = 0.5)\n",
    "\n",
    "for j, day in enumerate(list(set(DataContainer['kwdays']))):\n",
    "    locals()['ax{}'.format(j)] = plt.subplot(len(set(DataContainer['kwdays'])), 1, j+1)\n",
    "    auxax = locals()['ax{}'.format(j)]\n",
    "    #print('index, day', j, day)\n",
    "    for i, idata in enumerate(DataContainer['{}'.format(day)]):\n",
    "        #plt.subplots_adjust(hspace=0.01)\n",
    "        tod = idata.timeline(TES = TESNum, asic = asic )\n",
    "        print(len(tod))\n",
    "        tt = idata.timeaxis(axistype='pps', asic = asic)\n",
    "        print(tt[0], tt[-1])\n",
    "        auxax.set_title('{} - {} files '.format(day, \n",
    "                                               len(DataContainer['{}'.format(day)])))\n",
    "        auxax.plot(tt-tt[0], idata.ADU2I(tod), \n",
    "                   color = colors[i], \n",
    "                   label = '{}'.format(day) if i == 0 else None)    \n",
    "        auxax.legend()\n",
    "        auxax.set_ylabel(r'Current / $\\mu$A')\n",
    "    if zoom: auxax.set_xlim(0,10)\n",
    "auxax.set_xlabel('PPS')\n",
    "        \n",
    "#plt.savefig('QUBIC_timelines_{}_TES{}_allfiles'.format(words[0], TESNum) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "314ab837",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f397bc66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cb08ea4b",
   "metadata": {},
   "source": [
    "# Wavelets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e209a5",
   "metadata": {},
   "source": [
    "### Haart transform\n",
    "\n",
    "Given a timeline $\\{U\\} = (u_0, u_1, u_2, \\dots , u_N$) you can create two subsets by doing the sum and the difference of two consecutive elements: $S = \\{u_0 + u_1, u_2 + u_3, \\dots u_{N-1} + u_N$} and $D = \\{u_0 - u_1, u_2 - u_3, \\dots u_{N-1} - u_N$}.\n",
    "\n",
    "S will give an idea of Low pass, Sum, Smooth, Synthesis, and Trend behavior of the timeline.\n",
    "\n",
    "D will give an idea of High pass, Difference, Detail, Analysis, and Fluctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115fd532",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "zoom = False\n",
    "asic = 1\n",
    "\n",
    "allstd = []\n",
    "plot = False\n",
    "\n",
    "for j in range(0,127):\n",
    "    TESNum = j+1\n",
    "    \n",
    "    print('doing TES = ', TESNum)\n",
    "    \n",
    "    stdarr = []\n",
    "    \n",
    "    #Save the std for same TES & different dataset\n",
    "    datastd = []\n",
    "    if plot:\n",
    "        fig, ax = plt.subplots(nrows = 1, ncols = 3, figsize = (15,5))\n",
    "        fig.suptitle('Wavelets study {} - TES {}'.format(day, TESNum))\n",
    "    for i in range(0, len(DataContainer['{}'.format(day)])):\n",
    "        idata = DataContainer['{}'.format(day)][i]\n",
    "        tod = idata.timeline(TES = TESNum, asic = asic )\n",
    "        tt = idata.timeaxis(axistype='pps', asic = asic)\n",
    "\n",
    "        if (len(tod) % 2) == 0:\n",
    "            pass\n",
    "        else:\n",
    "            tod = tod[:-1]\n",
    "            tod = idata.ADU2I(tod)\n",
    "            tt = tt[:-1]\n",
    "        S = 0.5*(tod[::2] + tod[1::2])\n",
    "        D = 0.5*(tod[::2] - tod[1::2])\n",
    "        newt = 0.5*(tt[::2] -tt[0] + tt[1::2] - tt[0])\n",
    "\n",
    "        ##Compute std\n",
    "        dstd = np.std(D)\n",
    "        datastd.append(dstd)\n",
    "                \n",
    "        if plot:\n",
    "            print(np.shape(tod), np.shape(S))\n",
    "            ax[0].set_title('S set (addition)')\n",
    "            ax[0].plot(S, label = '{}'.format(i),\n",
    "                        alpha = 0.8)\n",
    "            ax[0].legend()\n",
    "            ax[0].set_xlabel('Reduced timestamp')\n",
    "\n",
    "            ax[1].set_title('D set (difference)')\n",
    "            ax[1].plot(D, alpha = 0.8, label = r'$\\sigma = {:6.2e}$'.format(dstd))\n",
    "            ax[1].set_xlabel('Reduced timestamp')\n",
    "\n",
    "            ax[1].legend()\n",
    "            ax[2].set_title('Time Ordered Data')\n",
    "            ax[2].plot(tod)\n",
    "            #ax[2].plot((tt-tt[0])[:len(S)], tod[:len(S)]-S)\n",
    "            ax[2].set_xlabel('Timestamp')\n",
    "    \n",
    "            plt.tight_layout()\n",
    "            ##plt.savefig('test_wavelet_{}'.format(str(TESNum).zfill(3)))\n",
    "            plt.show()\n",
    "            #plt.clf()    \n",
    "    \n",
    "    allstd.append(datastd)\n",
    "\n",
    "#Convert to array\n",
    "allstdarr = np.array(allstd) \n",
    "print(np.shape(allstdarr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc55da24",
   "metadata": {},
   "outputs": [],
   "source": [
    "allstdarr = np.mean(allstdarr, axis = 1)\n",
    "print(np.shape(allstdarr))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66683d69",
   "metadata": {},
   "source": [
    "#### Look at the histogram std values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4347503",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tt), len(tod), len(newt), len(S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737c756e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All dataset of the day\n",
    "#allsetstdarr = np.array(allstd) \n",
    "#print(np.shape(allsetstdarr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed273c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert to array\n",
    "#Average standard deviations considering unequal sizes of the TOD[TES]\n",
    "#def AvStd(qfp, std):\n",
    "#    num, denm = 0, 0\n",
    "#    for i in range(128):\n",
    "#        itod = qfp.timeline(TES = i+1, asic = 1 )\n",
    "#        istd = std[i]\n",
    "#        nlen = len(itod)\n",
    "#        num += (nlen - 1) * istd**2\n",
    "#        denm += nlen\n",
    "#    denm = denm - len(tod)    \n",
    "#    return np.sqrt(num/denm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d07f77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 200.\n",
    "\n",
    "indexes = allstdarr < threshold\n",
    "\n",
    "fig = plt.figure(figsize = (20,10))\n",
    "#ax1 = plt.subplot(121)\n",
    "#ax2 = plt.subplot(122)\n",
    "#ax3 = plt.subplot(212)\n",
    "plt.suptitle('{}'.format(words[0]), fontsize = 20)\n",
    "plt.subplot(221)\n",
    "hist, bins = np.histogram(allstdarr, bins = 60)\n",
    "logbins = np.logspace(np.log10(bins[0]+1.),np.log10(bins[-1]),len(bins))\n",
    "plt.hist(allstdarr, bins = logbins)\n",
    "plt.axvline(threshold, ls = '--', lw = 2, color = 'k')\n",
    "plt.xscale('log')\n",
    "plt.hist(allstdarr[indexes], bins = logbins, color = 'r')\n",
    "plt.xlabel('Std Dev')\n",
    "plt.ylabel('Counts')\n",
    "plt.text(threshold, 10, '  Threshold {}'.format(threshold), fontsize = 'large')\n",
    "\n",
    "plt.subplot(222)\n",
    "plt.plot(allstdarr, 'ko')\n",
    "plt.xlabel('TES index')\n",
    "plt.ylabel('Std Dev')\n",
    "plt.plot(allstdarr[indexes], 'ro')\n",
    "\n",
    "print()\n",
    "plt.subplot(223)\n",
    "for j, idx in enumerate(indexes):\n",
    "    if idx:\n",
    "        plt.plot(DataContainer[day][0].ADU2I(DataContainer[day][0].timeline(TES = j+1, asic = 1)) )\n",
    "plt.title('TES corresp. to std dev < threshold')\n",
    "plt.ylabel('TOD [current]')\n",
    "plt.xlabel('Timestamp')\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.subplot(224)\n",
    "for j, idx in enumerate(indexes[50:]):\n",
    "    if idx:\n",
    "        plt.plot(DataContainer[day][0].ADU2I(DataContainer[day][0].timeline(TES = j+1, asic = 1)) )\n",
    "plt.title('TES corresp. to std dev < threshold')\n",
    "plt.ylabel('TOD [current]')\n",
    "plt.xlabel('Timestamp')\n",
    "plt.tight_layout()\n",
    "\n",
    "#plt.savefig('{}_{}_Saturated_TES_threshold{}'.format(day, words[0], int(threshold)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c65aef09",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Indexes of subsample\n",
    "subarr = [0,5,10,15,20,25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3147442",
   "metadata": {},
   "outputs": [],
   "source": [
    "colors2 = cm.get_cmap('rainbow', 6)(range(len(subarr)))\n",
    "print(np.shape(colors2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8229dc4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "TESind = 20\n",
    "plt.figure(figsize = (15,6))\n",
    "# Plot one TES across\n",
    "plt.subplot(121)\n",
    "plt.title('TES {} - day {}'.format(TESind, day))\n",
    "for i in range(len(subarr)):\n",
    "    plt.plot(subarr[i], scaled[TESind,i], 's-', color = colors2[i], label = 'subsample')\n",
    "#plt.plot(allsetstdarr[TESind,:]/np.max(allsetstdarr[TESind,:]), 'm.-', label ='full sample', alpha = 0.6)\n",
    "#plt.yscale('log')\n",
    "#plt.ylim(0.99,1.01)\n",
    "plt.xlabel('Experiment index', fontsize = 20)\n",
    "plt.ylabel('wavelet Std(D)', fontsize = 20)\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "#Look at the data \n",
    "plt.subplot(122)\n",
    "h=0\n",
    "for i in range(0, len(DataContainer['{}'.format(day)]), 5):\n",
    "    idata = DataContainer['{}'.format(day)][i]\n",
    "    tod =idata.timeline(TES = TESind, asic = asic )\n",
    "    tt = idata.timeaxis(axistype = 'pps', asic = asic)\n",
    "    plt.plot(tt-tt[0], idata.ADU2I(tod)/np.max(idata.ADU2I(tod)), color = colors2[h])\n",
    "    plt.xlabel('Timestamp', fontsize = 20)\n",
    "    plt.ylabel('Current (normalized)', fontsize = 20)\n",
    "    #plt.legend()\n",
    "    h+=1\n",
    "plt.grid()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb4d8333",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "# transform data\n",
    "scaled = scaler.fit_transform(allstdarr)\n",
    "datascaled = scaler.fit_transform([DataContainer[day][0].timeline(TES = TESind, asic = asic )[:1000], \n",
    "                                   DataContainer[day][5].timeline(TES = TESind, asic = asic )[:1000]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296dd6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "idata = DataContainer['{}'.format(day)][20]\n",
    "tod = idata.timeline(TES = TESind, asic = asic )\n",
    "tt = idata.timeaxis(axistype = 'pps', asic = asic)\n",
    "plt.plot(tt-tt[0], idata.ADU2I(tod)/np.max(idata.ADU2I(tod)))\n",
    "plt.xlabel('Timestamp', fontsize = 20)\n",
    "plt.ylabel('Current (normalized)', fontsize = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c3459a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import sys\n",
    "#!pip install --upgrade PyWavelets\n",
    "\n",
    "#import pywt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1464ebc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can we use GCloud to save the spreadsheet? \n",
    "#import sys\n",
    "#!conda install --yes --prefix {sys.prefix} pywt\n",
    "#import pywt\n",
    "#!pip install --upgrade google-api-python-client google-auth-httplib2 google-auth-oauthlib\n",
    "#!pip install --upgrade cachetools\n",
    "\n",
    "#from __future__ import print_function\n",
    "\n",
    "#import os.path\n",
    "\n",
    "#from google.auth.transport.requests import Request\n",
    "#from google.oauth2.credentials import Credentials\n",
    "#from google_auth_oauthlib.flow import InstalledAppFlow\n",
    "#from googleapiclient.discovery import build\n",
    "#from googleapiclient.errors import HttpError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace5aff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tod = DataContainer['{}'.format(day)][1].timeline(TES = TESNum, asic = asic )\n",
    "tod = DataContainer['{}'.format(day)][1].ADU2I(tod)[:-1]\n",
    "tt = DataContainer['{}'.format(day)][1].timeaxis(axistype='pps', asic = asic)\n",
    "S = 0.5*(tod[::2] + tod[1::2])\n",
    "D = 0.5*(tod[::2] - tod[1::2])\n",
    "print(np.shape(tod), np.shape(S))\n",
    "plt.figure(figsize = (12,5))\n",
    "plt.subplot(121)\n",
    "plt.plot(S, label = 'sum')\n",
    "plt.subplot(122)\n",
    "plt.plot(D, label = 'diff')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f8f274",
   "metadata": {},
   "outputs": [],
   "source": [
    "Unew = []\n",
    "for i in range(len(D)):\n",
    "    Unew.append(S[i] + D[i])\n",
    "    Unew.append(S[i] - D[i])\n",
    "print(np.shape(Unew))\n",
    "plt.plot(tt, tod - np.array(Unew), 'k-', alpha = 0.3)\n",
    "#plt.plot(tt, np.array(Unew)-5000, 'r-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4237f4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f62718a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#    if zoom: ax[1].set_xlim(0,200)\n",
    "#for j, kdata in enumerate(DataContainer['{}'.format('2022-08-24')]):\n",
    "#    tod = kdata.timeline(TES = TESNum, asic = asic )\n",
    "#    tt = kdata.timeaxis(axistype='pps', asic = asic)\n",
    "#    ax[2].set_title('{} - {} files {} '.format('2022-08-24', \n",
    "#                                                len(DataContainer['2022-08-24']),\n",
    "#                                              DataContainer['fnames2022-08-24'][0]))\n",
    "#    ax[2].plot(tt-tt[0], kdata.ADU2I(tod),\n",
    "#               color = colors2[-1-j], \n",
    "#               label = '2022-08-24' if j == 0 else None )\n",
    "#    ax[2].legend()\n",
    "#    #if zoom: ax[1].set_xlim(0,200)\n",
    "##plt.savefig('QUBIC_timelines_{}_TES{}_allfiles'.format(words[0], TESNum) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc6731f1",
   "metadata": {},
   "source": [
    "Plot bath temperature of a TES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b09fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_Tbath,Tbath = qfp.Tbath"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
