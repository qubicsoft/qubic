{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4707a64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%matplotlib notebook\n",
    "%matplotlib inline\n",
    "from matplotlib import rc\n",
    "rc('figure',figsize=(16,8))\n",
    "rc('font',size=12)\n",
    "rc('text',usetex=False)\n",
    "\n",
    "from qubicpack import qubicpack as qp\n",
    "import fibtools as ft\n",
    "import plotters as p\n",
    "import lin_lib as ll\n",
    "import demodulation_lib as dl\n",
    "\n",
    "from pysimulators import FitsArray\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib.pyplot import *\n",
    "import matplotlib.mlab as mlab\n",
    "import scipy.ndimage.filters as f\n",
    "import glob\n",
    "import string\n",
    "import scipy.signal as scsig\n",
    "from scipy import interpolate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa299cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2b19c97d",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "Between March 13th 2019 and March 17th 2019 we have performed 4 series of scans, each starting at -XX in elevation (w.r.t. rest position==50 deg.) and then making 40 azimuth scans, each from -20 to 20 degrees. After each azimuth scan, the elevation is increased by 1 degree (not encoder degrees, only step motors, so with a significant uncertainty, but Louise has done some calibration of this).\n",
    "\n",
    "Here is a description of each dataset:\n",
    "1. \"ScanMap\": from 2019-03-13 @ 19h21 to 2019-03-14 @ 11h03 \n",
    "    - First scan from -20 in elevation to +20, therefore actual elevation from 30 to 70\n",
    "    - To be analyzed\n",
    "2. \"ScanMapNew\": from 2019-03-14 @ 13h22 to 15h34, then 2019-03-15 @ 13h42 to 14h13\n",
    "    - Many GPS issues with this scan\n",
    "    - finally interrupted. \n",
    "    - Not to be analaysed in priority\n",
    "3. \"ScanMapNew2\": from 2019-03-15 @ 17h21 to 2019-03-16 @ 9h17\n",
    "    - Scan from -20 in elevation to +20, therefore actual elevation from 30 to 70\n",
    "    - Cycle finished at scan 38 or 39 => take care of this\n",
    "    - to be analysed\n",
    "4. \"ScanMapNew2_Start_40.5\": from 2019-03-16 @ 20h17 to 2019-03-17 @ 12h15\n",
    "    - Scan started at el-19.5 to + 20.5: therefore actual elevation 30.5 to 70.5\n",
    "    - to be analyzed\n",
    "    \n",
    "Lets get the directories corresponding to each dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b85be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['ScanMap', 'ScanMapNew2', 'ScanMapNew2_start-40.5']\n",
    "days = [['2019-03-13', '2019-03-14'], ['2019-03-15', '2019-03-16'], ['2019-03-16', '2019-03-17']]\n",
    "el_start = [30., 30., 30.5]\n",
    "delta_el = 1.\n",
    "\n",
    "all_elevation = []\n",
    "datasets=[]\n",
    "for inames in xrange(len(names)):\n",
    "    n = names[inames]\n",
    "    print n, ' Elevation starts at {}'.format(el_start[inames])\n",
    "    datasets.append([])\n",
    "    for d in days[inames]:\n",
    "        dd = glob.glob('/qubic/Data/Calib-TD/'+d+'/*'+n)\n",
    "        for i in xrange(len(dd)): \n",
    "            datasets[inames].append(dd[i])\n",
    "        print '  * ',d,' : {} files'.format(len(dd))\n",
    "    print '  => Total = {} files'.format(len(datasets[inames]))\n",
    "    elevations = el_start[inames]+arange(len(datasets[inames]))*delta_el\n",
    "    all_elevation.append(elevations)\n",
    "    print '  => Elevation ends at {}'.format(np.max(elevations))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa5c9f2a",
   "metadata": {},
   "source": [
    "We start with the forst dataset ('ScanMap'):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "286a41b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 0\n",
    "dirs = datasets[index]\n",
    "elevation = all_elevation[index]\n",
    "\n",
    "labels = []\n",
    "dir_time = []\n",
    "for d in dirs:\n",
    "    bla = str.split(d,'__')\n",
    "    blo = str.split(bla[0],'/')\n",
    "    labels.append(bla[1])\n",
    "    dir_time.append(blo[-1])\n",
    "    \n",
    "for i in xrange(len(labels)): \n",
    "    print labels[i], dir_time[i], 'Elevation: ', elevation[i]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef96902",
   "metadata": {},
   "source": [
    "And we first start with the middle file: i=21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68853c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "ii = 20\n",
    "thedir = datasets[index][ii]\n",
    "print thedir, 'Elevation =',all_elevation[index][ii]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b4378e",
   "metadata": {},
   "source": [
    "## Reading Data for a given asic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e92dfee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "AsicNum = 1\n",
    "a = qp()\n",
    "a.read_qubicstudio_dataset(thedir, asic=AsicNum)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41548a27",
   "metadata": {},
   "source": [
    "## Reading TES data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15cfaad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "TESNum = 96\n",
    "data = a.timeline(TES=TESNum)\n",
    "t_data = a.timeline_timeaxis(axistype='pps')\n",
    "\n",
    "plot(t_data-t_data[0], (data-np.mean(data))/np.std(data), label='Data')\n",
    "#a.plot_timestamp_diagnostic()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7bbacf3",
   "metadata": {},
   "source": [
    "## Reading Azimuth Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3876fb60",
   "metadata": {},
   "outputs": [],
   "source": [
    "az = a.azimuth()\n",
    "#t_az = a.timeaxis(datatype='hk',axistype='index')\n",
    "t_az = (np.max(t_data)-np.min(t_data))*np.linspace(0,1,len(az))\n",
    "\n",
    "plot(t_az, az)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9648b0b1",
   "metadata": {},
   "source": [
    "### Plot Data and Azimuth together (they should match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e628b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "subplot(1,2,1)\n",
    "plot(t_data, f.gaussian_filter1d((data-np.mean(data))/np.std(data),15), label='Data')\n",
    "plot(t_az, (az-np.mean(az))/np.std(az), label='Az')\n",
    "legend()\n",
    "\n",
    "subplot(1,2,2)\n",
    "plot(np.interp(t_data, t_az, az), data-f.gaussian_filter1d(data,1000))\n",
    "xlim(-5,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9479d286",
   "metadata": {},
   "source": [
    "Let's check the modulation frequency (main peak in data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d5115c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "FREQ_SAMPLING = 1./(t_data[1]-t_data[0])\n",
    "spectrum_f, freq_f = mlab.psd(data, Fs=FREQ_SAMPLING, NFFT=len(data), window=mlab.window_hanning)\n",
    "plot(freq_f, f.gaussian_filter1d(spectrum_f,1),label='Data')\n",
    "yscale('log')\n",
    "xscale('log')\n",
    "xlim(0.2,0.45)\n",
    "freq_mod = 0.333\n",
    "plot([freq_mod, freq_mod], [1e6, 1e12], label='Modulation Frequency: {}'.format(freq_mod))\n",
    "ylim(1e6, 1e12)\n",
    "legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add94e57",
   "metadata": {},
   "source": [
    "# Demodulation with RMS per period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39168f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(dl)\n",
    "\n",
    "#### Parameters\n",
    "ppp = 1./freq_mod\n",
    "lowcut = 0.1\n",
    "highcut = 15.\n",
    "nbins = 100\n",
    "elevation = 50\n",
    "\n",
    "t_src = []\n",
    "data_src = []\n",
    "angle, sb, dsb, pars, err_pars = dl.general_demodulate(ppp, t_data, data, t_src, data_src, t_az, az, \n",
    "                                                    lowcut, highcut, elevation, \n",
    "                                                    nbins=nbins, median=True, method='rms', \n",
    "                                                    doplot=True, unbinned=False, \n",
    "                                                    renormalize_plot=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac0206d2",
   "metadata": {},
   "source": [
    "Now we loop on the TES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6066d64a",
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(dl)\n",
    "reload(ft)\n",
    "savedir = '/Volumes/Data/Qubic/Calib-TD/ScanData/'\n",
    "for ids in xrange(len(datasets)):\n",
    "    dirs = datasets[ids]\n",
    "    for ii in xrange(len(dirs)):\n",
    "        thedir = dirs[ii]\n",
    "        print '##############################################################'\n",
    "        print 'Dataset {} / {} :'.format(ids,len(datasets)),names[ids]\n",
    "        print 'Directory {} / {} :'.format(ii, len(dirs)), thedir\n",
    "        print '##############################################################'\n",
    "        alldemod = np.zeros((256,100))\n",
    "        for iasic in [0,1]:\n",
    "            print '======== ASIC {} ====================='.format(iasic)\n",
    "            AsicNum = iasic+1\n",
    "            a = qp()\n",
    "            a.read_qubicstudio_dataset(thedir, asic=AsicNum)\n",
    "            t_data = a.timeline_timeaxis(axistype='index')\n",
    "            FREQ_SAMPLING = 1./(t_data[1]-t_data[0])\n",
    "            az = a.azimuth()\n",
    "            t_az = (np.max(t_data)-np.min(t_data))*np.linspace(0,1,len(az))\n",
    "            for TESNum in np.arange(128)+1:\n",
    "                if (16*(TESNum/16))==TESNum: print(TESNum)\n",
    "                TESindex = iasic*128+(TESNum-1)\n",
    "                thedata = a.timeline(TES=TESNum)\n",
    "                t_src=[]\n",
    "                data_src=[]\n",
    "                angle, sb, dsb, pars, err_pars = dl.general_demodulate(ppp, t_data, thedata, t_src, data_src, t_az, az, \n",
    "                                                            lowcut, highcut, all_elevation[ids][ii], \n",
    "                                                            nbins=nbins, median=True, method='rms', \n",
    "                                                            doplot=False, unbinned=False)\n",
    "                alldemod[TESindex,:] = sb\n",
    "        FitsArray(alldemod).save(savedir+'alltes_{}_el_{}.fits'.format(names[ids],all_elevation[ids][ii]))\n",
    "        FitsArray(np.append(pars,err_pars).reshape((2,4))).save(savedir+'fitpars_{}_el_{}.fits'.format(names[ids],all_elevation[ids][ii]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cdacf0d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
