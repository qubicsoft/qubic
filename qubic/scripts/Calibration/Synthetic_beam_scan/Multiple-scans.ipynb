{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d3b92bd2",
      "metadata": {},
      "outputs": [],
      "source": [
        "#%matplotlib notebook\n",
        "%matplotlib inline\n",
        "from matplotlib import rc\n",
        "rc('figure',figsize=(16,8))\n",
        "rc('font',size=12)\n",
        "rc('text',usetex=False)\n",
        "\n",
        "from qubicpack import qubicpack as qp\n",
        "import fibtools as ft\n",
        "import plotters as p\n",
        "import lin_lib as ll\n",
        "import demodulation_lib as dl\n",
        "\n",
        "from pysimulators import FitsArray\n",
        "\n",
        "import numpy as np\n",
        "from matplotlib.pyplot import *\n",
        "import matplotlib.mlab as mlab\n",
        "import scipy.ndimage.filters as f\n",
        "import glob\n",
        "import string\n",
        "import scipy.signal as scsig\n",
        "from scipy import interpolate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8cc8ce5d",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "17b06316",
      "metadata": {},
      "source": [
        "## Dataset\n",
        "Between March 13th 2019 and March 17th 2019 we have performed 4 series of scans, each starting at -XX in elevation (w.r.t. rest position==50 deg.) and then making 40 azimuth scans, each from -20 to 20 degrees. After each azimuth scan, the elevation is increased by 1 degree (not encoder degrees, only step motors, so with a significant uncertainty, but Louise has done some calibration of this).\n",
        "\n",
        "Here is a description of each dataset:\n",
        "1. \"ScanMap\": from 2019-03-13 @ 19h21 to 2019-03-14 @ 11h03 \n",
        "    - First scan from -20 in elevation to +20, therefore actual elevation from 30 to 70\n",
        "    - To be analyzed\n",
        "2. \"ScanMapNew\": from 2019-03-14 @ 13h22 to 15h34, then 2019-03-15 @ 13h42 to 14h13\n",
        "    - Many GPS issues with this scan\n",
        "    - finally interrupted. \n",
        "    - Not to be analaysed in priority\n",
        "3. \"ScanMapNew2\": from 2019-03-15 @ 17h21 to 2019-03-16 @ 9h17\n",
        "    - Scan from -20 in elevation to +20, therefore actual elevation from 30 to 70\n",
        "    - Cycle finished at scan 38 or 39 => take care of this\n",
        "    - to be analysed\n",
        "4. \"ScanMapNew2_Start_40.5\": from 2019-03-16 @ 20h17 to 2019-03-17 @ 12h15\n",
        "    - Scan started at el-19.5 to + 20.5: therefore actual elevation 30.5 to 70.5\n",
        "    - to be analyzed\n",
        "    \n",
        "Lets get the directories corresponding to each dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2af31c94",
      "metadata": {},
      "outputs": [],
      "source": [
        "names = ['ScanMap', 'ScanMapNew2', 'ScanMapNew2_start-40.5']\n",
        "days = [['2019-03-13', '2019-03-14'], ['2019-03-15', '2019-03-16'], ['2019-03-16', '2019-03-17']]\n",
        "el_start = [30., 30., 30.5]\n",
        "delta_el = 1.\n",
        "\n",
        "all_elevation = []\n",
        "datasets=[]\n",
        "for inames in xrange(len(names)):\n",
        "    n = names[inames]\n",
        "    print n, ' Elevation starts at {}'.format(el_start[inames])\n",
        "    datasets.append([])\n",
        "    for d in days[inames]:\n",
        "        dd = glob.glob('/qubic/Data/Calib-TD/'+d+'/*'+n)\n",
        "        for i in xrange(len(dd)): \n",
        "            datasets[inames].append(dd[i])\n",
        "        print '  * ',d,' : {} files'.format(len(dd))\n",
        "    print '  => Total = {} files'.format(len(datasets[inames]))\n",
        "    elevations = el_start[inames]+arange(len(datasets[inames]))*delta_el\n",
        "    all_elevation.append(elevations)\n",
        "    print '  => Elevation ends at {}'.format(np.max(elevations))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d186c392",
      "metadata": {},
      "source": [
        "We start with the forst dataset ('ScanMap'):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "50df6979",
      "metadata": {},
      "outputs": [],
      "source": [
        "index = 0\n",
        "dirs = datasets[index]\n",
        "elevation = all_elevation[index]\n",
        "\n",
        "labels = []\n",
        "dir_time = []\n",
        "for d in dirs:\n",
        "    bla = str.split(d,'__')\n",
        "    blo = str.split(bla[0],'/')\n",
        "    labels.append(bla[1])\n",
        "    dir_time.append(blo[-1])\n",
        "    \n",
        "for i in xrange(len(labels)): \n",
        "    print labels[i], dir_time[i], 'Elevation: ', elevation[i]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3174bb18",
      "metadata": {},
      "source": [
        "And we first start with the middle file: i=21"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "091e2ff2",
      "metadata": {},
      "outputs": [],
      "source": [
        "ii = 20\n",
        "thedir = datasets[index][ii]\n",
        "print thedir, 'Elevation =',all_elevation[index][ii]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f9d806bc",
      "metadata": {},
      "source": [
        "## Reading Data for a given asic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "02284db1",
      "metadata": {},
      "outputs": [],
      "source": [
        "AsicNum = 1\n",
        "a = qp()\n",
        "a.read_qubicstudio_dataset(thedir, asic=AsicNum)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "25c3fa27",
      "metadata": {},
      "source": [
        "## Reading TES data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1ca75cbd",
      "metadata": {},
      "outputs": [],
      "source": [
        "TESNum = 96\n",
        "data = a.timeline(TES=TESNum)\n",
        "t_data = a.timeline_timeaxis(axistype='pps')\n",
        "\n",
        "plot(t_data-t_data[0], (data-np.mean(data))/np.std(data), label='Data')\n",
        "#a.plot_timestamp_diagnostic()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b0422b54",
      "metadata": {},
      "source": [
        "## Reading Azimuth Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0e596f51",
      "metadata": {},
      "outputs": [],
      "source": [
        "az = a.azimuth()\n",
        "#t_az = a.timeaxis(datatype='hk',axistype='index')\n",
        "t_az = (np.max(t_data)-np.min(t_data))*np.linspace(0,1,len(az))\n",
        "\n",
        "plot(t_az, az)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "95b902c9",
      "metadata": {},
      "source": [
        "### Plot Data and Azimuth together (they should match)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "511940b7",
      "metadata": {},
      "outputs": [],
      "source": [
        "subplot(1,2,1)\n",
        "plot(t_data, f.gaussian_filter1d((data-np.mean(data))/np.std(data),15), label='Data')\n",
        "plot(t_az, (az-np.mean(az))/np.std(az), label='Az')\n",
        "legend()\n",
        "\n",
        "subplot(1,2,2)\n",
        "plot(np.interp(t_data, t_az, az), data-f.gaussian_filter1d(data,1000))\n",
        "xlim(-5,5)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "693fe878",
      "metadata": {},
      "source": [
        "Let's check the modulation frequency (main peak in data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bf4f661e",
      "metadata": {},
      "outputs": [],
      "source": [
        "FREQ_SAMPLING = 1./(t_data[1]-t_data[0])\n",
        "spectrum_f, freq_f = mlab.psd(data, Fs=FREQ_SAMPLING, NFFT=len(data), window=mlab.window_hanning)\n",
        "plot(freq_f, f.gaussian_filter1d(spectrum_f,1),label='Data')\n",
        "yscale('log')\n",
        "xscale('log')\n",
        "xlim(0.2,0.45)\n",
        "freq_mod = 0.333\n",
        "plot([freq_mod, freq_mod], [1e6, 1e12], label='Modulation Frequency: {}'.format(freq_mod))\n",
        "ylim(1e6, 1e12)\n",
        "legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "09df3ea9",
      "metadata": {},
      "source": [
        "# Demodulation with RMS per period"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bb081478",
      "metadata": {},
      "outputs": [],
      "source": [
        "reload(dl)\n",
        "\n",
        "#### Parameters\n",
        "ppp = 1./freq_mod\n",
        "lowcut = 0.1\n",
        "highcut = 15.\n",
        "nbins = 100\n",
        "elevation = 50\n",
        "\n",
        "t_src = []\n",
        "data_src = []\n",
        "angle, sb, dsb, pars, err_pars = dl.general_demodulate(ppp, t_data, data, t_src, data_src, t_az, az, \n",
        "                                                    lowcut, highcut, elevation, \n",
        "                                                    nbins=nbins, median=True, method='rms', \n",
        "                                                    doplot=True, unbinned=False, \n",
        "                                                    renormalize_plot=True)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fa8abc2b",
      "metadata": {},
      "source": [
        "Now we loop on the TES"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ec7383c4",
      "metadata": {},
      "outputs": [],
      "source": [
        "reload(dl)\n",
        "reload(ft)\n",
        "savedir = '/Volumes/Data/Qubic/Calib-TD/ScanData/'\n",
        "for ids in xrange(len(datasets)):\n",
        "    dirs = datasets[ids]\n",
        "    for ii in xrange(len(dirs)):\n",
        "        thedir = dirs[ii]\n",
        "        print '##############################################################'\n",
        "        print 'Dataset {} / {} :'.format(ids,len(datasets)),names[ids]\n",
        "        print 'Directory {} / {} :'.format(ii, len(dirs)), thedir\n",
        "        print '##############################################################'\n",
        "        alldemod = np.zeros((256,100))\n",
        "        for iasic in [0,1]:\n",
        "            print '======== ASIC {} ====================='.format(iasic)\n",
        "            AsicNum = iasic+1\n",
        "            a = qp()\n",
        "            a.read_qubicstudio_dataset(thedir, asic=AsicNum)\n",
        "            t_data = a.timeline_timeaxis(axistype='index')\n",
        "            FREQ_SAMPLING = 1./(t_data[1]-t_data[0])\n",
        "            az = a.azimuth()\n",
        "            t_az = (np.max(t_data)-np.min(t_data))*np.linspace(0,1,len(az))\n",
        "            for TESNum in np.arange(128)+1:\n",
        "                if (16*(TESNum/16))==TESNum: print(TESNum)\n",
        "                TESindex = iasic*128+(TESNum-1)\n",
        "                thedata = a.timeline(TES=TESNum)\n",
        "                t_src=[]\n",
        "                data_src=[]\n",
        "                angle, sb, dsb, pars, err_pars = dl.general_demodulate(ppp, t_data, thedata, t_src, data_src, t_az, az, \n",
        "                                                            lowcut, highcut, all_elevation[ids][ii], \n",
        "                                                            nbins=nbins, median=True, method='rms', \n",
        "                                                            doplot=False, unbinned=False)\n",
        "                alldemod[TESindex,:] = sb\n",
        "        FitsArray(alldemod).save(savedir+'alltes_{}_el_{}.fits'.format(names[ids],all_elevation[ids][ii]))\n",
        "        FitsArray(np.append(pars,err_pars).reshape((2,4))).save(savedir+'fitpars_{}_el_{}.fits'.format(names[ids],all_elevation[ids][ii]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5f544228",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {},
  "nbformat": 4,
  "nbformat_minor": 5
}
