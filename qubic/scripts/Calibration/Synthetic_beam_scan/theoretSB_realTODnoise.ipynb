{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53bf6b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "#%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "rc('figure', figsize=(15,8))\n",
    "rc('font', size=12)\n",
    "rc('text', usetex=False)\n",
    "rc('image', cmap='viridis')\n",
    "\n",
    "import healpy as hp\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "import qubic.io\n",
    "from pysimulators import FitsArray\n",
    "import qubic.fibtools as ft\n",
    "import qubic.demodulation_lib as dl\n",
    "import qubic.sb_fitting as sbfit\n",
    "from scipy.stats import norm\n",
    "\n",
    "# Import jchinstrument from ../\n",
    "import os,sys,inspect\n",
    "current_dir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "sys.path.insert(0, parent_dir) \n",
    "import jchinstrument as jcinst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f8f1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hall_pointing(az, el, angspeed_psi, maxpsi,backandforth = False,\n",
    "                 date_obs=None, latitude=None, longitude=None,fix_azimuth=None,random_hwp=True):\n",
    "    #This method will reproduce the pointing that is used in the hall to take the data. Will start from bottom\n",
    "    #left and will go up at fixed elevation.\n",
    "    \n",
    "    if backandforth: \n",
    "        nsamples = 2*len(az)*len(el)\n",
    "    else:\n",
    "        nsamples = len(az)*len(el)\n",
    "    #print('nsamples = ', nsamples)\n",
    "    pp = qubic.QubicSampling(nsamples,date_obs=date_obs, period=0.1, latitude=latitude,longitude=longitude)\n",
    "    \n",
    "    #Comented because we do not go and back in simulations.. \n",
    "    if backandforth:\n",
    "        mult_el = []\n",
    "        for eachEl in el:\n",
    "            mult_el.append(np.tile(eachEl, 2*len(az)))\n",
    "        # Azimuth go and back and same elevation. \n",
    "        az_back = az[::-1]\n",
    "        az = list(az)\n",
    "        az.extend(az_back)\n",
    "        mult_az = np.tile(az, len(el))\n",
    "        pp.elevation = np.asarray(mult_el).ravel()\n",
    "        pp.azimuth = np.asarray(mult_az).ravel()\n",
    "    \n",
    "    else:\n",
    "        mult_el = []\n",
    "        for eachEl in el:\n",
    "            mult_el.extend(np.tile(eachEl, len(az)))\n",
    "        mult_az = []\n",
    "        mult_az.append(np.tile(az, len(el)))\n",
    "        pp.elevation = np.asarray(mult_el)#az2d.ravel()\n",
    "        pp.azimuth = np.asarray(mult_az[0])#el2d.ravel()\n",
    "    \n",
    "    ### scan psi as well,\n",
    "    pitch = pp.time * angspeed_psi\n",
    "    pitch = pitch % (4 * maxpsi)\n",
    "    mask = pitch > (2 * maxpsi)\n",
    "    pitch[mask] = -pitch[mask] + 4 * maxpsi\n",
    "    pitch -= maxpsi\n",
    "    \n",
    "    pp.pitch = pitch\n",
    "    \n",
    "    if random_hwp:\n",
    "        pp.angle_hwp = np.random.random_integers(0, 7, nsamples) * 11.25\n",
    "        \n",
    "    if fix_azimuth['apply']:\n",
    "        pp.fix_az=True\n",
    "        if fix_azimuth['fix_hwp']:\n",
    "            pp.angle_hwp=pp.pitch*0+ 11.25\n",
    "        if fix_azimuth['fix_pitch']:\n",
    "            pp.pitch= 0\n",
    "    else:\n",
    "        pp.fix_az=False\n",
    "\n",
    "    return pp\n",
    "    #print(pp.elevation)#, len(pp.elevation))\n",
    "\n",
    "\n",
    "def select_det(q,id):\n",
    "    #### For now the ids are not matched... so we only take the len(id) first detectors...\n",
    "    detector_i = q.detector[:len(id)]\n",
    "    q.detector = detector_i\n",
    "    return(q)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e8ec10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSTRUMENT\n",
    "ns = 256\n",
    "d = qubic.qubicdict.qubicDict()\n",
    "d.read_from_file(os.environ['QUBIC_DICT']+'/global_source_oneDet.dict')\n",
    "print(d['kind'])\n",
    "d['kind']='I'\n",
    "print(d['kind'])\n",
    "d['nside']=ns\n",
    "sel_det = True\n",
    "fittedpeakfile = os.environ['QUBIC_PEAKS']+'/fitted_peaks.fits'\n",
    "directory = os.environ['QUBIC_TODDIR']+'/150GHz-2019-04-06/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cedff798",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reload(dl)\n",
    "#reload(sbfit)\n",
    "\n",
    "#reload(jcinst)\n",
    "#detnums = [6, 37, 38, 72, 79, 86, 94, 96, 110, 124, 149, 153, 176, 184, 185, 199, 205, 229, 231, 235, 247]\n",
    "#detnums = [37, 124, 185, 229]\n",
    "detnums = [137] #,37,185]\n",
    "#detnums = [37, 185, 229]\n",
    "nsrec = 256\n",
    "tol = 5e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b49ac8e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "qcut = select_det(qubic.QubicInstrument(d),detnums)\n",
    "\n",
    "s = qubic.QubicScene(d)\n",
    "\n",
    "sb = 0.\n",
    "sb = qcut.get_synthbeam(s, idet=1, detpos=qcut.detector.center[0])\n",
    "xr=0.1*np.max(sb)\n",
    "\n",
    "#Take maps from files\n",
    "flatmap = np.zeros((len(detnums),))\n",
    "backandforth = False\n",
    "\n",
    "if backandforth: flatmap = np.empty((144,400)); xsize = 400; ysize = 144; reso = 5\n",
    "else: xsize = 200; ysize = 144 ; reso = 10\n",
    "    \n",
    "for i in range(len(detnums)):    \n",
    "    if backandforth:\n",
    "        readmap, az, el = sbfit.get_flatmap(detnums[i], directory)\n",
    "        for irow, _ in enumerate(readmap):\n",
    "            flatmap[irow, :len(az)] = readmap[irow, :]\n",
    "            flatmap[irow, len(az):] = readmap[irow, ::-1]\n",
    "    else:\n",
    "        flatmap, az, el = sbfit.get_flatmap(detnums[i], directory)\n",
    "        \n",
    "    \n",
    "print(flatmap.shape)    \n",
    "#We hace to reshape the sb with the az,el shape read it from fits files\n",
    "sb_img=hp.gnomview(sb, rot=[0,90], xsize=xsize,ysize=ysize, reso=reso, min=-xr, max=xr,title='Input ', \n",
    "                   return_projected_map=True,hold=False,cmap='viridis')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e106f042",
   "metadata": {},
   "source": [
    "***\n",
    "Normalization and plot TOD and SB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db89b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "flatmapnorm = flatmap/np.max(flatmap)\n",
    "sb_imgnorm = sb_img/np.max(sb_img)\n",
    "\n",
    "plt.subplot(221)\n",
    "plt.title('real TOD')\n",
    "plt.imshow(flatmapnorm)\n",
    "plt.subplot(222)\n",
    "plt.title('real TOD ravel')\n",
    "plt.plot(flatmapnorm.ravel())\n",
    "plt.subplot(223)\n",
    "plt.title('sim SB')\n",
    "plt.imshow(sb_imgnorm)\n",
    "plt.subplot(224)\n",
    "plt.title('sim TOD ravel')\n",
    "plt.plot(sb_imgnorm.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe92895",
   "metadata": {},
   "source": [
    "***\n",
    "Rescaling SB to the same as the real flat map. We want SB with the same mean and std than flatmap and noisegen. If $SB_{i}$ has $\\mu_{1}$ and $\\sigma_{1}$, and flatmap and noisegen has $\\mu_{2}$ and $\\sigma_{2}$, then we need to do: $$SBnew_{i} = \\mu_{2} + (SB_{i} - \\mu_{1}) \\times \\frac{\\sigma_{2}}{\\sigma_{1}}  $$.\n",
    "That new $SBnew_{i}$ has mean $\\mu_{2}$ and std $\\sigma_{2}$, i.e., SB scaled to flatmap and noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f84a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "muSB, stdSB = ft.meancut(sb_imgnorm.ravel(),3)\n",
    "muScale, stdScale = ft.meancut(flatmapnorm.ravel(),3)\n",
    "\n",
    "#now scale mu and std of SB to the data\n",
    "SBnew = muScale + (sb_imgnorm - muSB)*stdScale/stdSB\n",
    "\n",
    "# generate random distributions of noise with scaled mu and std\n",
    "noisegen =3.5e2*np.mean(SBnew)*np.random.normal(muSB, stdScale, len(sb_imgnorm.ravel()))\n",
    "\n",
    "# Should I use something related with S/N ratio? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e25b1955",
   "metadata": {},
   "source": [
    "***\n",
    "check if it's ok mu and std of SBnew.. It works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec899a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(ft.meancut(SBnew,3), muScale, stdScale)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f542bc",
   "metadata": {},
   "source": [
    "***\n",
    "Take noise level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a746a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pts = flatmapnorm.ravel()\n",
    "#muNoise,stdNoise = ft.meancut(pts,3)\n",
    "#print('fit gaussian with smal amount of points ', muNoise, stdNoise)\n",
    "\n",
    "plt.subplot(211)\n",
    "plt.plot(flatmapnorm.ravel(), 'b-')\n",
    "plt.subplot(212)\n",
    "count, bins, ignored = plt.hist(flatmapnorm.ravel(), color='b', bins=90, density=True,label='hits in map')\n",
    "plt.plot(bins, 1/(stdScale * np.sqrt(2 * np.pi)) *np.exp( - (bins - muScale)**2 / (2 * stdScale**2) ),\n",
    "        linewidth=3, color='r', label= 'gaussian fit')\n",
    "plt.legend(loc='best')\n",
    "\n",
    "# Add noise to SB\n",
    "simSB = SBnew.ravel()\n",
    "noisyTOD = simSB + noisegen\n",
    "#print(np.max(SBnew))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fbf9c96",
   "metadata": {},
   "source": [
    "***\n",
    "Check level of noise.. seems to be ok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab6b5892",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "plt.subplot(131)\n",
    "plt.title('SB')\n",
    "plt.plot(simSB, 'r')\n",
    "plt.subplot(132)\n",
    "plt.title('SB+noise from det {}'.format(detnums))\n",
    "plt.plot(noisyTOD)\n",
    "plt.subplot(133)\n",
    "plt.title('TOD')\n",
    "plt.plot(flatmap.ravel(), 'r')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c05bb237",
   "metadata": {},
   "source": [
    "***\n",
    "### Map-making with no fit locations of SB+realNoise\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a272fac4",
   "metadata": {},
   "source": [
    "***\n",
    "Standard pointing $p$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "500ef4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = hall_pointing(az, el, 0, 0, backandforth = False, fix_azimuth=d['fix_azimuth'])# qubic.QubicSampling(d)\n",
    "\n",
    "a = qubic.QubicAcquisition(qcut, p, s, d)\n",
    "\n",
    "simSBr = simSB.reshape((1,len(simSB)))\n",
    "noisyTODr = noisyTOD.reshape((1,len(noisyTOD)))\n",
    "\n",
    "#maps_recon_sb, _,_ = a.tod2map(simSBr,d,cov=None)\n",
    "#maps_recon_sbPn, niter, error = a.tod2map(noisyTODr, d, cov=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e0c9751",
   "metadata": {},
   "source": [
    "***\n",
    "Change pointing. \n",
    "\n",
    "bf: back and forth standard pointing\n",
    "\n",
    "dens: denser one. (not working because elevation problem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f949e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "shiftaz = list(set(np.diff(az)/2))[0]\n",
    "shiftel = list(set(np.diff(el)/2))[0]\n",
    "newaz, newel = [], []\n",
    "for i in range(len(az)):\n",
    "    newaz.append(az[i])\n",
    "    newaz.append(az[i] + shiftaz)\n",
    "for j in range(len(el)):\n",
    "    newel.append(el[j])\n",
    "    newel.append(el[j] + shiftel)\n",
    "    \n",
    "print('az: ', len(az), len(newaz))\n",
    "print('el: ', len(el), len(newel))\n",
    "\n",
    "dens = hall_pointing(newaz,newel, 0, 0, backandforth=True,fix_azimuth=d['fix_azimuth'])\n",
    "bf = hall_pointing(az, el, 0, 0, backandforth=True, fix_azimuth=d['fix_azimuth'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5aa2c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(211)\n",
    "plt.xlim(0,2800)\n",
    "plt.ylabel('Azimuth', fontsize=14)\n",
    "plt.plot(dens.azimuth, 'b', label='denser')\n",
    "plt.plot(bf.azimuth, 'g', label = 'default b&f')\n",
    "plt.plot(p.azimuth, 'r', label = 'default')\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(212)\n",
    "#plt.xlim(0,2800)\n",
    "#plt.ylim(36,38)\n",
    "plt.ylabel('Elevation', fontsize=14)\n",
    "plt.plot(dens.elevation, 'b')\n",
    "plt.plot(p.elevation, 'r')\n",
    "plt.plot(bf.elevation, 'g')\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c40c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Maps shapes noisyTOD and simulated SB: ', noisyTODr.shape, simSB.shape)\n",
    "print('default pointing', len(p.azimuth), len(p.elevation))\n",
    "print('b&f pointing', len(bf.azimuth), len(bf.elevation))\n",
    "print('denser pointing', len(dens.azimuth), len(dens.azimuth))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "222478a0",
   "metadata": {},
   "source": [
    "have to fill some map to do b&f and denser pointing..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf7bf15",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = testing # p, bf and dens\n",
    "if len(model) == 57600: dim0,dim1, par = 144,400, .5\n",
    "elif len(model) == 28800: dim0, dim1, par = 144,200, 1\n",
    "elif len(model) == 230400: dim0, dim1, par = 288,800, .125\n",
    "    \n",
    "# take input dim from SB\n",
    "dimSB = np.arange(0,len(simSB))\n",
    "# take more point\n",
    "newdim=np.arange(0,len(simSB), par)\n",
    "# Interpolation to the new points\n",
    "interpSB = np.interp(newdim,dimSB,noisyTODr[0])\n",
    "\n",
    "plt.xlim(13500,13550)\n",
    "plt.plot(dimSB,noisyTODr[0], 'ro', label = 'real value')\n",
    "plt.plot(newdim, interpSB, 'b*', label = 'interpolated')\n",
    "plt.legend()\n",
    "#plt.imshow(interpSB.reshape(dim0,dim1), extent=[np.min(model.azimuth),np.max(model.azimuth), \n",
    "#                                              np.min(model.elevation), np.max(model.elevation)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9cae178",
   "metadata": {},
   "source": [
    "Check if the recons is fine.... OK!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd68fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#noisegenr=np.array(noisegen).reshape((144,200))\n",
    "#hp.gnomview(maps_recon_sb,rot=[0,50], reso=10, title='sb(no refit)',sub=(1,2,1),\n",
    "#            hold=False,cmap='viridis')\n",
    "#hp.gnomview(maps_recon_sbPn,rot=[0,50], reso=10, title='sb+noiseTOD (no refit)', sub=(1,2,2),\n",
    "#            hold=False,cmap='viridis')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f3f5e78",
   "metadata": {},
   "source": [
    "***\n",
    "### Fit the locations from SB+realNoise\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "869475d9",
   "metadata": {},
   "source": [
    "##### Do it by hand using JCh function do_some_dets\n",
    "Cannot use do_some_dets because it uses realTOD and I want noisyTOD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9241f915",
   "metadata": {},
   "source": [
    "Create sbfitmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd36becc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sbfitmodel = sbfit.SbModelIndepPeaks(nrings=2, common_fwhm=True, \n",
    "                                     no_xy_shift=False, distortion=False)\n",
    "print('Using Fit Model {} for TES #{}'.format(sbfitmodel.name,detnums[i]))\n",
    "fit, thexypeaks = sbfit.fit_sb(noisyTOD.reshape((dim0,dim1)), az, el, sbfitmodel, resample=True, newsize=70,\n",
    "                                               verbose=False, doplot=True)\n",
    "\n",
    "# Refitting of the peaks location\n",
    "xypeaks=[]\n",
    "xypeaks.append(thexypeaks)\n",
    "                \n",
    "### Convert to measurement coordinate system\n",
    "xypeaks = np.array(xypeaks)\n",
    "allthetas_M = np.radians(90-(xypeaks[:,1,:]-50))\n",
    "allphis_M = np.radians(-xypeaks[:,0,:])#*thecos)\n",
    "allvals_M = xypeaks[:,2,:]\n",
    "\n",
    "angs=None\n",
    "nu=qcut.filter.nu\n",
    "horn = getattr(qcut, 'horn', None)\n",
    "primary_beam = getattr(qcut, 'primary_beam', None)\n",
    "thecos = np.cos(np.radians(50))\n",
    "usepeaks=None\n",
    "synthbeam = qcut.synthbeam\n",
    "\n",
    "if angs is None:\n",
    "    angs = np.radians(np.array([0, 90, 0]))\n",
    "allthetas_Q = np.zeros_like(allthetas_M)\n",
    "allphis_Q = np.zeros_like(allthetas_M)\n",
    "allvals_Q = np.zeros_like(allthetas_M)\n",
    "for ites in range(len(detnums)):\n",
    "    allthetas_Q[ites,:], allphis_Q[ites,:] = sbfit.rotate_q2m(allthetas_M[ites,:], \n",
    "                                                              allphis_M[ites,:], \n",
    "                                                              angs=angs, inverse=True)\n",
    "    allvals_Q[ites,:] = allvals_M[ites,:]/np.max(allvals_M[ites,:])*synthbeam.peak150.solid_angle * (150e9 / nu)**2 / s.solid_angle * len(horn)\n",
    "        \n",
    "### We nowwrite the temporary file that contains the peaks locations to be used\n",
    "#if usepeaks is None:\n",
    "#    peaknums = np.arange(9)\n",
    "#else:\n",
    "peaknums = usepeaks\n",
    "data = np.array([allthetas_Q[:,peaknums], allphis_Q[:,peaknums], allvals_Q[:,peaknums]])\n",
    "file = open(os.environ['QUBIC_PEAKS']+'peaks.pk', 'wb')\n",
    "pickle.dump(data, file)\n",
    "file.close()\n",
    "    \n",
    "qfit = select_det(jcinst.QubicInstrument(d),detnums)\n",
    "afit = qubic.QubicAcquisition(qfit, p, s, d)\n",
    "d['tol'] = tol\n",
    "maps_recon_fit, niter, error = afit.tod2map(noisyTODr*5e-28, d, cov=None)\n",
    "maps_recon_fit_noiseless, _, _ = afit.tod2map(simSBr*5e-28, d, cov=None)\n",
    "#if verbose: print('Mapmaking QUBIC done in {} iterations with error: {}'.format(niter, error))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0cb62e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mindisp = -0.07*max(maps_recon_fit)\n",
    "maxdisp =0.07*max(maps_recon_fit)\n",
    "\n",
    "hp.gnomview(maps_recon_fit_noiseless,rot=[0,50], reso=10, title='Recons. map (sb noiseless) TES#{}'.format(detnums[0]), sub=(1,3,1),\n",
    "            min=mindisp, max=maxdisp,\n",
    "            hold=False,cmap='viridis')\n",
    "hp.gnomview(maps_recon_fit,rot=[0,50], reso=10, title='Recons. map (sb+realNoise)', sub=(1,3,2),\n",
    "            min=mindisp, max=maxdisp,\n",
    "            hold=False,cmap='viridis')\n",
    "hp.gnomview(maps_recon_fit_noiseless - maps_recon_fit,rot=[0,50], reso=10, title='residual', sub=(1,3,3),\n",
    "            min=mindisp, max=maxdisp, \n",
    "            hold=False,cmap='viridis')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea0a9e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c9d59f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d02d9d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
