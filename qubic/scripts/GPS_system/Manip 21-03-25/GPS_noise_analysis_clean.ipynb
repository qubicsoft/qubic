{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import plotly.figure_factory as ff\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "import datetime as dt\n",
    "import pickle\n",
    "\n",
    "from scipy.spatial import Delaunay\n",
    "from scipy.stats import linregress\n",
    "from scipy.optimize import curve_fit\n",
    "from getdist import plots, MCSamples\n",
    "from iminuit import Minuit\n",
    "from iminuit.cost import LeastSquares\n",
    "\n",
    "from qubic.lib.Qgps import GPSAntenna\n",
    "import qubic.lib.Calibration.Qfiber as ft\n",
    " \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If True, allow plots for debug\n",
    "DEBUG = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distances during experiment\n",
    "distance_base_antenna2 = np.array([10, 10, 10, 10, 10, 10, 10, 8, 8, 8, 8, 8, 8, 8, 6, 6, 6, 6, 6, 6, 5, 5, 5, 5, 5, 5, 4, 4, 4, 4, 4, 3, 3, 3, 3, 2, 2, 2, 2, 1, 1])\n",
    "distance_antenna1_antenna2 = np.array([7, 6, 5, 4, 3, 2, 1, 1, 2, 3, 4, 5, 6, 7, 6, 5, 4, 3, 2, 1, 1, 2, 3, 4, 5, 6, 5, 4, 3, 2, 1, 1, 2, 3, 4, 2, 3, np.sqrt(2), np.sqrt(3), 2, 1])\n",
    "\n",
    "if distance_base_antenna2.size != distance_antenna1_antenna2.size:\n",
    "    print(distance_base_antenna2.size, distance_antenna1_antenna2.size)\n",
    "    raise ValueError(\"The two arrays must have the same size\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_data = pickle.load(open('GPS_noise_analysis.pkl', 'rb'))\n",
    "\n",
    "names = np.array(['North', 'East', 'Down', 'Roll', 'Yaw'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dict_data.keys())\n",
    "print(dict_data['rpN'].keys())\n",
    "print(dict_data['rpN']['clean_data'][0].size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Noise Power Spectrum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Def useful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestep = 0.125\n",
    "print(\"Timestep : \", timestep, \"s.\")\n",
    "\n",
    "def get_ps(array):\n",
    "    \"\"\"Function to compute the power spectrum of a given array.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    array : array_like\n",
    "        array containing the data to compute the power spectrum of.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    power_spectrum : array_like\n",
    "        array containing the power spectrum of the input array.\n",
    "    freq: array_like\n",
    "        array containing the frequency of the power spectrum.\n",
    "    \"\"\"\n",
    "    N = array.size\n",
    "    return np.abs(np.fft.rfft(array))**2, np.fft.rfftfreq(N, d=timestep/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "power_spectrum, freq = get_ps(dict_data['rpN']['clean_data'][0])\n",
    "power_spectrum, freq = power_spectrum[1:], freq[1:]\n",
    "\n",
    "plt.plot(freq, power_spectrum)\n",
    "plt.xlabel('Frequency (Hz)')\n",
    "plt.ylabel(r'Power Spectrum ($m^2/Hz$)')\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.title('Noise Power Spectrum - North')\n",
    "\n",
    "del power_spectrum, freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def noise_model(x, A_white, f_knee, slope):\n",
    "    return A_white**2 * (1 + np.abs(f_knee/x)**slope)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit using my Gaussian LogLikelihood function with minuit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit 1/f + white with minuit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nll_exp(A, f_knee, alpha, f, ps):\n",
    "    P_model = noise_model(f, A, f_knee, alpha)\n",
    "    return np.sum(np.log(P_model) + ps / P_model)\n",
    "\n",
    "def nll_gauss(A, f_knee, alpha, freq, ps, sigma):\n",
    "    P_model = noise_model(freq, A, f_knee, alpha)\n",
    "    return np.sum(0.5 * ((ps - P_model) / sigma)**2 + 0.5 * np.log(2 * np.pi * sigma**2))\n",
    "\n",
    "def fit_minuit_ll(data, nbins=300, plot=False, data_name=None, index=None):\n",
    "    ps, freq = get_ps(data)\n",
    "    ps, freq = ps[1:], freq[1:]\n",
    "    \n",
    "    binned_freq, binned_ps, _, binned_ps_error, _ = ft.profile(freq, ps, nbins=nbins, plot=False)\n",
    "    \n",
    "    def nll_wrapper(A, f_knee, alpha):\n",
    "       return nll_gauss(A, f_knee, alpha, binned_freq, binned_ps, sigma=binned_ps_error)\n",
    "\n",
    "    m = Minuit(nll_wrapper, A=0.1, f_knee=1, alpha=1)\n",
    "    m.limits['A'] = (0, None)\n",
    "    m.limits['f_knee'] = (0, None)\n",
    "    m.limits['alpha'] = (0, None)\n",
    "\n",
    "    m.migrad()\n",
    "    m.hesse()\n",
    "    \n",
    "    if plot:\n",
    "        plt.plot(freq, ps, label=\"data\")\n",
    "        plt.plot(freq, noise_model(freq, *m.values), 'r', label=\"fit\")\n",
    "\n",
    "        # display legend with some fit info\n",
    "        fit_info = [\n",
    "            f\"$\\\\chi^2$/$n_\\\\mathrm{{dof}}$ = {m.fval:.1f} / {m.ndof:.0f} = {m.fmin.reduced_chi2:.1f}\",\n",
    "        ]\n",
    "        for p, v, e in zip(m.parameters, m.values, m.errors):\n",
    "            fit_info.append(f\"{p} = ${v:.3f} \\\\pm {e:.3f}$\")\n",
    "        plt.title(f'Fit on Noise Power Spectrum - {data_name} - Instrumental Index {index}')\n",
    "        plt.legend(title=\"\\n\".join(fit_info), frameon=False)\n",
    "        plt.xlabel('Frequency (Hz)')\n",
    "        plt.ylabel(r'Power Spectrum ($m^2/Hz$)')\n",
    "        plt.xscale(\"log\")\n",
    "        plt.yscale(\"log\")\n",
    "        plt.show()\n",
    "        \n",
    "    return m.values, m.errors, m.fmin.reduced_chi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Try to use video from scikit MOOC (module 2, Validation and learning curves) to determine the number of points I want to use (and also, which model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_values_loglike, params_errors_loglike, reduced_chi2_loglike = [], [], []\n",
    "names = ['rpN', 'rpE', 'rpD', 'roll', 'yaw']\n",
    "label = [r'$A_{white}$', r'$f_{knee}$', r'$\\alpha$']\n",
    "\n",
    "# Fit for each instrumental configurations\n",
    "for idata in range(len(names)):\n",
    "    values, errors, chi2_dof= [], [], []\n",
    "    for index in range(len(dict_data['rpN']['clean_data'])):\n",
    "        if index == 0:\n",
    "            plot = True\n",
    "        else:\n",
    "            plot = False\n",
    "        val, err, red_chi2 = fit_minuit_ll(dict_data[names[idata]]['clean_data'][index], nbins=int(dict_data[names[idata]]['clean_data'][index].size/10), plot=plot, data_name=names[idata], index=index)\n",
    "        values.append(val)\n",
    "        errors.append(err)\n",
    "        chi2_dof.append(red_chi2)\n",
    "    params_values_loglike.append(values)\n",
    "    params_errors_loglike.append(errors)\n",
    "    reduced_chi2_loglike.append(chi2_dof)\n",
    "    \n",
    "print(len(params_values_loglike))\n",
    "print(len(params_values_loglike[0]))\n",
    "print(len(params_values_loglike[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "fig, ax = plt.subplots(3, 5, figsize=(15, 10), sharey='row', sharex=True)\n",
    "\n",
    "n_datasets = len(names)\n",
    "n_points   = len(params_values_loglike[0])  \n",
    "for idata in range(n_datasets):\n",
    "    for iparam in range(3):\n",
    "        values = [params_values_loglike[idata][i][iparam] for i in range(n_points)]\n",
    "        errors = [params_errors_loglike[idata][i][iparam] for i in range(n_points)]\n",
    "        x = np.arange(n_points)\n",
    "        \n",
    "        ax[iparam, idata].errorbar(x, values, yerr=errors,\n",
    "                                   fmt='o', color='black', capsize=3)\n",
    "        \n",
    "        mean_val = np.mean(values)\n",
    "        std_val = np.std(values)\n",
    "        ax[iparam, idata].axhline(mean_val, color='red', linestyle='--', linewidth=2, label=f'Mean = {mean_val:.2f} | Std = {std_val:.2f}')\n",
    "        ax[iparam, idata].legend(fontsize=8)\n",
    "\n",
    "for iparam in range(3):\n",
    "    ax[iparam, 0].set_ylabel(label[iparam], fontsize=12)\n",
    "\n",
    "for idata in range(n_datasets):\n",
    "    ax[0, idata].set_title(names[idata], fontsize=14)\n",
    "#    ax[1, idata].set_ylim(0, 10)\n",
    "\n",
    "for idata in range(n_datasets):\n",
    "    ax[2, idata].set_xlabel('Instrumental Index', fontsize=12)\n",
    "fig.suptitle(r'GPS noise analysis - logLikelihood - $P_{noise}(f) = A_{white}^2 (1 + |f_{knee}/f|^{\\alpha})$', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.savefig('GPS noise analysis - over f + White.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "fig = make_subplots(\n",
    "    rows=3, cols=5, shared_xaxes=True, shared_yaxes=True,\n",
    "    subplot_titles=names,\n",
    "    vertical_spacing=0.05,   # decreased spacing for larger plots\n",
    "    horizontal_spacing=0.03, # decreased spacing for larger plots\n",
    "    row_heights=[0.1, 0.1, 0.1],\n",
    "    column_widths=[0.1, 0.1, 0.1, 0.1, 0.1]\n",
    ")\n",
    "\n",
    "n_datasets = len(names)\n",
    "n_points = len(params_values_loglike[0])\n",
    "\n",
    "for idata in range(n_datasets):\n",
    "    for iparam in range(3):\n",
    "        values = [params_values_loglike[idata][i][iparam] for i in range(n_points)]\n",
    "        errors = [params_errors_loglike[idata][i][iparam] for i in range(n_points)]\n",
    "        x = np.arange(n_points)\n",
    "        \n",
    "        mean_val = np.mean(values)\n",
    "        std_val = np.std(values)\n",
    "        \n",
    "        # Add error bars\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=x,\n",
    "                y=values,\n",
    "                error_y=dict(type='data', array=errors, visible=True),\n",
    "                mode='markers',\n",
    "                marker=dict(color=\"black\"),\n",
    "                name=names[idata],\n",
    "                showlegend=False\n",
    "            ),\n",
    "            row=iparam+1, col=idata+1\n",
    "        )\n",
    "        \n",
    "        # Add mean line\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=[0, n_points-1],\n",
    "                y=[mean_val, mean_val],\n",
    "                mode='lines',\n",
    "                line=dict(color='red', dash='dash'),\n",
    "                name=f'Mean = {mean_val:.2f} | Std = {std_val:.2f}',\n",
    "                showlegend=False\n",
    "            ),\n",
    "            row=iparam+1, col=idata+1\n",
    "        )\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(\n",
    "    height=1000,\n",
    "    width=2000,\n",
    "    title_text=r'GPS noise analysis - logLikelihood - $P_{noise}(f) = A_{white}^2 (1 + |f_{knee}/f|^{\\alpha})$',\n",
    "    showlegend=False\n",
    ")\n",
    "\n",
    "# Update y-axis labels\n",
    "for iparam in range(3):\n",
    "    fig.update_yaxes(title_text=label[iparam], row=iparam+1, col=1)\n",
    "\n",
    "# Update x-axis labels\n",
    "for idata in range(n_datasets):\n",
    "    fig.update_xaxes(title_text='Instrumental Index', row=3, col=idata+1)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Are the parameters scaled with the distance between antennas ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_name = 'roll'\n",
    "index_data = names.index(data_name)\n",
    "params_value = np.array(params_values_loglike, dtype=float)[index_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "unique_distances = np.unique(distance_base_antenna2)\n",
    "colors = px.colors.sample_colorscale(\"jet\", [i/(len(unique_distances)-1) for i in range(len(unique_distances))])\n",
    "\n",
    "# Create a subplot figure with 2 rows and 1 column, sharing the x-axis.\n",
    "fig = make_subplots(\n",
    "    rows=3, cols=1, shared_xaxes=True,\n",
    "    vertical_spacing=0.1,\n",
    ")\n",
    "\n",
    "# Loop over unique distances to add traces for both subplots.\n",
    "for i, dist in enumerate(unique_distances):\n",
    "    mask = distance_base_antenna2 == dist\n",
    "    # First subplot: A_white values\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=distance_antenna1_antenna2[mask],\n",
    "            y=params_value[mask, 0],\n",
    "            mode='markers',\n",
    "            name=f'{dist:.1f}',\n",
    "            marker=dict(color=colors[i])\n",
    "        ),\n",
    "        row=1, col=1\n",
    "    )\n",
    "    # Second subplot: f_knee values; hide legend to avoid duplicates.\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=distance_antenna1_antenna2[mask],\n",
    "            y=params_value[mask, 1],\n",
    "            mode='markers',\n",
    "            name=f'{dist:.1f}',\n",
    "            marker=dict(color=colors[i]),\n",
    "            showlegend=False\n",
    "        ),\n",
    "        row=2, col=1\n",
    "    )\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=distance_antenna1_antenna2[mask],\n",
    "            y=params_value[mask, 2],\n",
    "            mode='markers',\n",
    "            name=f'{dist:.1f}',\n",
    "            marker=dict(color=colors[i]),\n",
    "            showlegend=False\n",
    "        ),\n",
    "        row=3, col=1\n",
    "    )\n",
    "\n",
    "# Update axis labels and overall layout.\n",
    "fig.update_xaxes(title_text='Distance Antenna 1 to Antenna 2', row=3, col=1)\n",
    "fig.update_yaxes(title_text=label[0], row=1, col=1)\n",
    "fig.update_yaxes(title_text=label[1], row=2, col=1)\n",
    "fig.update_yaxes(title_text=label[2], row=3, col=1)\n",
    "\n",
    "fig.update_layout(\n",
    "    title=f'Noise power spectrum parameters for different distances - {data_name} data',\n",
    "    # Position the legend outside the plot on the right.\n",
    "    legend=dict(\n",
    "        title='Distance Base to Antenna 2',\n",
    "        orientation='v',\n",
    "        x=1.02,\n",
    "        y=1,\n",
    "        xanchor='left',\n",
    "        yanchor='top'\n",
    "    ),\n",
    "    width=1200,\n",
    "    height=800,\n",
    "    margin=dict(r=150)  # Increase right margin to accommodate the legend.\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_distances = np.unique(distance_base_antenna2)\n",
    "colors = cm.jet(np.linspace(0, 1, len(unique_distances)))\n",
    "\n",
    "fig, ax = plt.subplots(2, 1, figsize=(10, 8), sharex=True)\n",
    "\n",
    "for i, dist in enumerate(unique_distances):\n",
    "    mask = distance_base_antenna2 == dist\n",
    "    ax[0].scatter(distance_antenna1_antenna2[mask], params_value[mask, 0], label=f'{dist:.1f}', color=colors[i])\n",
    "    ax[1].scatter(distance_antenna1_antenna2[mask], params_value[mask, 1], color=colors[i])\n",
    "\n",
    "ax[0].set_ylabel(r'$A_{white}$')\n",
    "ax[1].set_ylabel(r'$f_{knee}$')\n",
    "ax[1].set_xlabel('Distance Antenna 1 to Antenna 2')\n",
    "\n",
    "# Create a single legend outside the plot\n",
    "handles, labels = ax[0].get_legend_handles_labels()\n",
    "fig.legend(handles, labels, loc='upper left', bbox_to_anchor=(1, 1), title='Distance Base to Antenna 2')\n",
    "\n",
    "fig.suptitle(f'Noise power spectrum parameters for different distances - {data_name} data')\n",
    "plt.tight_layout(rect=[0, 0, 0.85, 1])  # Adjust layout to make space for legend\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit 1/f + linear noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$P(f) = A_{white}^2 ((f)^{\\alpha} + (\\frac{f_{knee}}{f})^{\\beta})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def advanced_noise_model(x, A_white, f_knee, alpha, beta):\n",
    "    return A_white**2 * (1 + x*alpha + (f_knee/x)**beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nll_gauss(A, f_knee, alpha, beta, freq, ps, sigma):\n",
    "    P_model = advanced_noise_model(freq, A, f_knee, alpha, beta)\n",
    "    return np.sum(0.5 * ((ps - P_model) / sigma)**2 + 0.5 * np.log(2 * np.pi * sigma**2))\n",
    "\n",
    "def fit_minuit_ll(data, nbins=300, plot=False, data_name=None, index=None):\n",
    "    ps, freq = get_ps(data)\n",
    "    ps, freq = ps[1:], freq[1:]\n",
    "    \n",
    "    binned_freq, binned_ps, _, binned_ps_error, _ = ft.profile(freq, ps, nbins=nbins, plot=False)\n",
    "    \n",
    "    def nll_wrapper(A, f_knee, alpha, beta):\n",
    "       return nll_gauss(A, f_knee, alpha, beta, binned_freq, binned_ps, sigma=binned_ps_error)\n",
    "\n",
    "    m = Minuit(nll_wrapper, A=0.1, f_knee=1, alpha=1, beta=1)\n",
    "    m.limits['A'] = (0, None)\n",
    "    m.limits['f_knee'] = (0, None)\n",
    "    m.limits['alpha'] = (0, None)\n",
    "    m.limits['beta'] = (0, None)\n",
    "\n",
    "    m.migrad()\n",
    "    m.hesse()\n",
    "    \n",
    "    if plot:\n",
    "        plt.plot(freq, ps, label=\"data\")\n",
    "        plt.plot(freq, advanced_noise_model(freq, *m.values), 'r', label=\"fit\")\n",
    "\n",
    "        # display legend with some fit info\n",
    "        fit_info = [\n",
    "            f\"$\\\\chi^2$/$n_\\\\mathrm{{dof}}$ = {m.fval:.1f} / {m.ndof:.0f} = {m.fmin.reduced_chi2:.1f}\",\n",
    "        ]\n",
    "        for p, v, e in zip(m.parameters, m.values, m.errors):\n",
    "            fit_info.append(f\"{p} = ${v:.3f} \\\\pm {e:.3f}$\")\n",
    "        plt.title(f'Fit on Noise Power Spectrum - {data_name} - Instrumental Index {index}')\n",
    "        plt.legend(title=\"\\n\".join(fit_info), frameon=False)\n",
    "        plt.xlabel('Frequency (Hz)')\n",
    "        plt.ylabel(r'Power Spectrum ($m^2/Hz$)')\n",
    "        plt.xscale(\"log\")\n",
    "        plt.yscale(\"log\")\n",
    "        plt.show()\n",
    "        \n",
    "    return m.values, m.errors, m.fmin.reduced_chi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_values_loglike, params_errors_loglike, reduced_chi2_loglike = [], [], []\n",
    "names = ['rpN', 'rpE', 'rpD', 'roll', 'yaw']\n",
    "label = [r'$A_{white}$', r'$f_{knee}$', r'$\\alpha$', r'$\\beta$']\n",
    "\n",
    "# Fit for each instrumental configurations\n",
    "for idata in range(len(names)):\n",
    "    values, errors, chi2_dof= [], [], []\n",
    "    for index in range(len(dict_data[names[idata]]['clean_data'])):\n",
    "        if index == 0:\n",
    "            plot = True\n",
    "        else:\n",
    "            plot = False\n",
    "        val, err, red_chi2 = fit_minuit_ll(dict_data[names[idata]]['clean_data'][index], nbins=int(dict_data[names[idata]]['clean_data'][index].size/10), plot=plot, data_name=names[idata], index=index)\n",
    "        values.append(val)\n",
    "        errors.append(err)\n",
    "        chi2_dof.append(red_chi2)\n",
    "    params_values_loglike.append(values)\n",
    "    params_errors_loglike.append(errors)\n",
    "    reduced_chi2_loglike.append(chi2_dof)\n",
    "    \n",
    "print(len(params_values_loglike))\n",
    "print(len(params_values_loglike[0]))\n",
    "print(len(params_values_loglike[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "fig, ax = plt.subplots(len(label), 5, figsize=(15, 10), sharey='row', sharex=True)\n",
    "\n",
    "n_datasets = len(names)\n",
    "n_points   = len(params_values_loglike[0])  \n",
    "for idata in range(n_datasets):\n",
    "    for iparam in range(len(label)):\n",
    "        values = [params_values_loglike[idata][i][iparam] for i in range(n_points)]\n",
    "        errors = [params_errors_loglike[idata][i][iparam] for i in range(n_points)]\n",
    "        x = np.arange(n_points)\n",
    "        \n",
    "        ax[iparam, idata].errorbar(x, values, yerr=errors,\n",
    "                                   fmt='o', color='black', capsize=3)\n",
    "        \n",
    "        mean_val = np.mean(values)\n",
    "        std_val = np.std(values)\n",
    "        ax[iparam, idata].axhline(mean_val, color='red', linestyle='--', linewidth=2, label=f'Mean = {mean_val:.2f} | Std = {std_val:.2f}')\n",
    "        ax[iparam, idata].legend(fontsize=8)\n",
    "\n",
    "for iparam in range(len(label)):\n",
    "    ax[iparam, 0].set_ylabel(label[iparam], fontsize=12)\n",
    "\n",
    "for idata in range(n_datasets):\n",
    "    ax[0, idata].set_title(names[idata], fontsize=14)\n",
    "#    ax[1, idata].set_ylim(0, 10)\n",
    "\n",
    "for idata in range(n_datasets):\n",
    "    ax[-1, idata].set_xlabel('Instrumental Index', fontsize=12)\n",
    "fig.suptitle(r'GPS noise analysis - logLikelihood - $P_{noise}(f) = A_{white}^2 (1 + |f_{knee}/f|^{\\alpha})$', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.savefig('GPS noise analysis - over f + Linear.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "fig = make_subplots(\n",
    "    rows=3, cols=5, shared_xaxes=True, shared_yaxes=True,\n",
    "    subplot_titles=names,\n",
    "    vertical_spacing=0.05,   # decreased spacing for larger plots\n",
    "    horizontal_spacing=0.03, # decreased spacing for larger plots\n",
    "    row_heights=[0.1, 0.1, 0.1],\n",
    "    column_widths=[0.1, 0.1, 0.1, 0.1, 0.1]\n",
    ")\n",
    "\n",
    "n_datasets = len(names)\n",
    "n_points = len(params_values_loglike[0])\n",
    "\n",
    "for idata in range(n_datasets):\n",
    "    for iparam in range(3):\n",
    "        values = [params_values_loglike[idata][i][iparam] for i in range(n_points)]\n",
    "        errors = [params_errors_loglike[idata][i][iparam] for i in range(n_points)]\n",
    "        x = np.arange(n_points)\n",
    "        \n",
    "        mean_val = np.mean(values)\n",
    "        std_val = np.std(values)\n",
    "        \n",
    "        # Add error bars\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=x,\n",
    "                y=values,\n",
    "                error_y=dict(type='data', array=errors, visible=True),\n",
    "                mode='markers',\n",
    "                marker=dict(color=\"black\"),\n",
    "                name=names[idata],\n",
    "                showlegend=False\n",
    "            ),\n",
    "            row=iparam+1, col=idata+1\n",
    "        )\n",
    "        \n",
    "        # Add mean line\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=[0, n_points-1],\n",
    "                y=[mean_val, mean_val],\n",
    "                mode='lines',\n",
    "                line=dict(color='red', dash='dash'),\n",
    "                name=f'Mean = {mean_val:.2f} | Std = {std_val:.2f}',\n",
    "                showlegend=False\n",
    "            ),\n",
    "            row=iparam+1, col=idata+1\n",
    "        )\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(\n",
    "    height=1000,\n",
    "    width=2000,\n",
    "    title_text=r'GPS noise analysis - logLikelihood - $P_{noise}(f) = A_{white}^2 (1 + |f_{knee}/f|^{\\alpha})$',\n",
    "    showlegend=False\n",
    ")\n",
    "\n",
    "# Update y-axis labels\n",
    "for iparam in range(3):\n",
    "    fig.update_yaxes(title_text=label[iparam], row=iparam+1, col=1)\n",
    "\n",
    "# Update x-axis labels\n",
    "for idata in range(n_datasets):\n",
    "    fig.update_xaxes(title_text='Instrumental Index', row=3, col=idata+1)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_value = np.array(params_values_loglike, dtype=float)[index_data]\n",
    "print(params_value.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_distances = np.unique(distance_base_antenna2)\n",
    "colors = px.colors.sample_colorscale(\"jet\", [i/(len(unique_distances)-1) for i in range(len(unique_distances))])\n",
    "\n",
    "# Create a subplot figure with 2 rows and 1 column, sharing the x-axis.\n",
    "fig = make_subplots(\n",
    "    rows=2, cols=1, shared_xaxes=True,\n",
    "    vertical_spacing=0.1,\n",
    ")\n",
    "\n",
    "# Loop over unique distances to add traces for both subplots.\n",
    "for i, dist in enumerate(unique_distances):\n",
    "    mask = distance_base_antenna2 == dist\n",
    "    # First subplot: A_white values\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=distance_antenna1_antenna2[mask],\n",
    "            y=params_value[mask, 0],\n",
    "            mode='markers',\n",
    "            name=f'{dist:.1f}',\n",
    "            marker=dict(color=colors[i])\n",
    "        ),\n",
    "        row=1, col=1\n",
    "    )\n",
    "    # Second subplot: f_knee values; hide legend to avoid duplicates.\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=distance_antenna1_antenna2[mask],\n",
    "            y=params_value[mask, 1],\n",
    "            mode='markers',\n",
    "            name=f'{dist:.1f}m',\n",
    "            marker=dict(color=colors[i]),\n",
    "            showlegend=False\n",
    "        ),\n",
    "        row=2, col=1\n",
    "    )\n",
    "\n",
    "# Update axis labels and overall layout.\n",
    "fig.update_xaxes(title_text='Distance Antenna 1 to Antenna 2', row=2, col=1)\n",
    "fig.update_yaxes(title_text=r'$A_{white}$', row=1, col=1)\n",
    "fig.update_yaxes(title_text=r'$f_{knee}$', row=2, col=1)\n",
    "\n",
    "fig.update_layout(\n",
    "    title=f'Noise power spectrum parameters for different distances - {data_name} data',\n",
    "    # Position the legend outside the plot on the right.\n",
    "    legend=dict(\n",
    "        title=\"Distance Base to Antenna 2\",\n",
    "        orientation='v',\n",
    "        x=1.02,\n",
    "        y=1,\n",
    "        xanchor='left',\n",
    "        yanchor='top'\n",
    "    ),\n",
    "    width=1200,\n",
    "    height=800,\n",
    "    margin=dict(r=150)  # Increase right margin to accommodate the legend.\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_distances = np.unique(distance_base_antenna2)\n",
    "colors = cm.jet(np.linspace(0, 1, len(unique_distances)))\n",
    "\n",
    "fig, ax = plt.subplots(2, 1, figsize=(10, 8), sharex=True)\n",
    "\n",
    "for i, dist in enumerate(unique_distances):\n",
    "    mask = distance_base_antenna2 == dist\n",
    "    ax[0].scatter(distance_antenna1_antenna2[mask], params_value[mask, 0], label=f'{dist:.1f}', color=colors[i])\n",
    "    ax[1].scatter(distance_antenna1_antenna2[mask], params_value[mask, 1], color=colors[i])\n",
    "\n",
    "ax[0].set_ylabel(r'$A_{white}$')\n",
    "ax[1].set_ylabel(r'$f_{knee}$')\n",
    "ax[1].set_xlabel('Distance Antenna 1 to Antenna 2')\n",
    "\n",
    "# Create a single legend outside the plot\n",
    "handles, labels = ax[0].get_legend_handles_labels()\n",
    "fig.legend(handles, labels, loc='upper left', bbox_to_anchor=(1, 1), title=\"Distance Base to Antenna 2\")\n",
    "\n",
    "fig.suptitle(f'Noise power spectrum parameters for different distances - {data_name} data')\n",
    "plt.tight_layout(rect=[0, 0, 0.85, 1])  # Adjust layout to make space for legend\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-qubic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
