{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1af2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pylab import *\n",
    "import camb.correlations as cc\n",
    "import healpy as hp\n",
    "rc('figure', figsize=(16, 7))\n",
    "rc('font', size=15)\n",
    "mpl.rcParams['image.cmap'] = 'jet'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c27659f",
   "metadata": {},
   "source": [
    "I am trying to simulate data on a healpix map with a spatial correlation given by a known C(theta). In order to do so, I simulate white noise in a full sky map, then smooth it with the Cl corresponding to the C(theta) and then go back to map-space.\n",
    "\n",
    "I have made dseveral functions to play with that. They are mostly based on camb.correlations functions that are precisely designed for that, although they have. issues with theta=0 (as explained in the doc: https://camb.readthedocs.io/en/latest/correlations.html?highlight=correlations#module-camb.correlations). This is why I have. tried to extend them to be general.\n",
    "\n",
    "Starting from the well known:\n",
    "$$C(\\theta) = \\frac{1}{4\\pi} \\sum_\\ell (2\\ell+1)C_\\ell P_\\ell(\\cos(\\theta))$$\n",
    "one can easily demonstrate that:\n",
    "$$C_\\ell = 2\\pi \\int_{-1}^{1}P_\\ell(x)C(x)dx$$ where $x=\\cos\\theta$\n",
    "\n",
    "As a consequence the special case $\\theta=0$ can be calculated using $C(x)=\\delta(x-1)$ in the above formula leading to:\n",
    "$$\\begin{eqnarray}\n",
    "C_\\ell &=& 2\\pi\\int_{-1}{1}P_\\ell(x)C(x)dx\\\\\n",
    "&=& 2\\pi P_\\ell(1)\\\\\n",
    "&=& 2\\pi\n",
    "\\end{eqnarray}\n",
    "$$\n",
    "as $P_\\ell(1)=1$ whatever $\\ell$.\n",
    "\n",
    "**However it seems to me that this should be equal to 1 instead of $2\\pi$ so I have implemented it with 1. It is easy to change it back to $2\\pi$ in the function below and to test it again in the Monte-Carlo at the end and show that it does not solve the problem.**\n",
    "\n",
    "This is what is implemented in the function below for calculating the $C_\\ell$ for a given $C(\\theta)$ and tested with two case:\n",
    "- the trivial white noise case\n",
    "- my correlation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cadbd5be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ctheta_2_cell(theta_deg, ctheta, lmax, pol=False, normalization=1.):\n",
    "    ### this is how camb recommends to prepare the x = cos(theta) values for integration\n",
    "    ### These x values do not contain x=1 so we have. to do this case separately\n",
    "    x, w = np.polynomial.legendre.leggauss(lmax+1)\n",
    "    xdeg = np.degrees(np.arccos(x))\n",
    "\n",
    "    ### We first replace theta=0 by 0 and do that case separately\n",
    "    myctheta = ctheta.copy()\n",
    "    myctheta[0] = 0\n",
    "    ### And now we fill the array that should include polarization (we put zeros there)\n",
    "    ### with the values of our imput c(theta) interpolated at the x locations\n",
    "    allctheta = np.zeros((len(x), 4))\n",
    "    allctheta[:,0] = np.interp(xdeg, theta_deg, myctheta)\n",
    "\n",
    "    ### Here we call the camb function that does the transform to Cl\n",
    "    clth = cc.corr2cl(allctheta, x,  w, lmax)\n",
    "    lll = np.arange(lmax+1)\n",
    "\n",
    "    ### the special case x=1 corresponds to theta=0 and add 2pi times c(theta=0) to the Cell\n",
    "    return lll, clth[:,0]+ctheta[0]*normalization\n",
    "\n",
    "\n",
    "#### Normalization of c(theta=0) ###################################\n",
    "normalization = 1.#2*np.pi\n",
    "####################################################################\n",
    "\n",
    "### Test 1 - white noise\n",
    "nth = 1000\n",
    "theta = np.linspace(0,90,nth)\n",
    "ctheta = np.zeros(nth)\n",
    "ctheta[0] = 1.\n",
    "\n",
    "lll, cell = ctheta_2_cell(theta, ctheta, 1024, normalization=normalization)\n",
    "\n",
    "subplot(1,2,1)\n",
    "plot(theta, ctheta)\n",
    "plot(theta, theta*0, 'k:')\n",
    "xlabel(r'$\\theta$ [deg]')\n",
    "ylabel(r'$C(\\theta)$')\n",
    "title('test 1')\n",
    "\n",
    "subplot(1,2,2)\n",
    "plot(lll, cell)\n",
    "plot(lll, lll*0+normalization, 'k:')\n",
    "xlabel(r'$\\ell$')\n",
    "ylabel(r'$C_\\ell$')\n",
    "title('test 1: C(0) normalization={0:5.3f}'.format(normalization))\n",
    "\n",
    "\n",
    "figure()\n",
    "### Test 2 - My noise\n",
    "fct = lambda x, a, b, c: a * np.sin(x/b) * exp(-x/c)\n",
    "a = 0.48\n",
    "b = 2.14\n",
    "c = 4.27\n",
    "\n",
    "myctheta = fct(theta, a,b,c)\n",
    "myctheta[0] = 1.\n",
    "mylll, mycell = ctheta_2_cell(theta, myctheta, 1024, normalization=normalization)\n",
    "\n",
    "\n",
    "\n",
    "subplot(1,2,1)\n",
    "plot(theta, myctheta)\n",
    "plot(theta, theta*0, 'k:')\n",
    "xlabel(r'$\\theta$ [deg]')\n",
    "ylabel(r'$C(\\theta)$')\n",
    "title('test 2')\n",
    "\n",
    "subplot(1,2,2)\n",
    "plot(mylll, mycell)\n",
    "plot(mylll, mylll*0+normalization, 'k:')\n",
    "xlabel(r'$\\ell$')\n",
    "ylabel(r'$C_\\ell$')\n",
    "title('test 2: C(0) normalization={0:5.3f}'.format(normalization))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "843d3cfe",
   "metadata": {},
   "source": [
    "So we can go from smooth C(theta) to smooth Cl and vice-versa. We now need to investigate how to take a map and apply the convolution by C(theta) in harmonic space. We can do that through three manners that should be equivalent:\n",
    "1. using hp.smoothing() on a uniform uncorrelated map\n",
    "2. calculating alms from a uniform, uncorrelated map and doing the smoothing directly on alms\n",
    "3. directly simulating with synfast() according to the expected Cl\n",
    "\n",
    "Differences between these manners could arise form various normalizations, ell cutoff in the different functions. The difficulty mainly lies in the fact that our Cl kernel does not have a compact support (does not go to zero beyond somw ell), so that ell-space cutoff might have a rather strong impact."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f47f6cd",
   "metadata": {},
   "source": [
    "## Method 1: hp.smoothing() on uncorrelated map\n",
    "In principle this should be very straightforward.\n",
    "\n",
    "Let's first build an uncorrelated map and calculate its power spectrum, check that normalizations are clear, especially when changing nside and signoise:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af5e635",
   "metadata": {},
   "outputs": [],
   "source": [
    "### General parameters\n",
    "nside = 128\n",
    "lmax = 2*nside\n",
    "ell = np.arange(lmax+1)\n",
    "npix = 12 * nside**2\n",
    "signoise = 10.\n",
    "\n",
    "### Map realization\n",
    "map_uncorr = np.random.randn(npix) * signoise\n",
    "rms_uncorr = np.std(map_uncorr)\n",
    "\n",
    "### Power spectrum from map\n",
    "cl_uncorr = hp.anafast(map_uncorr, lmax=lmax)\n",
    "\n",
    "### Theoretical power spectrum\n",
    "clth_uncorr = ell*0+signoise**2 * 4*np.pi / npix\n",
    "print(len(cl_uncorr), len(ell))\n",
    "\n",
    "### Plotting Unocorrelated\n",
    "p=plot(ell, cl_uncorr, label='Input Uncorrelated map')\n",
    "plot(ell, clth_uncorr, ':', color=p[0].get_color(), label='Theoretical Uncorrelated Cl')\n",
    "legend()\n",
    "xlabel(r'$\\ell$')\n",
    "ylabel(r'$C_\\ell$')\n",
    "title('Nside = {0:} - RMS={1:5.1f} - Expected:{2:5.1f}'.format(nside, signoise, rms_uncorr))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dcfd9cd",
   "metadata": {},
   "source": [
    "Now we can try to smooth the very same map with a constant kernel and see the result. We should get exactly the input map... To check this we look at the RMS and power spectrum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39bfb893",
   "metadata": {},
   "outputs": [],
   "source": [
    "### General parameters\n",
    "nside = 128\n",
    "lmax = 2*nside\n",
    "ell = np.arange(lmax+1)\n",
    "npix = 12 * nside**2\n",
    "signoise = 10.\n",
    "myiter = 3\n",
    "use_weights = False\n",
    "\n",
    "### Map realization\n",
    "map_uncorr = np.random.randn(npix) * signoise\n",
    "rms_uncorr = np.std(map_uncorr)\n",
    "\n",
    "### Smoothing input map with a constant kernel with some random normalization and too wide ell range\n",
    "kernel = np.ones(2*nside)*np.random.rand(1)*3\n",
    "# normalize kernel and reduce to convenient ell range\n",
    "#mykernel = kernel[0:lmax+1]/kernel[0]\n",
    "mykernel = np.ones(lmax+1)\n",
    "# beware it should be the square root of the Cell kernel \n",
    "map_smooth = hp.smoothing(map_uncorr, beam_window=np.sqrt(mykernel), iter=myiter, use_weights=use_weights)\n",
    "rms_smooth = np.std(map_smooth)\n",
    "\n",
    "subplot(1,2,1)\n",
    "#plot(kernel, label='Unnormalized Kernel')\n",
    "plot(ell, mykernel, label = 'Normalized and ell-restricted kernel')\n",
    "plot(ell, ell*0+1,'k:')\n",
    "ylim(0,3)\n",
    "legend()\n",
    "\n",
    "### Power spectrum from maps\n",
    "cl_uncorr = hp.anafast(map_uncorr, lmax=lmax, iter=myiter, use_weights=use_weights)\n",
    "cl_smooth = hp.anafast(map_smooth, lmax=lmax, iter=myiter, use_weights=use_weights)\n",
    "\n",
    "### Theoretical power spectrum\n",
    "clth_uncorr = ell*0+signoise**2 * 4*np.pi / npix\n",
    "print(len(cl_uncorr), len(ell))\n",
    "\n",
    "### Plotting Unocorrelated\n",
    "subplot(1,2,2)\n",
    "p=plot(ell, cl_uncorr, lw=3, label='In Uncorr. RMS={0:5.1f} - Exp:{1:5.1f}'.format(signoise, rms_uncorr))\n",
    "plot(ell, clth_uncorr, 'k--', label='Theoretical Uncorrelated Cl')\n",
    "p1=plot(ell, cl_smooth, ':', lw=3, label='Smoothed map RMS={0:5.1f} - Exp:{1:5.1f} - Ratio={2:5.2f}'.format(signoise, rms_smooth, rms_smooth/signoise))\n",
    "legend(loc='upper right', fontsize=10)\n",
    "xlabel(r'$\\ell$')\n",
    "ylabel(r'$C_\\ell$')\n",
    "title('Nside = {0:}'.format(nside))\n",
    "\n",
    "figure()\n",
    "hp.mollview(map_uncorr, min=-3*signoise, max=3*signoise, \n",
    "            title='Map Uncorr - RMS={0:5.1f}'.format(rms_uncorr), sub=(1,2,1))\n",
    "hp.mollview(map_smooth, min=-3*signoise, max=3*signoise, \n",
    "            title='Map Smoothed - RMS={0:5.1f}'.format(rms_smooth), sub=(1,2,2))\n",
    "figure()\n",
    "title('Comparing Cells - nside = {}'.format(nside))\n",
    "plot(ell, np.abs((cl_uncorr-cl_smooth))/cl_smooth*100)\n",
    "xlabel(r'$\\ell$')\n",
    "ylabel('Difference in %')\n",
    "yscale('log')\n",
    "print(cl_uncorr[0:10])\n",
    "print(cl_smooth[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b84d6311",
   "metadata": {},
   "source": [
    "So there is already a problem here as although the Cls of the smoothed map are the same as the input it does not have the same RMS by a quite large amount...!!!\n",
    "\n",
    "This is likely to be caused by missing modes in the kernel that is cut beyond 2*nside. This is confirmed when extending the ell range beyond 2*nside:\n",
    "- for lmax = 2 x nside the RMS ratio is 0.58\n",
    "- for lmax = 3 x nside the RMS ratio is 0.86 with a few very bad bins at large ell\n",
    "- for lmax = 4 x nside the RMS ratio is 0.86 and the Cell difference becomes very large beyond 3x nside. the smoothed ones are at zero while the input ones are not... \n",
    "\n",
    "Notes:\n",
    "- the above ratios are independent of the nside\n",
    "- that the RMS ratio is constant independently of the realization.\n",
    "- playing with the \"iter\" keyword for hp.anafast() and hp.smoothing() does not change anything.\n",
    "- putting use_weights=True in hp.anafast() and hp.smoothing() does not change anything\n",
    "\n",
    "So apparently there is significant truncation at large ells that has this undersirable effect. We need to find a way to avoid this.\n",
    "\n",
    "Maybe the right way is to directly get the alms and build my own function..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fbe9550",
   "metadata": {},
   "source": [
    "## Method 2: smooth the alms by myself\n",
    "Let's first try to go bak and forth between map and alm and see if the map is distorted in the process. We see the exact same issues:\n",
    "- RMS ratio same at above\n",
    "- independent from nside, realization, iter or use_weights\n",
    "\n",
    "We define a function here in order to be. able to try different casses easily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "519c2034",
   "metadata": {},
   "outputs": [],
   "source": [
    "### General parameters\n",
    "nside = 128\n",
    "lmax = 4*nside\n",
    "ell = np.arange(lmax+1)\n",
    "npix = 12 * nside**2\n",
    "signoise = 10.\n",
    "myiter = 4\n",
    "use_weights=False\n",
    "\n",
    "def doit(nside, signoise, lmax_nside = 2., myiter=3, use_weights=False, seed=42):\n",
    "    if seed is not None:\n",
    "        np.random.seed(42)\n",
    "        \n",
    "    lmax = int(lmax_nside*nside)\n",
    "    ell = np.arange(lmax+1)\n",
    "    npix = 12 * nside**2\n",
    "\n",
    "    ### Theoretical power spectrum\n",
    "    clth_uncorr = ell*0+signoise**2 * 4*np.pi / npix\n",
    "\n",
    "    ### Map realization\n",
    "    map_uncorr = np.random.randn(npix) * signoise\n",
    "    rms_uncorr = np.std(map_uncorr)\n",
    "\n",
    "    ### Getting alms:\n",
    "    alms = hp.map2alm(map_uncorr, lmax=lmax, iter=myiter, use_weights=use_weights)\n",
    "    map_back = hp.alm2map(alms, nside, lmax=lmax)\n",
    "    rms_back = np.std(map_back)\n",
    "\n",
    "    ### Calculate Cells:\n",
    "    cls_uncorr = hp.anafast(map_uncorr, lmax=lmax, iter=myiter, use_weights=use_weights)\n",
    "    cls_fromalm = hp.alm2cl(alms, lmax=lmax)\n",
    "    cls_back = hp.anafast(map_back, lmax=lmax, iter=myiter, use_weights=use_weights)\n",
    "\n",
    "    subplot(1,2,1)\n",
    "    plot(ell, cls_uncorr, label='Cls Uncorr')\n",
    "    plot(ell, cls_fromalm, '--',label='Cls From alms')\n",
    "    plot(ell, cls_back, label='Cls from anafast(alm2map(map2alm(uncorr)))')\n",
    "    plot(ell, clth_uncorr, 'k--', label='Theoretical Uncorrelated Cl')\n",
    "    axvline(1*nside, ls=':')\n",
    "    axvline(2*nside, ls=':')\n",
    "    axvline(3*nside, ls=':')\n",
    "    ylim(0, 2*clth_uncorr[0])\n",
    "    legend()\n",
    "    title('nside={} lmax/nside={} iter={} weights={}'.format(nside, lmax_nside, myiter, use_weights))\n",
    "\n",
    "\n",
    "    hp.mollview(map_uncorr, min=-3*signoise, max=3*signoise, \n",
    "                title='Map Uncorr - RMS={0:5.1f}'.format(rms_uncorr), sub=(2,2,2))\n",
    "    hp.mollview(map_back, min=-3*signoise, max=3*signoise, \n",
    "                title='Map Back - RMS={0:5.1f}'.format(rms_back), sub=(2,2,4))\n",
    "\n",
    "    tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a4df446",
   "metadata": {},
   "source": [
    "We see below that weights do not change anything while the number of iterations plays a role:\n",
    "- when iter is odd we see a significant distorsion starting at ell=2*nside\n",
    "- when iter is even the distorstion reallys tarts at 3.5 x nside\n",
    "This is is very strange...\n",
    "\n",
    "We also note that:\n",
    "- Cls from anafast(map) are equal to calculating them from the alms of the map (logical)\n",
    "- Cls from the map reconstructed from the alms are more or less in agreement with initial ones and theorey up to 2 x nside when iter is odd while only up to 1 x nside when iter is even..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b75e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "nside = 128\n",
    "lmax_nside = 2.\n",
    "ell = np.arange(lmax+1)\n",
    "npix = 12 * nside**2\n",
    "signoise = 10.\n",
    "myiter = 4\n",
    "use_weights=False\n",
    "\n",
    "doit(nside, signoise, lmax_nside=4)\n",
    "\n",
    "figure()\n",
    "doit(nside, signoise, lmax_nside=4, myiter=4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cfa5bda",
   "metadata": {},
   "source": [
    "One thing to try is to use ud_grade to artificially work with higher nside ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd0d79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### General parameters\n",
    "nside = 128\n",
    "signoise = 10.\n",
    "\n",
    "def doit_shift_nside(nside, signoise, nside_fact = 2, lmax_nside = 2., myiter=3, use_weights=False, seed=42):\n",
    "    if seed is not None:\n",
    "        np.random.seed(42)\n",
    "        \n",
    "    # normal maps\n",
    "    lmax = int(lmax_nside*nside)\n",
    "    ell = np.arange(lmax+1)\n",
    "    npix = 12 * nside**2\n",
    "    \n",
    "    # higher resolution maps\n",
    "    nside_big = nside_fact * nside\n",
    "    lmax_big = int(2*nside_big)\n",
    "    ell_big = np.arange(lmax_big+1)\n",
    "    npix_big = 12 * nside_big**2\n",
    "\n",
    "    ### Theoretical power spectrum\n",
    "    clth_uncorr = ell*0+signoise**2 * 4*np.pi / npix\n",
    "\n",
    "    ### Map realization with large nside\n",
    "    map_uncorr_big = np.random.randn(npix_big) * signoise * nside_fact\n",
    "    rms_uncorr_big = np.std(map_uncorr_big)\n",
    "\n",
    "    ### THis is the degraded version of the map\n",
    "    map_uncorr = hp.ud_grade(map_uncorr_big, nside)\n",
    "    rms_uncorr = np.std(map_uncorr)\n",
    "    print('RMS uncorr Big:',rms_uncorr_big)\n",
    "    print('RMS uncorr:',rms_uncorr)\n",
    "    \n",
    "    ### Let's look at cls\n",
    "    cl_uncorr = hp.anafast(map_uncorr, lmax=lmax)\n",
    "    cl_uncorr_big = hp.anafast(map_uncorr_big, lmax=lmax_big)\n",
    "\n",
    "    ### Theoretical power spectrum\n",
    "    clth_uncorr = ell*0+signoise**2 * 4*np.pi / npix\n",
    "    \n",
    "    ### Now alms\n",
    "    alms = hp.map2alm(map_uncorr_big, lmax=lmax_big, iter=myiter, use_weights=use_weights)\n",
    "    map_back = hp.ud_grade(hp.alm2map(alms, nside_big, lmax=lmax_big), nside)\n",
    "    cl_back = hp.anafast(map_back, lmax=lmax)\n",
    "    rms_back = np.std(map_back)\n",
    "    print('RMS back:',rms_back)\n",
    "    \n",
    "\n",
    "    ### Plotting Unocorrelated\n",
    "    plot(ell_big, cl_uncorr_big, label='Input Uncorrelated map Big')\n",
    "    plot(ell, cl_uncorr, label='Uncorrelated map')\n",
    "    plot(ell, cl_back, label='Back')\n",
    "    plot(ell, clth_uncorr, 'r:', label='Theoretical Uncorrelated Cl')\n",
    "    legend()\n",
    "    xlim(0,4*nside)\n",
    "    xlabel(r'$\\ell$')\n",
    "    ylabel(r'$C_\\ell$')\n",
    "    title('Nside = {0:} - RMS Back={1:5.2f} - Expected:{2:5.2f}'.format(nside, rms_back, signoise))\n",
    "    \n",
    "    \n",
    "    \n",
    "doit_shift_nside(64, 2., nside_fact=4, seed=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda6b3a0",
   "metadata": {},
   "source": [
    "OK so going to higher nside seems to be working as expected: the effect of lmax truncation is much less. Let's now try to directly simulate the alms in harmonic space without a prior uncor map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e64cb79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def doit_shift_nside(nside, signoise, nside_fact = 2, lmax_nside = 2., \n",
    "                     generate_alm=True, doplot=True, verbose=True, \n",
    "                     myiter=3, use_weights=False, seed=42):\n",
    "    if seed is not None:\n",
    "        np.random.seed(42)\n",
    "        \n",
    "    # normal maps\n",
    "    lmax = int(lmax_nside*nside)\n",
    "    ell = np.arange(lmax+1)\n",
    "    npix = 12 * nside**2\n",
    "    \n",
    "    ### Theoretical power spectrum\n",
    "    clth_uncorr = ell*0+signoise**2 * 4*np.pi / npix\n",
    "\n",
    "    ### higher resolution maps\n",
    "    nside_big = nside_fact * nside\n",
    "    lmax_big = int(lmax_nside*nside_big)\n",
    "    ell_big = np.arange(lmax_big+1)\n",
    "    npix_big = 12 * nside_big**2\n",
    "\n",
    "    ### Genereate the alms be it in harmonic space or pixel-space\n",
    "    if generate_alm:\n",
    "        if verbose: print('simulate alms in harmonic space')\n",
    "        alm_size = hp.sphtfunc.Alm.getsize(lmax_big)\n",
    "        alm_rms = 1./np.sqrt(2) * signoise * nside_fact * np.sqrt(4 * np.pi/npix_big)\n",
    "        alms = (np.random.randn(alm_size) + np.random.randn(alm_size) * 1.0j) * alm_rms\n",
    "    else:\n",
    "        if verbose: print('Simulate in pixel-space an uncorrelated map')\n",
    "        ### Map realization with large nside\n",
    "        map_uncorr_big = np.random.randn(npix_big) * signoise * nside_fact\n",
    "        rms_uncorr_big = np.std(map_uncorr_big)    \n",
    "        ### Now alms\n",
    "        alms = hp.map2alm(map_uncorr_big, lmax=lmax_big, iter=myiter, use_weights=use_weights)\n",
    "\n",
    "    ### Now go back to pixel-space\n",
    "    map_back = hp.ud_grade(hp.alm2map(alms, nside_big, lmax=lmax_big, verbose=verbose), nside)\n",
    "    cl_back = hp.anafast(map_back, lmax=lmax)\n",
    "    rms_back = np.std(map_back)\n",
    "    \n",
    "    ### Plotting Unocorrelated\n",
    "    if doplot:\n",
    "        plot(ell, cl_back, label='Back')\n",
    "        plot(ell, clth_uncorr, 'r:', label='Theoretical Uncorrelated Cl')\n",
    "        legend()\n",
    "        xlim(0,lmax_nside*nside)\n",
    "        ylim(0,2*clth_uncorr[0])\n",
    "        xlabel(r'$\\ell$')\n",
    "        ylabel(r'$C_\\ell$')\n",
    "        title('Nside = {0:} -  AlmSpace={3:} \\n RMS Back={1:5.2f} - Expected:{2:5.2f}'.format(nside, rms_back, signoise, generate_alm))\n",
    "    \n",
    "### General parameters\n",
    "nside = 64\n",
    "signoise = 1.\n",
    "nside_fact = 8\n",
    "\n",
    "subplot(1,2,1)\n",
    "doit_shift_nside(nside, signoise, seed=None, nside_fact=nside_fact,generate_alm=False, doplot=True, verbose=False)\n",
    "print()\n",
    "subplot(1,2,2)\n",
    "doit_shift_nside(nside, signoise, seed=None, nside_fact=nside_fact,generate_alm=True, doplot=True, verbose=False)\n",
    "tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cd4bb5a",
   "metadata": {},
   "source": [
    "OK this is getting much better:\n",
    "- we can approach much better the RMS for the maps\n",
    "- the power spectrum is fine\n",
    "\n",
    "Note that directly generating the alms is much faster (factor 5) than generating in pixel space first\n",
    "\n",
    "Let's now try to apply a spectrum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa13ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def doit_shift_nside_cell(nside, signoise, clin = None, \n",
    "                          nside_fact = 2, lmax_nside = 2., \n",
    "                          generate_alm=True, doplot=True, verbose=True, \n",
    "                          myiter=3, use_weights=False, seed=42):\n",
    "    if seed is not None:\n",
    "        np.random.seed(42)\n",
    "        \n",
    "    # normal maps\n",
    "    lmax = int(lmax_nside*nside)\n",
    "    ell = np.arange(lmax+1)\n",
    "    npix = 12 * nside**2\n",
    "    \n",
    "    ### higher resolution maps\n",
    "    nside_big = nside_fact * nside\n",
    "    lmax_big = int(lmax_nside*nside_big)\n",
    "    ell_big = np.arange(lmax_big+1)\n",
    "    npix_big = 12 * nside_big**2\n",
    "    \n",
    "        ### Theoretical power spectrum\n",
    "    clth_uncorr = ell*0+signoise**2 * 4*np.pi / npix\n",
    "    \n",
    "    if clin is None:\n",
    "        clth = 1\n",
    "    else:\n",
    "        clth = clin[0:lmax_big+1]/clin[0] \n",
    "\n",
    "\n",
    "    ### Genereate the alms be it in harmonic space or pixel-space\n",
    "    if generate_alm:\n",
    "        if verbose: print('simulate alms in harmonic space')\n",
    "        alm_size = hp.sphtfunc.Alm.getsize(lmax_big)\n",
    "        alm_rms = 1./np.sqrt(2) * signoise * nside_fact * np.sqrt(4 * np.pi/npix_big)\n",
    "        alms = (np.random.randn(alm_size) + np.random.randn(alm_size) * 1.0j) * alm_rms\n",
    "    else:\n",
    "        if verbose: print('Simulate in pixel-space an uncorrelated map')\n",
    "        ### Map realization with large nside\n",
    "        map_uncorr_big = np.random.randn(npix_big) * signoise * nside_fact\n",
    "        rms_uncorr_big = np.std(map_uncorr_big)    \n",
    "        ### Now alms\n",
    "        alms = hp.map2alm(map_uncorr_big, lmax=lmax_big, iter=myiter, use_weights=use_weights)\n",
    "        \n",
    "    ### Apply filter:\n",
    "    alms = hp.almxfl(alms, np.sqrt(clth))\n",
    "    \n",
    "    ### Now go back to pixel-space\n",
    "    map_back = hp.ud_grade(hp.alm2map(alms, nside_big, lmax=lmax_big, verbose=verbose), nside)\n",
    "    cl_back = hp.anafast(map_back, lmax=lmax)\n",
    "    rms_back = np.std(map_back)\n",
    "    \n",
    "    ### Plotting Unocorrelated\n",
    "    if doplot:\n",
    "        plot(ell, cl_back, label='Back')\n",
    "        plot(ell, clth_uncorr, 'r:', label='Theoretical Uncorrelated Cl')\n",
    "        if clin is not None:\n",
    "            plot(ell, clin[0:lmax+1]/clin[0] * clth_uncorr, 'r--', label='Theoretical Correlated Cl')\n",
    "        legend()\n",
    "        xlim(0,lmax_nside*nside)\n",
    "        ylim(0,2*clth_uncorr[0])\n",
    "        xlabel(r'$\\ell$')\n",
    "        ylabel(r'$C_\\ell$')\n",
    "        title('Nside = {0:} -  AlmSpace={3:} \\n RMS Back={1:5.2f} - Expected:{2:5.2f}'.format(nside, rms_back, signoise, generate_alm))\n",
    "    \n",
    "### General parameters\n",
    "nside = 64\n",
    "signoise = 1.\n",
    "nside_fact = 8\n",
    "\n",
    "subplot(1,2,1)\n",
    "doit_shift_nside_cell(nside, signoise, seed=None, clin = mycell,  \n",
    "                 nside_fact=nside_fact,generate_alm=False, \n",
    "                 doplot=True, verbose=False)\n",
    "print()\n",
    "subplot(1,2,2)\n",
    "doit_shift_nside_cell(nside, signoise, seed=None, clin= mycell, \n",
    "                 nside_fact=nside_fact,generate_alm=True, \n",
    "                 doplot=True, verbose=False)\n",
    "tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82541d35",
   "metadata": {},
   "source": [
    "That looks very nice ! Let's build a function to do that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd5a40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_correlated_map(nside, signoise, clin = None, \n",
    "                            nside_fact = 1, lmax_nside = 2., \n",
    "                            generate_alm=True, verbose=True, \n",
    "                            myiter=3, use_weights=False, seed=None, synfast=False):\n",
    "    \n",
    "    #### Define the seed\n",
    "    if seed is not None:\n",
    "        np.random.seed(42)\n",
    "        \n",
    "    #### We can work at the planned nside\n",
    "    # normal maps\n",
    "    lmax = int(lmax_nside*nside)\n",
    "    ell = np.arange(lmax+1)\n",
    "    npix = 12 * nside**2\n",
    "    \n",
    "    #### Or with higher resolution maps in order to reduce the effect of aliasing on the RMS of the maps\n",
    "    #### However this does not change the Cl spectrum so is likely to be worthless\n",
    "    ### higher resolution maps\n",
    "    nside_big = nside_fact * nside\n",
    "    lmax_big = int(lmax_nside*nside_big)\n",
    "    ell_big = np.arange(lmax_big+1)\n",
    "    npix_big = 12 * nside_big**2\n",
    "    \n",
    "    #### We also need to account for the pixel window function\n",
    "    pixwin = hp.pixwin(nside_big)[:lmax_big+1]*0+1\n",
    "    if clin is None:\n",
    "        clth = 1./pixwin**2\n",
    "    else:\n",
    "        clth = clin[0:lmax_big+1]/clin[0]/pixwin**2\n",
    "\n",
    "        \n",
    "    #### There are three options here\n",
    "    # 1. use ssynfast to directly generate the map with the correct spectrum (fastest)\n",
    "    # 2. generate alms by hand and go back to map-sapce (essentially equivalent to the previous)\n",
    "    # 3. generate a map in pixel space, smooth it with hp.smoothing() => slower by ~ factor 5\n",
    "\n",
    "    if synfast:\n",
    "        ### Case 1.\n",
    "        fact = signoise*np.sqrt(4 * np.pi/npix_big)* nside_fact\n",
    "        map_back = hp.synfast(clth, nside_big,lmax=lmax_big, verbose=False)*fact\n",
    "    else:\n",
    "        ### Cases 2 and 3 Genereate the alms be it in harmonic space or pixel-space\n",
    "        if generate_alm:\n",
    "            ### Case 2\n",
    "            if verbose: print('simulate alms in harmonic space')\n",
    "            alm_size = hp.sphtfunc.Alm.getsize(lmax_big)\n",
    "            alm_rms = 1./np.sqrt(2) * signoise * nside_fact * np.sqrt(4 * np.pi/npix_big)\n",
    "            alms = (np.random.randn(alm_size) + np.random.randn(alm_size) * 1.0j) * alm_rms\n",
    "        else:\n",
    "            ### Case 3\n",
    "            if verbose: print('Simulate in pixel-space an uncorrelated map')\n",
    "            ### Map realization with large nside\n",
    "            map_uncorr_big = np.random.randn(npix_big) * signoise * nside_fact\n",
    "            rms_uncorr_big = np.std(map_uncorr_big)    \n",
    "            ### Now alms\n",
    "            alms = hp.map2alm(map_uncorr_big, lmax=lmax_big, iter=myiter, use_weights=use_weights)\n",
    "\n",
    "        ### Apply filter:\n",
    "        alms = hp.almxfl(alms, np.sqrt(clth))\n",
    "\n",
    "        ### Now go back to pixel-space\n",
    "        map_back = hp.alm2map(alms, nside_big, lmax=lmax_big, verbose=verbose)\n",
    "           \n",
    "    if nside_fact==1:\n",
    "        return map_back\n",
    "    else: \n",
    "        return hp.ud_grade(map_back, nside)\n",
    "\n",
    "\n",
    "\n",
    "nside = 64\n",
    "signoise = 1.\n",
    "nside_fact = 8\n",
    "lmax = 2*nside\n",
    "npix = 12*nside**2\n",
    "\n",
    "mymap = simulate_correlated_map(nside, signoise, seed=None, clin= mycell, \n",
    "                                 nside_fact=nside_fact,generate_alm=True, verbose=False)\n",
    "\n",
    "print('RMS = {0:5.2f}'.format(np.std(mymap)))\n",
    "cls = hp.anafast(mymap, lmax=lmax)\n",
    "ell = np.arange(lmax+1)\n",
    "\n",
    "plot(ell, cls)\n",
    "plot(mycell[:lmax+1]/mycell[0] * signoise**2 * 4*np.pi / npix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c500c647",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qubic.utils import progress_bar\n",
    "# Monte-carlo\n",
    "nbmc = 100\n",
    "nside = 64\n",
    "signoise = 1.\n",
    "nside_fact = 1\n",
    "lmax = 2*nside\n",
    "npix = 12*nside**2\n",
    "\n",
    "\n",
    "allcl = np.zeros((nbmc, lmax+1))\n",
    "allrms = np.zeros(nbmc)\n",
    "bar = progress_bar(nbmc)\n",
    "for i in range(nbmc):\n",
    "    mymap = simulate_correlated_map(nside, signoise, seed=None, clin= mycell, synfast=True, \n",
    "                                 nside_fact=nside_fact,generate_alm=True, verbose=False)\n",
    "\n",
    "    allrms[i] = np.std(mymap)\n",
    "    allcl[i,:] = hp.anafast(mymap, lmax=lmax)\n",
    "    bar.update()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c738691a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import qubic.fibtools as ft\n",
    "clth = mycell[:lmax+1]/mycell[0] * signoise**2 * 4*np.pi / npix\n",
    "lth = np.arange(lmax+1)\n",
    "\n",
    "ell = np.arange(lmax+1)\n",
    "subplot(1,2,1)\n",
    "errorbar(ell, np.mean(allcl, axis=0), yerr=np.std(allcl, axis=0)/np.sqrt(nbmc), fmt='ro', label='MC')\n",
    "plot(lth, clth, label='Expected')\n",
    "xlabel(r'$\\ell$')\n",
    "ylabel(r'$C_\\ell$')\n",
    "legend()\n",
    "\n",
    "pull = (np.mean(allcl, axis=0) - np.interp(ell, lth, clth))/(np.std(allcl, axis=0)/np.sqrt(nbmc))\n",
    "subplot(2,2,2)\n",
    "a = hist(pull, label=ft.statstr(pull))\n",
    "xlabel(r'$C_\\ell$ Pull')\n",
    "legend()\n",
    "\n",
    "subplot(2,2,4)\n",
    "a = hist(allrms, range=[np.mean(allrms)-4*np.std(allrms), np.mean(allrms)+4*np.std(allrms)], bins=15,\n",
    "        label=ft.statstr(allrms)+'\\n expexcted: {}'.format(signoise))\n",
    "xlabel('Map RMS')\n",
    "legend()\n",
    "\n",
    "tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc59176",
   "metadata": {},
   "source": [
    "So we now have a rather well understood code:\n",
    "- we can still use synfast with excellent agreement with the expected power spectrum, however aliasing indicess a disagreement on the. map RMS which may not at all be an issue at the end of the day as this comes from modes outside the relevant bandwidth...\n",
    "- If having a good agreement on the RMS as well, it is possible to achieve a much better (although not oerfect) agreement by going up to higher nside (by a factor 4 or 8) using synfast or alm production.\n",
    "- It is also possible to generate and random map in pixel space and convolve it but it's much slower (factor 5)\n",
    "\n",
    "Now we want to check the C(theta) function... that was the initial point... But maybe it's not going to be very. satisfactory because of the RMS issue..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1f6177",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_corr_neighbtheta(themap_in, ipok_in, thetamin, thetamax, nbins, degrade=None, verbose=True):\n",
    "    if degrade is None:\n",
    "        themap = themap_in.copy()\n",
    "        ipok = ipok_in.copy()\n",
    "    else:\n",
    "        themap = hp.ud_grade(themap_in, degrade)\n",
    "        mapbool = themap_in < -1e30\n",
    "        mapbool[ipok_in] = True\n",
    "        mapbool = hp.ud_grade(mapbool, degrade)\n",
    "        ip = np.arange(12*degrade**2)\n",
    "        ipok = ip[mapbool]\n",
    "    rthmin = np.radians(thetamin)\n",
    "    rthmax = np.radians(thetamax)\n",
    "    thvals = np.linspace(rthmin, rthmax, nbins+1)\n",
    "    ns = hp.npix2nside(len(themap))\n",
    "    thesum = np.zeros(nbins)\n",
    "    thecount = np.zeros(nbins)\n",
    "    for i in range(len(ipok)):\n",
    "        valthis = themap[ipok[i]]\n",
    "        v = hp.pix2vec(ns, ipok[i])\n",
    "        #ipneighb_inner = []\n",
    "        ipneighb_inner = list(hp.query_disc(ns, v, np.radians(thetamin)))\n",
    "        for k in range(nbins): \n",
    "            thmin = thvals[k]\n",
    "            thmax = thvals[k+1]\n",
    "            ipneighb_outer = list(hp.query_disc(ns, v, thmax))\n",
    "            ipneighb = ipneighb_outer.copy()\n",
    "            for l in ipneighb_inner: ipneighb.remove(l)\n",
    "            valneighb = themap[ipneighb]\n",
    "            thesum[k] += np.sum(valthis * valneighb)\n",
    "            thecount[k] += len(valneighb)\n",
    "            ipneighb_inner = ipneighb_outer.copy()\n",
    "            \n",
    "    corrfct = thesum / thecount\n",
    "    return np.degrees(thvals[:-1]+thvals[1:])/2, corrfct\n",
    "\n",
    "\n",
    "def ctheta_parts(themap, ipok, thetamin, thetamax, nbinstot, nsplit=4, degrade_init=None, verbose=True):\n",
    "    allthetalims = np.linspace(thetamin, thetamax, nbinstot+1)\n",
    "    thmin = allthetalims[:-1]\n",
    "    thmax = allthetalims[1:]\n",
    "    idx = np.arange(nbinstot)//(nbinstot//nsplit)\n",
    "    if degrade_init is None:\n",
    "        nside_init = hp.npix2nside(len(themap))\n",
    "    else:\n",
    "        nside_init = degrade_init\n",
    "    nside_part = nside_init // (2**idx)\n",
    "    thall = (thmin+thmax)/2\n",
    "    cthall = np.zeros(nbinstot)\n",
    "    for k in range(nsplit):\n",
    "        thispart = idx==k\n",
    "        mythmin = np.min(thmin[thispart])\n",
    "        mythmax = np.max(thmax[thispart])\n",
    "        mynbins = nbinstot//nsplit\n",
    "        mynside = nside_init // (2**k)\n",
    "        if verbose: print('Doing {0:3.0f} bins between {1:5.2f} and {2:5.2f} deg at nside={3:4.0f}'.format(mynbins, mythmin, mythmax, mynside))\n",
    "        myth, mycth = map_corr_neighbtheta(themap, ipok, mythmin, mythmax, mynbins, degrade=mynside, verbose=verbose)\n",
    "        cthall[thispart] = mycth \n",
    "    return thall, cthall\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe63569",
   "metadata": {},
   "source": [
    "Let's take the example of a white noise map and check if it's fine:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "370e7c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "nside = 128\n",
    "thetamin = 0.\n",
    "thetamax = 20.\n",
    "nbins = 40\n",
    "ipok = np.arange(12*nside**2)  ## we take all pixels\n",
    "signoise = 1.\n",
    "\n",
    "nbmc = 10\n",
    "all_cthmes = np.zeros((nbmc, nbins))\n",
    "\n",
    "for i in range(nbmc):\n",
    "    print(i, nbmc)\n",
    "    mymap = np.random.randn(12*nside**2) * signoise\n",
    "    thmes, all_cthmes[i,:] = ctheta_parts(mymap, np.arange(12*nside), thetamin, thetamax, nbins, nsplit=5, \n",
    "                                         degrade_init=128, verbose=False)\n",
    "\n",
    "m_cthmes = np.mean(all_cthmes, axis=0)\n",
    "s_cthmes = np.std(all_cthmes, axis=0)\n",
    "errorbar(thmes, m_cthmes, yerr=s_cthmes, fmt='ro')\n",
    "plot(linspace(thetamin, thetamax,100), np.zeros(100), 'k:')\n",
    "xlabel(r'$\\theta$ [deg]')\n",
    "ylabel(r'$C(\\theta)$')\n",
    "xlim(thetamin, thetamax)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca1ec38a",
   "metadata": {},
   "source": [
    "Now we have the tools and we can test the spatial-correlation simulation.\n",
    "\n",
    "We take some model for the input correlation function $C(\\theta)$ and calculate the corresponding $C_\\ell$ using the \n",
    "functions tested above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e748bf10",
   "metadata": {},
   "outputs": [],
   "source": [
    "nth = 1000\n",
    "theta = np.linspace(0,90,nth)\n",
    "\n",
    "#### Normalization of c(theta=0) ###################################\n",
    "normalization = 1.#2 * np.pi\n",
    "####################################################################\n",
    "\n",
    "fct = lambda x, a, b, c: a * np.sin(x/b) * exp(-x/c)\n",
    "a = 0.48\n",
    "b = 2.14\n",
    "c = 4.27\n",
    "myctheta = fct(theta, a,b,c)\n",
    "myctheta[0] = 1.\n",
    "\n",
    "\n",
    "#### Calculation of the corresponding Cell\n",
    "myell, mycell = ctheta_2_cell(theta, myctheta, 2048, normalization=normalization)\n",
    "\n",
    "subplot(1,2,1)\n",
    "plot(theta, myctheta)\n",
    "plot(theta, theta*0, 'k:')\n",
    "xlabel(r'$\\theta$ [deg]')\n",
    "ylabel(r'$C(\\theta)$')\n",
    "\n",
    "subplot(1,2,2)\n",
    "plot(myell, mycell)\n",
    "plot(myell, myell*0+normalization, 'k:')\n",
    "xlabel(r'$\\ell$')\n",
    "ylabel(r'$C_\\ell$')\n",
    "title('normalization={0:5.3f}'.format(normalization))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d144c272",
   "metadata": {},
   "source": [
    "We now take this as an input and perform a Monte carlo in the following manner:\n",
    "- generate a correlated noise image according to the method developped above\n",
    "- Calculate the C(theta) of the recovered map\n",
    "\n",
    "When averaging over MC realizations, one should recover the input $C(\\theta)$ and $C_\\ell$..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d03dbbd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qubic.utils import progress_bar\n",
    "## Let's try an MC\n",
    "nside = 128\n",
    "nbmc = 100\n",
    "nbins = 20\n",
    "thmax = 20.\n",
    "signoise = 1.\n",
    "nside_fact = 1\n",
    "lmax = 2*nside\n",
    "allip = np.arange(12*nside**2)\n",
    "\n",
    "allclout = np.zeros((nbmc, lmax+1))\n",
    "all_cthout = np.zeros((nbmc, nbins))\n",
    "all_rms = np.zeros(nbmc)\n",
    "bar = progress_bar(nbmc)\n",
    "for i in range(nbmc):\n",
    "    outmap = simulate_correlated_map(nside, signoise, seed=None, clin= mycell, synfast=True, \n",
    "                                     nside_fact=nside_fact,generate_alm=False, verbose=False)\n",
    "    all_rms[i] = np.std(outmap)\n",
    "    \n",
    "    ### Calculate the Cells from the correlated map\n",
    "    allclout[i,:]=hp.anafast(outmap, lmax=lmax)\n",
    "    \n",
    "    ### Calculate the C(theta) from our map\n",
    "    th, all_cthout[i,:] = ctheta_parts(outmap, allip, 0, thmax, nbins, \n",
    "                                        nsplit=4, degrade_init=nside//2, verbose=False)\n",
    "    bar.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eedc8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### We calculate the average of the MC Cells\n",
    "mcl_corr = np.mean(allclout, axis=0) \n",
    "ell = np.arange(lmax+1)\n",
    "\n",
    "npix = 12*nside**2\n",
    "clth = mycell[:lmax+1]/mycell[0] * signoise**2 * 4*np.pi / npix\n",
    "lth = np.arange(lmax+1)\n",
    "\n",
    "#### We calculate the average of the MC C(theta)\n",
    "mcthout = np.mean(all_cthout, axis=0)\n",
    "scthout = np.std(all_cthout, axis=0)/np.sqrt(nbmc)\n",
    "\n",
    "#### And now we plot them as well as the expected ones\n",
    "subplot(1,2,1)\n",
    "plot(lth, clth, label=r'Predicted $C_\\ell$')\n",
    "plot(ell, mcl_corr , label=r'MC $C_\\ell$')\n",
    "plot(lth, clth*0+clth[0] , 'k:')\n",
    "legend()\n",
    "xlim(0.1,np.max(ell))\n",
    "xlabel(r'$\\ell$')\n",
    "ylabel(r'$C_\\ell$')\n",
    "\n",
    "#### And now we plot them as well as the expected one\n",
    "factormult = 7\n",
    "stretchth = 1.\n",
    "subplot(1,2,2)\n",
    "errorbar(th*stretchth, (mcthout/mcthout[0]*factormult), yerr=scthout/mcthout[0]*factormult, fmt='ro', label=r'MC $C(\\theta) \\times${}'.format(factormult))\n",
    "plot(theta,myctheta/myctheta[0],'o',label=r'Input $C(\\theta)$')\n",
    "plot(theta,theta*0,'k:')\n",
    "xlim(0,20)\n",
    "ylim(-0.1,1.5)\n",
    "legend()\n",
    "print(mcthout/mcthout[0])\n",
    "print(np.mean(all_rms))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c5c5c3",
   "metadata": {},
   "source": [
    "### Avec normalisation C(theta) = 2*np.pi\n",
    "- on a des Cl avec bcp moins d'amplitude\n",
    "- le C(theta) aussi\n",
    "\n",
    "### Verifier Ã§a\n",
    "avec fact_nside = 8 on se retrouve bcp plus bas que x7\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884b50f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b5483cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53da3f65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a87fa4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf9b2a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa2e9e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc9706b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca76680",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165bb352",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0b208e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb7acfb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f24e5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ff6fec58",
   "metadata": {},
   "source": [
    "Now we want to test this with a Monte-Carlo simulation. We will need a function to calculate the C(theta) from a healpix map. This is usually very slow if done without tricks. Here I degrade the map to different nside to have less pixels to deal with when going to large angles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f498438",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_corr_neighbtheta(themap_in, ipok_in, thetamin, thetamax, nbins, degrade=None, verbose=True):\n",
    "    if degrade is None:\n",
    "        themap = themap_in.copy()\n",
    "        ipok = ipok_in.copy()\n",
    "    else:\n",
    "        themap = hp.ud_grade(themap_in, degrade)\n",
    "        mapbool = themap_in < -1e30\n",
    "        mapbool[ipok_in] = True\n",
    "        mapbool = hp.ud_grade(mapbool, degrade)\n",
    "        ip = np.arange(12*degrade**2)\n",
    "        ipok = ip[mapbool]\n",
    "    rthmin = np.radians(thetamin)\n",
    "    rthmax = np.radians(thetamax)\n",
    "    thvals = np.linspace(rthmin, rthmax, nbins+1)\n",
    "    ns = hp.npix2nside(len(themap))\n",
    "    thesum = np.zeros(nbins)\n",
    "    thecount = np.zeros(nbins)\n",
    "    for i in range(len(ipok)):\n",
    "        valthis = themap[ipok[i]]\n",
    "        v = hp.pix2vec(ns, ipok[i])\n",
    "        #ipneighb_inner = []\n",
    "        ipneighb_inner = list(hp.query_disc(ns, v, np.radians(thetamin)))\n",
    "        for k in range(nbins): \n",
    "            thmin = thvals[k]\n",
    "            thmax = thvals[k+1]\n",
    "            ipneighb_outer = list(hp.query_disc(ns, v, thmax))\n",
    "            ipneighb = ipneighb_outer.copy()\n",
    "            for l in ipneighb_inner: ipneighb.remove(l)\n",
    "            valneighb = themap[ipneighb]\n",
    "            thesum[k] += np.sum(valthis * valneighb)\n",
    "            thecount[k] += len(valneighb)\n",
    "            ipneighb_inner = ipneighb_outer.copy()\n",
    "            \n",
    "    corrfct = thesum / thecount\n",
    "    return np.degrees(thvals[:-1]+thvals[1:])/2, corrfct\n",
    "\n",
    "\n",
    "def ctheta_parts(themap, ipok, thetamin, thetamax, nbinstot, nsplit=4, degrade_init=None, verbose=True):\n",
    "    allthetalims = np.linspace(thetamin, thetamax, nbinstot+1)\n",
    "    thmin = allthetalims[:-1]\n",
    "    thmax = allthetalims[1:]\n",
    "    idx = np.arange(nbinstot)//(nbinstot//nsplit)\n",
    "    if degrade_init is None:\n",
    "        nside_init = hp.npix2nside(len(themap))\n",
    "    else:\n",
    "        nside_init = degrade_init\n",
    "    nside_part = nside_init // (2**idx)\n",
    "    thall = (thmin+thmax)/2\n",
    "    cthall = np.zeros(nbinstot)\n",
    "    for k in range(nsplit):\n",
    "        thispart = idx==k\n",
    "        mythmin = np.min(thmin[thispart])\n",
    "        mythmax = np.max(thmax[thispart])\n",
    "        mynbins = nbinstot//nsplit\n",
    "        mynside = nside_init // (2**k)\n",
    "        if verbose: print('Doing {0:3.0f} bins between {1:5.2f} and {2:5.2f} deg at nside={3:4.0f}'.format(mynbins, mythmin, mythmax, mynside))\n",
    "        myth, mycth = map_corr_neighbtheta(themap, ipok, mythmin, mythmax, mynbins, degrade=mynside, verbose=verbose)\n",
    "        cthall[thispart] = mycth \n",
    "    return thall, cthall\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6919b12b",
   "metadata": {},
   "source": [
    "Let's take the example of a white noise map and check if it's fine:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711342d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "nside = 128\n",
    "thetamin = 0.\n",
    "thetamax = 20.\n",
    "nbins = 40\n",
    "ipok = np.arange(12*nside**2)  ## we take all pixels\n",
    "signoise = 1.\n",
    "\n",
    "nbmc = 10\n",
    "all_cthmes = np.zeros((nbmc, nbins))\n",
    "\n",
    "for i in range(nbmc):\n",
    "    print(i, nbmc)\n",
    "    mymap = np.random.randn(12*nside**2) * signoise\n",
    "    thmes, all_cthmes[i,:] = ctheta_parts(mymap, np.arange(12*nside), thetamin, thetamax, nbins, nsplit=5, \n",
    "                                         degrade_init=128, verbose=False)\n",
    "\n",
    "m_cthmes = np.mean(all_cthmes, axis=0)\n",
    "s_cthmes = np.std(all_cthmes, axis=0)\n",
    "errorbar(thmes, m_cthmes, yerr=s_cthmes, fmt='ro')\n",
    "plot(linspace(thetamin, thetamax,100), np.zeros(100), 'k:')\n",
    "xlabel(r'$\\theta$ [deg]')\n",
    "ylabel(r'$C(\\theta)$')\n",
    "xlim(thetamin, thetamax)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce697fa",
   "metadata": {},
   "source": [
    "Now we have the tools and we can test the spatial-correlation simulation.\n",
    "\n",
    "We take some model for the input correlation function $C(\\theta)$ and calculate the corresponding $C_\\ell$ using the \n",
    "functions tested above. There are two case below (selected by commenting one or the other):\n",
    "- uncorrelated data\n",
    "- correlated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350246e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "nth = 1000\n",
    "theta = np.linspace(0,90,nth)\n",
    "\n",
    "#### Normalization of c(theta=0) ###################################\n",
    "normalization = 1.#2 * np.pi\n",
    "####################################################################\n",
    "\n",
    "\n",
    "#### First Case : uncorrelated data\n",
    "# myctheta = np.zeros(nth)\n",
    "# myctheta[0] = 1.\n",
    "\n",
    "\n",
    "#### Second case: correlated data following the model above\n",
    "fct = lambda x, a, b, c: a * np.sin(x/b) * exp(-x/c)\n",
    "a = 0.48\n",
    "b = 2.14\n",
    "c = 4.27\n",
    "myctheta = fct(theta, a,b,c)\n",
    "myctheta[0] = 1.\n",
    "\n",
    "\n",
    "#### Calculation of the corresponding Cell\n",
    "myell, mycell = ctheta_2_cell(theta, myctheta, 1024, normalization=normalization)\n",
    "\n",
    "subplot(1,2,1)\n",
    "plot(theta, myctheta)\n",
    "plot(theta, theta*0, 'k:')\n",
    "xlabel(r'$\\theta$ [deg]')\n",
    "ylabel(r'$C(\\theta)$')\n",
    "\n",
    "subplot(1,2,2)\n",
    "plot(myell, mycell)\n",
    "plot(myell, myell*0+normalization, 'k:')\n",
    "xlabel(r'$\\ell$')\n",
    "ylabel(r'$C_\\ell$')\n",
    "title('normalization={0:5.3f}'.format(normalization))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24b4dc19",
   "metadata": {},
   "source": [
    "We now take this as an input and perform a Monte carlo in the following manner:\n",
    "- generate a white noise map\n",
    "- smooth it using Healpy with the kernel calculated above\n",
    "- Calculate the C(theta) of the recovered map\n",
    "\n",
    "When averaging over MC realizations, one should recover the input $C(\\theta)$ and $C_\\ell$..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2491c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### This is to have an outmap that has RMS independent from nside\n",
    "#### This comes from the. fact that the cell we use here does not have a compact support...\n",
    "for ns in [32, 64, 128, 256, 512, 1024]:\n",
    "    lmax = 2*ns\n",
    "    norm = np.sum(mycell[:lmax+1])\n",
    "    outmap2 = hp.synfast(mycell[:lmax+1], ns, verbose=False, lmax=lmax)/norm*np.pi*np.sqrt(mycell[0])\n",
    "    print(ns, np.std(outmap2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57bd869f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Let's try an MC\n",
    "nside = 256\n",
    "nbmc = 100\n",
    "nbins = 20\n",
    "thmax = 20.\n",
    "signoise = 1.\n",
    "lmax = 2*nside\n",
    "allip = np.arange(12*nside**2)\n",
    "\n",
    "allclout = np.zeros((nbmc, lmax+1))\n",
    "all_cthout = np.zeros((nbmc, nbins))\n",
    "allclout2 = np.zeros((nbmc, lmax+1))\n",
    "all_cthout2 = np.zeros((nbmc, nbins))\n",
    "for i in range(nbmc):\n",
    "    print(i,nbmc)\n",
    "    #if ((i//10)*10)==i: print(i,nbmc)\n",
    "    ### Input uniform map\n",
    "    inmap = np.random.randn(12*nside**2)*signoise\n",
    "    ### Output correlated map\n",
    "    outmap = hp.smoothing(inmap, beam_window=(mycell[0:lmax+1]/mycell[0])**0.5 , verbose=False, lmax=lmax)\n",
    "    #outmap = outmap / np.std(outmap)\n",
    "\n",
    "    ### Calculate the Cells from the correlated map\n",
    "    allclout[i,:]=hp.anafast(outmap, lmax=lmax)\n",
    "    \n",
    "    ### Calculate the C(theta) from our map\n",
    "    th, all_cthout[i,:] = ctheta_parts(outmap, allip, 0, thmax, nbins, \n",
    "                                        nsplit=5, degrade_init=64, verbose=False)\n",
    "\n",
    "#     #ken's suggestion: use synfast : Because the Cell does not drop to zero at high ell\n",
    "#     norm = np.sum(mycell[:lmax+1])\n",
    "#     outmap2 = hp.synfast(mycell[:lmax+1], nside, verbose=False, lmax=lmax)/norm*np.pi*np.sqrt(mycell[0])\n",
    "#     allclout2[i,:]=hp.anafast(outmap2, lmax=lmax)\n",
    "#     th, all_cthout2[i,:] = ctheta_parts(outmap2, allip, 0, thmax, nbins, \n",
    "#                                         nsplit=3, degrade_init=nside//4, verbose=False)\n",
    "#     print('RMS maps',np.std(inmap),np.std(outmap), np.std(outmap2))\n",
    "    print('RMS maps',np.std(inmap),np.std(outmap))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21051250",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "#### We calculate the average of the MC Cells\n",
    "npix = 12*nside**2\n",
    "mcl_corr = np.mean(allclout, axis=0) / (4 * np.pi / npix)\n",
    "ell = np.arange(lmax+1)\n",
    "\n",
    "# mcl_corr2 = np.mean(allclout2, axis=0) / (4 * np.pi / npix)\n",
    "\n",
    "\n",
    "#### And now we plot them as well as the expected ones\n",
    "subplot(1,2,1)\n",
    "plot(myell, mycell*signoise**2, label=r'Predicted $C_\\ell$')\n",
    "plot(ell, mcl_corr , label=r'MC $C_\\ell$')\n",
    "# plot(ell, mcl_corr2 , label=r'MC $C_\\ell$ Synfast')\n",
    "plot(myell, myell*0+signoise**2 , 'k:')\n",
    "legend()\n",
    "xlim(0.1,np.max(ell)*1.5)\n",
    "xlabel(r'$\\ell$')\n",
    "ylabel(r'$C_\\ell$')\n",
    "xscale('log')\n",
    "\n",
    "#### We calculate the average of the MC C(theta)\n",
    "mcthout = np.mean(all_cthout, axis=0)\n",
    "scthout = np.std(all_cthout, axis=0)/np.sqrt(nbmc)\n",
    "# mcthout2 = np.mean(all_cthout2, axis=0)\n",
    "# scthout2 = np.std(all_cthout2, axis=0)/np.sqrt(nbmc)\n",
    "\n",
    "#### And now we plot them as well as the expected one\n",
    "factormult = 900\n",
    "stretchth = 1.\n",
    "subplot(1,2,2)\n",
    "errorbar(th*stretchth, (mcthout*factormult), yerr=scthout*factormult, fmt='ro', label=r'MC $C(\\theta) \\times${}'.format(factormult))\n",
    "# errorbar(th*stretchth, (mcthout2*factormult), yerr=scthout2*factormult, fmt='bo', label=r'MC $C(\\theta) \\times${} Synfast'.format(factormult))\n",
    "plot(theta,myctheta*signoise**2/np.std(outmap),label=r'Input $C(\\theta)$')\n",
    "plot(theta,theta*0,'k:')\n",
    "xlim(0,20)\n",
    "ylim(-0.1,0.5)\n",
    "legend()\n",
    "print(mcthout)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e040e4b7",
   "metadata": {},
   "source": [
    "So the conclusions are:\n",
    "- we get consistent $C_\\ell$ between the smoothed map and the expected ones.\n",
    "- For $C(\\theta)$ we get very small results, only multiplying them by factormult~7 above (which is close to $2\\pi$...) starts to show that they have a shape that is broadly similar to the expected one, but not exactly (slightly shifted toward small angles)\n",
    "\n",
    "Why is that so ? There are probbably many wrong normalizations everywhere, but I can't find them...\n",
    "\n",
    "Changing the casse $x=1$ back to $2\\pi$ insgtead of ! in the function ctheta_2_cell() at the beginning doess not solve the problem - it becomes actually even a larger factor (about 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e987ce6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00eec22c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2f08fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60684ee1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e4e700d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
