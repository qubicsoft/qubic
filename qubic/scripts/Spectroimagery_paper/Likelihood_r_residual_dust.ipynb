{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa2442f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import healpy as hp\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import pickle\n",
    "from itertools import combinations, combinations_with_replacement\n",
    "from importlib import reload\n",
    "\n",
    "# Specific qubic modules\n",
    "from qubicpack.utilities import Qubic_DataDir\n",
    "import pysm\n",
    "import qubic\n",
    "from qubic.polyacquisition import compute_freq\n",
    "from qubic import QubicSkySim as qss\n",
    "from qubic import camb_interface as qc\n",
    "from qubic import NamasterLib as nam\n",
    "from qubic import mcmc\n",
    "\n",
    "rc('figure', figsize=(16, 10))\n",
    "rc('font', size=15)\n",
    "plt.rcParams['image.cmap'] = 'jet'\n",
    "rc('font', size=18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac487b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir = os.environ['DATA_SPECTROIM']\n",
    "print(datadir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bbb6028",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Initialize\n",
    "global_dir = Qubic_DataDir(datafile='instrument.py', datadir=os.environ['QUBIC_DATADIR'])\n",
    "print(global_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87975fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = 'FI220'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2ef695a",
   "metadata": {},
   "source": [
    "## Qubic sky object with dust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a1aedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dictfilename = global_dir + '/dicts/pipeline_demo.dict'\n",
    "d = qubic.qubicdict.qubicDict()\n",
    "d.read_from_file(dictfilename)\n",
    "\n",
    "d['nside'] = 256\n",
    "d['filter_nu'] = int(config[-3:]) * 1e9\n",
    "print(d['filter_nu'], 'Hz')\n",
    "\n",
    "# Number of bands\n",
    "nbands = 2\n",
    "d['nf_recon'] = nbands\n",
    "d['nf_sub'] = nbands\n",
    "\n",
    "# Possible combinations between bands\n",
    "combi = list(combinations_with_replacement(np.arange(nbands), 2))\n",
    "ncombi = len(combi)\n",
    "print('combi:', combi)\n",
    "print('ncombi:', ncombi)\n",
    "    \n",
    "\n",
    "# Make a sky with dust\n",
    "sky_config_dust = {'dust': 'd1'}\n",
    "Qubic_sky = qss.Qubic_sky(sky_config_dust, d)\n",
    "\n",
    "# sky_config_dust1 = {'dust': 'd1'}\n",
    "# sky_config_dust2 = {'dust': 'd2'}\n",
    "\n",
    "# Qubic_sky1 = qss.Qubic_sky(sky_config_dust1, d)\n",
    "# Qubic_sky2 = qss.Qubic_sky(sky_config_dust2, d)\n",
    "\n",
    "# dust_map1 = Qubic_sky1.get_fullsky_convolved_maps(FWHMdeg=None, verbose=False)\n",
    "# dust_map2 = Qubic_sky2.get_fullsky_convolved_maps(FWHMdeg=None, verbose=False)\n",
    "# dust_map = (dust_map2 - dust_map1)/10\n",
    "# print(dust_map.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67d22bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "Nfreq_edges, nus_edge, nus, deltas, Delta, Nbbands = compute_freq(int(config[-3:]), nbands)\n",
    "print(nus)\n",
    "\n",
    "fwhms = [d['synthbeam_peak150_fwhm'] * 150 / nu for nu in nus]\n",
    "print(fwhms)\n",
    "\n",
    "nus_eff = []\n",
    "for i, (band1, band2) in enumerate(combi):\n",
    "    print(f'Bands {band1} {band2}')\n",
    "    nus_eff.append(np.sqrt(nus[band1] * nus[band2]))\n",
    "print(nus_eff)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33dd6e08",
   "metadata": {},
   "source": [
    "## Coverage and seenmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f263d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "DataFastSimCoverage = pickle.load(open(global_dir +\n",
    "                                       '/doc/FastSimulator/Data/DataFastSimulator_' + config +'_coverage.pkl',\n",
    "                                       \"rb\"))\n",
    "coverage = DataFastSimCoverage['coverage']\n",
    "seenmap = coverage > np.max(coverage) * 0.1\n",
    "\n",
    "# hp.gnomview(coverage, reso=15, title='Coverage')\n",
    "# plt.savefig('/home/lmousset/QUBIC/Qubic_work/SpectroImagerie/paper_plot/coverage_10000ptgs_galaxycenter_150GHz.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a945b40",
   "metadata": {},
   "source": [
    "## BBcov matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e18ee30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Covariance noise matrices\n",
    "\n",
    "# Old simu with bad photon noise\n",
    "# Factor 2 to rescale it for 2 years\n",
    "# BBcov = 2 * np.load('/home/lmousset/QUBIC/Qubic_work/SpectroImagerie/corr_matrices/pourClaudia/'\n",
    "#                        + f'BBcovariance_bincross_nfrecon{nbands}_samereal_' + config + '_v2.npy')\n",
    "\n",
    "# New simu with right photon noise\n",
    "BBcov = np.load('/home/lmousset/QUBIC/Qubic_work/SpectroImagerie/corr_matrices/pourClaudia/'\n",
    "                       + f'BBcovariance_bincross_nfrecon{nbands}_samereal_' + config + '_v4.npy')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10200807",
   "metadata": {},
   "source": [
    "# Theoretical spectra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9fb86a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a Namaster object (needed to bin the Camblib)\n",
    "nside = d['nside']\n",
    "lmin = 40\n",
    "lmax = 2 * nside - 1\n",
    "delta_ell = 30\n",
    "\n",
    "\n",
    "mask = np.zeros(12 * nside ** 2)\n",
    "mask[seenmap] = 1\n",
    "Namaster = nam.Namaster(mask, lmin=lmin, lmax=lmax, delta_ell=delta_ell)\n",
    "mask_apo = Namaster.get_apodized_mask()\n",
    "# hp.gnomview(mask_apo, reso=20, title='Mask')\n",
    "\n",
    "ell_binned, b = Namaster.get_binning(nside)\n",
    "nbins = len(ell_binned)\n",
    "print('lmin:', lmin)\n",
    "print('lmax:', lmax)\n",
    "print('delta_ell:', delta_ell)\n",
    "print('nbins:', nbins)\n",
    "print('ell binned:', ell_binned)\n",
    "print('Fsky: {}'.format(Namaster.fsky))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aeefb2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CAMB library already saved\n",
    "with open(global_dir + '/doc/CAMB/camblib_0to1_step001.pkl', \"rb\") as file:\n",
    "    camblib = pickle.load(file)\n",
    "[lll, rvalues, spec, specunlensed] = camblib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c81f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "binned_camblib = qc.bin_camblib(Namaster, global_dir + '/doc/CAMB/camblib_0to1_step001.pkl', nside, verbose=True)\n",
    "\n",
    "[lll_b, rvalues_b, spec_b, specunlensed_b] = binned_camblib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae8409ab",
   "metadata": {},
   "source": [
    "## Loop over the residual dust fraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8189bd8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute BB cross spectra for dust once \n",
    "# dust_fraction = [0., 0.005, 0.01, 0.015, 0.02, 0.025, 0.03, 0.035, 0.04, 0.045, 0.05]\n",
    "dust_fraction = np.arange(0., 0.011, 0.001)\n",
    "print(dust_fraction)\n",
    "BBcross_dust = np.zeros((len(dust_fraction), ncombi, nbins))\n",
    "\n",
    "for f, frac in enumerate(dust_fraction):\n",
    "    print('\\n dust fraction:', frac)\n",
    "    dust_map = Qubic_sky.get_fullsky_convolved_maps(FWHMdeg=None, verbose=False) * frac\n",
    "    \n",
    "    cross_dust = np.zeros((ncombi, nbins, 4))\n",
    "    for i, (band1, band2) in enumerate(combi):\n",
    "        print(f'Bands {band1} {band2}')\n",
    "        \n",
    "        beam_corr = np.sqrt(fwhms[band1] * fwhms[band2])\n",
    "        print(beam_corr)\n",
    "        \n",
    "        map1 = dust_map[band1, :, :]\n",
    "        map2 = dust_map[band2, :, :]\n",
    "        leff, cross_dust[i, :, :], w = Namaster.get_spectra(map1.T,\n",
    "                                                              mask_apo,\n",
    "                                                              map2.T,\n",
    "                                                              w=None,\n",
    "                                                              purify_e=True,\n",
    "                                                              purify_b=False,\n",
    "                                                              beam_correction=beam_corr,\n",
    "                                                              pixwin_correction=True)\n",
    "    BBcross_dust[f, :, :] = cross_dust[:, :, 2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e9e5ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_save = datadir + 'FastSimulator'\n",
    "# np.save(dir_save + '/BBcross_dust_d1_' + config[-3:] + f'_{nbands}bands_dustfrac0-0.01-step0.001.npy', BBcross_dust)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b3fd89",
   "metadata": {},
   "outputs": [],
   "source": [
    "BBcross_dust = np.load(dir_save + '/BBcross_dust_d1_' + config[-3:] + f'_{nbands}bands_dustfrac0-0.01-step0.001.npy')\n",
    "# BBcross_dust = np.load(dir_save + '/BBcross_dust_d1_' + config[-3:] + f'_{nbands}bands_dustfrac0-0.05-step0.005.npy')\n",
    "# BBcross_dust = np.load(dir_save + '/BBcross_dust_d1_' + config[-3:] + f'_{nbands}bands_dustfrac0-0.05-step0.01.npy')\n",
    "print(BBcross_dust.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a42a346",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hp.mollview(dust_map[0, :, 0], title='Dust residuals d1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3825b9b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "palet = sns.cubehelix_palette(len(dust_fraction), start=3, hue=1, light=0.75)\n",
    "sns.palplot(palet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b16322",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for f, frac in enumerate(dust_fraction):\n",
    "#     c = palet[f]\n",
    "#     plt.plot(ell_binned, BBcross_dust[f, 0, :], color=c, label=r'$f_{dust}$' +f' = {frac}')\n",
    "# plt.title('BB dust')\n",
    "# plt.ylabel('$D_\\ell$')\n",
    "# plt.xlabel('$\\ell$')\n",
    "# plt.grid()\n",
    "# plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e597486f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(3):\n",
    "#     plt.plot(ell_binned, BBcross_dust[f, 0, :], label=f'IBCS {i}')\n",
    "# plt.title('BB dust d2-d1')\n",
    "# plt.ylabel('$D_\\ell$')\n",
    "# plt.xlabel('$\\ell$')\n",
    "# plt.grid()\n",
    "# plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aad54a2",
   "metadata": {},
   "source": [
    "## Global likelihood for each dust fraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36248415",
   "metadata": {},
   "outputs": [],
   "source": [
    "def myBBth(ell, r):\n",
    "    clBB = qc.get_Dl_fromlib(ell, r, lib=binned_camblib, unlensed=False, specindex=2)[0]\n",
    "    clBB = np.array(list(clBB) * ncombi)\n",
    "    return clBB\n",
    "\n",
    "\n",
    "# clBB = myBBth(ell_binned, r=0)\n",
    "# print(clBB.shape)\n",
    "# plt.plot(ell_binned, clBB[:nbins], color='r')\n",
    "# plt.title('CMB r = 0')\n",
    "# plt.ylabel('$D_\\ell$')\n",
    "# plt.xlabel('$\\ell$')\n",
    "# plt.grid()\n",
    "# plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aadef713",
   "metadata": {},
   "outputs": [],
   "source": [
    "xvals = list(ell_binned) * ncombi\n",
    "print(len(xvals))\n",
    "error = BBcov\n",
    "print(error.shape)\n",
    "\n",
    "x = np.linspace(0., 1, 10000)\n",
    "\n",
    "allLLH, allLLH_interp = [], []\n",
    "allr_dust = []\n",
    "allsigma68 = []\n",
    "for f, frac in enumerate(dust_fraction[:]):\n",
    "    print('\\n dust fraction:', frac)\n",
    "    fakedata = myBBth(ell_binned, r=0.) + np.ravel(BBcross_dust[f, :, :])\n",
    "#     plt.plot(np.ravel(BBcross_dust[f, :, :]), label=frac)\n",
    "#     plt.legend()\n",
    "    print(len(fakedata))\n",
    "\n",
    "    logLLH = mcmc.LogLikelihood(xvals=xvals, \n",
    "                              yvals=fakedata, \n",
    "                              errors=error,\n",
    "                              nbins=16,\n",
    "                              model=myBBth, \n",
    "                              flatprior=[[0,1]], \n",
    "                              covariance_model_funct=Namaster.knox_covariance)\n",
    "    logLLH([rvalues_b[10]])\n",
    "\n",
    "    LLH, sigma68 = logLLH.compute_sigma68(logLLH, rvalues)\n",
    "    allLLH.append(LLH)\n",
    "    print(sigma68)\n",
    "    allsigma68.append(sigma68)\n",
    "    \n",
    "    LLH_interp = np.interp(x, rvalues, LLH)\n",
    "    allLLH_interp.append(LLH_interp)\n",
    "    \n",
    "    r_dust = x[np.argmax(LLH_interp)]\n",
    "    print(r_dust)\n",
    "    allr_dust.append(r_dust)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a42aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax0, ax1) = plt.subplots(1, 2, figsize=(20, 6))\n",
    "fig.suptitle(config[-3:] + f' GHz - {nbands} bands')\n",
    "x = np.linspace(0., 1, 10000)\n",
    "for f, frac in enumerate(dust_fraction[:]):\n",
    "    c = palet[f]\n",
    "#     ax0.plot(rvalues, allLLH[f] / np.max(allLLH[f]), 'o', color=c, label=f'Likelihood frac {frac}')\n",
    "    ax0.plot(x, allLLH_interp[f]/ np.max(allLLH_interp[f]),\n",
    "                 color=c, label='{:1.1f} % dust residuals'.format(dust_fraction[f]*100))\n",
    "\n",
    "    ax0.axvline(x=allr_dust[f], color=c)\n",
    "    ax0.axvline(x=allsigma68[f], linestyle='--', color=c)\n",
    "\n",
    "ax0.legend(loc='best', fontsize=12)\n",
    "ax0.set_xlim(0, 1)\n",
    "ax0.set_xlabel('$r_{dust}$')\n",
    "ax0.set_ylabel('Posterior')\n",
    "\n",
    "\n",
    "\n",
    "for f, frac in enumerate(dust_fraction[:]):\n",
    "    c = palet[f]\n",
    "    ax1.errorbar(dust_fraction[f], allr_dust[f],\n",
    "             yerr=allsigma68[f] - allr_dust[f], \n",
    "             fmt='o', color=c)\n",
    "ax1.set_xlabel('$f_{dust}$')\n",
    "ax1.set_ylabel('$r_{dust}$')\n",
    "ax1.grid()\n",
    "\n",
    "# plt.savefig('/home/lmousset/QUBIC/Qubic_work/SpectroImagerie/paper_plot/'+\n",
    "#             f'Likelihood_dust_rdust_{config}_3y_{nbands}bands_GoodPhotonNoise_fdust0to0.05.pdf', \n",
    "#             bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec90842",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only the plot on the right \n",
    "fig = plt.figure(figsize=(8, 6))\n",
    "ax = plt.gca()\n",
    "plt.title(config[-3:] + f' GHz - {nbands} bands')\n",
    "\n",
    "for f, frac in enumerate(dust_fraction[:]):\n",
    "    c = palet[f]\n",
    "    ax.errorbar(dust_fraction[f], allr_dust[f],\n",
    "             yerr=allsigma68[f] - allr_dust[f], \n",
    "             fmt='o', color='r')\n",
    "ax.set_xlabel('$f_{dust}$')\n",
    "ax.set_ylabel('$r_{dust}$')\n",
    "ax.grid()\n",
    "\n",
    "# plt.savefig('/home/lmousset/QUBIC/Qubic_work/SpectroImagerie/paper_plot/'+\n",
    "#             f'Likelihood_dust_rdust_{config}_3y_{nbands}bands_rightplot_GoodPhotonNoise_fdust0to0.01.pdf', \n",
    "#             bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a43a717",
   "metadata": {},
   "source": [
    "## Likelihood of each IBCS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85694bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cut BBcov for each IBCS\n",
    "nIBCS = int(BBcov.shape[0] / nbins)\n",
    "BBcovsep = np.array([BBcov[i*nbins:(i+1)*nbins, i*nbins:(i+1)*nbins] for i in range(nIBCS)])\n",
    "print(BBcovsep.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6d4c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def myBBth_simple(ell, r):\n",
    "    clBB = qc.get_Dl_fromlib(ell, r, lib=binned_camblib, unlensed=False, specindex=2)[0]\n",
    "    return clBB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c695944",
   "metadata": {},
   "outputs": [],
   "source": [
    "xvals = list(ell_binned)\n",
    "print(len(xvals))\n",
    "\n",
    "nx = 1000\n",
    "x = np.linspace(0., 1, nx)\n",
    "\n",
    "LLH = np.zeros((len(dust_fraction), ncombi, rvalues.shape[0]))\n",
    "LLH_interp = np.zeros((len(dust_fraction), ncombi, nx))\n",
    "r_dust = np.zeros((len(dust_fraction), ncombi))\n",
    "sigma68 = np.zeros((len(dust_fraction), ncombi))\n",
    "\n",
    "for f, frac in enumerate(dust_fraction[:]):\n",
    "    print('\\n dust fraction:', frac)\n",
    "    # Loop over each IBCS\n",
    "    for i in range(ncombi):\n",
    "        error = BBcovsep[i, :, :]\n",
    "\n",
    "        fakedata = myBBth_simple(ell_binned, r=0.) + BBcross_dust[f, i, :]\n",
    "        print(len(fakedata))\n",
    "\n",
    "        logLLH = mcmc.LogLikelihood(xvals=xvals, \n",
    "                                  yvals=fakedata, \n",
    "                                  errors=error,\n",
    "                                  nbins=nbins,\n",
    "                                  model=myBBth_simple, \n",
    "                                  flatprior=[[0,1]], \n",
    "                                  covariance_model_funct=Namaster.knox_covariance)\n",
    "        logLLH([rvalues_b[10]])\n",
    "\n",
    "        LLH[f, i, :], sigma68[f, i] = logLLH.compute_sigma68(logLLH, rvalues)\n",
    "\n",
    "        LLH_interp[f, i, :] = np.interp(x, rvalues, LLH[f, i, :])\n",
    "        \n",
    "        r_dust[f, i] = x[np.argmax(LLH_interp[f, i, :])]\n",
    "        print(r_dust[f, i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb712642",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "\n",
    "\n",
    "x = np.linspace(0., 1, nx)\n",
    "for f, frac in enumerate(dust_fraction[:]):\n",
    "    print('\\n dust fraction:', frac)\n",
    "    c = palet[f]\n",
    "    for i in range(ncombi): \n",
    "        \n",
    "#         plt.plot(rvalues, LLH[f, i, :] / np.max(LLH[f, i, :]), \n",
    "#                  'o', color=c, label='frac = {} - nu = {:3.2f}, '.format(dust_fraction[f], nus_eff[i]))\n",
    "        plt.plot(x, LLH_interp[f, i, :]/ np.max(LLH_interp[f, i, :]), \n",
    "                 color=c,\n",
    "                 label='fdust = {} - nu = {:3.2f} - r_dust = {:1.4f}, '.format(dust_fraction[f], nus_eff[i], r_dust[f, i]))\n",
    "                 \n",
    "        plt.axvline(x=r_dust[f, i], linestyle='--', color=c, )\n",
    "\n",
    "plt.xlim(0, 1)\n",
    "plt.xlabel('r')\n",
    "plt.ylabel('Posterior')\n",
    "plt.grid()\n",
    "\n",
    "# plt.legend(loc='upper right', fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e759c703",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import curve_fit\n",
    "def func(x, a, b):\n",
    "    return a * x + b\n",
    "\n",
    "popt = np.zeros((len(dust_fraction[:]), 2))\n",
    "perr = np.zeros((len(dust_fraction[:]), 2))\n",
    "for f in range(len(dust_fraction[:])):\n",
    "    popt[f, :], pcov = curve_fit(func, nus_eff, r_dust[f, :], sigma=sigma68[f, :] - r_dust[f, :], absolute_sigma=True)\n",
    "    print(popt[f, :])\n",
    "    perr[f, :] = np.sqrt(np.diag(pcov))\n",
    "    print(perr[f, :])\n",
    "    \n",
    "significance_a = popt[:, 0] / perr[:, 0]  \n",
    "significance_b = popt[:, 1] / perr[:, 1]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb025a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = np.linspace(135, 165, 10)\n",
    "x = np.linspace(195, 245, 10)\n",
    "\n",
    "fig, (ax0, ax1) = plt.subplots(1, 2, figsize=(20, 6))\n",
    "fig.suptitle(config[-3:] + f' GHz - {nbands} bands')\n",
    "for f in range(len(dust_fraction[:])):\n",
    "    print(f)\n",
    "    c = palet[f]\n",
    "    ax0.errorbar(nus_eff[:], \n",
    "                 r_dust[f, :],\n",
    "                 yerr=sigma68[f, :]- r_dust[f, :], \n",
    "                 fmt='o',\n",
    "                 color=c, \n",
    "                 label='{:1.1f} % dust residuals'.format(dust_fraction[f]*100) )   \n",
    "\n",
    "    ax0.plot(x, np.polyval(popt[f, :], x),\n",
    "             color=c)\n",
    "ax0.set_xlabel(r'$\\nu$ [GHz]')\n",
    "ax0.set_ylabel(r'$r_{dust}$')\n",
    "ax0.legend(fontsize=12)\n",
    "ax0.grid()\n",
    "\n",
    "for f in range(1, 11):\n",
    "    c = palet[f]\n",
    "    ax1.plot(dust_fraction[f], significance_a[f], 'o', color=c)#, label='Linear fit: a = {:1.4f} $\\pm$ {:1.4f}'.\n",
    "#                  format(popt[f, 0], perr[f, 0]))\n",
    "ax1.set_xlabel(r'$f_{dust}$')\n",
    "ax1.set_ylabel('$a / \\sigma_a$')\n",
    "# ax1.legend(loc='best', fontsize=12)\n",
    "ax1.grid()\n",
    "ax1.set_xticks(np.arange(0., 0.011, 0.001))\n",
    "ax1.set_title('Slope significance')\n",
    "\n",
    "# plt.savefig('/home/lmousset/QUBIC/Qubic_work/SpectroImagerie/paper_plot/'\n",
    "#             +f'Likelihood_dust_rdustbyfreq_{config}_3y_{nbands}bands_GoodPhotonNoise_fdust0to0.05.pdf', \n",
    "#             bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ec26fe",
   "metadata": {},
   "source": [
    "## CMB with r not 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd0631e",
   "metadata": {},
   "outputs": [],
   "source": [
    "xvals = list(ell_binned)\n",
    "print(len(xvals))\n",
    "\n",
    "nx = 1000\n",
    "x = np.linspace(0., 1, nx)\n",
    "\n",
    "LLH_CMBwithr = np.zeros((ncombi, rvalues.shape[0]))\n",
    "LLH_interp_CMBwithr = np.zeros((ncombi, nx))\n",
    "r_dust_CMBwithr = np.zeros(ncombi)\n",
    "sigma68_CMBwithr = np.zeros(ncombi)\n",
    "\n",
    "index = 3\n",
    "print('Dust fraction:', dust_fraction[index])\n",
    "\n",
    "smallr = r_dust[index, nbands-1]\n",
    "print('smallr', smallr)\n",
    "\n",
    "# Loop over each IBCS\n",
    "for i in range(ncombi):\n",
    "    error = BBcovsep[i, :, :]\n",
    "\n",
    "    fakedata = myBBth_simple(ell_binned, r=smallr)\n",
    "    print(len(fakedata))\n",
    "\n",
    "    logLLH = mcmc.LogLikelihood(xvals=xvals, \n",
    "                              yvals=fakedata, \n",
    "                              errors=error,\n",
    "                              nbins=nbins,\n",
    "                              model=myBBth_simple, \n",
    "                              flatprior=[[0,1]], \n",
    "                              covariance_model_funct=Namaster.knox_covariance)\n",
    "    logLLH([rvalues_b[10]])\n",
    "\n",
    "    LLH_CMBwithr[i, :], sigma68_CMBwithr[i] = logLLH.compute_sigma68(logLLH, rvalues)\n",
    "\n",
    "    LLH_interp_CMBwithr[i, :] = np.interp(x, rvalues, LLH_CMBwithr[i, :])\n",
    "\n",
    "    r_dust_CMBwithr[i] = x[np.argmax(LLH_interp_CMBwithr[i, :])]\n",
    "    print(r_dust_CMBwithr[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab66b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "popt_CMBwithr, pcov = curve_fit(func, nus_eff, r_dust_CMBwithr, sigma=sigma68_CMBwithr - r_dust_CMBwithr,\n",
    "                                absolute_sigma=True)\n",
    "\n",
    "perr_CMBwithr = np.sqrt(np.diag(pcov))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83528257",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = np.linspace(130, 170, 10)\n",
    "x = np.linspace(195, 245, 10)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "plt.errorbar(nus_eff, \n",
    "             r_dust[index, :],\n",
    "             yerr=sigma68[index, :]- r_dust[index, :], \n",
    "             fmt='o',\n",
    "             color='b', \n",
    "             label=r'CMB$(r = 0)$' + ' + {:1.1f} % dust residuals'.format(dust_fraction[index]*100) + \n",
    "                     '\\nSlope significance: {:1.2f} $\\sigma$'.format(significance_a[index]))   \n",
    "\n",
    "plt.plot(x, np.polyval(popt[index, :], x),\n",
    "         color='b')\n",
    "\n",
    "plt.errorbar(np.array(nus_eff)+0.5, \n",
    "                 r_dust_CMBwithr,\n",
    "                 yerr=sigma68_CMBwithr- r_dust_CMBwithr, \n",
    "                 fmt='o',\n",
    "                 color='r', \n",
    "                 label='CMB$(r = {:1.2f})$'.format(smallr))  \n",
    "plt.plot(x, np.polyval(popt_CMBwithr, x), color='r')\n",
    "\n",
    "\n",
    "plt.xlabel(r'$\\nu$ [GHz]')\n",
    "plt.ylabel(r'$r_{dust}$')\n",
    "plt.legend(fontsize=14, loc='upper left')\n",
    "plt.grid()\n",
    "plt.title(config[-3:] + f' GHz - {nbands} bands')\n",
    "# plt.savefig('/home/lmousset/QUBIC/Qubic_work/SpectroImagerie/paper_plot/'+\n",
    "#             f'Likelihood_dust_CMBwithr_{config}_3y_{nbands}bands_GoodPhotonNoise_dust{dust_fraction[index]}.pdf', \n",
    "#             bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21876bfa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
