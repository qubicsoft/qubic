{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3507711a-fbe9-49fe-8d55-09b02f0f1939",
   "metadata": {},
   "source": [
    "# Moon Analysis 2024\n",
    "## JCH - Nov. 2024\n",
    "\n",
    "This notebook attemps to integrate the Moon analysis from previous Notebooks (`Analysis Moon 2024` and `Moon-FWHM-Offsets-2024`) into a single runable function in order to be able to update the calibration files with the measured focal plane rotation from `Moon-FWHM-Offsets-2024`. \n",
    "\n",
    "- `Analysis Moon 2024` is doing a minimal TOD treatment to be able to perform coadded maps of the Moon for each TES where one can see the Moon main peak, sometimes secondary peaks as well as the trees in fron t of the Salta Intergation hall door. This notebook produces files with Moon maps for each TES.\n",
    "- `Moon-FWHM-Offsets-2024` is reading those Moon maps for each TES and focuses on the main peak from the Moon. It then fits its location, amplitude and FWHM with a 2D Gaussian. Then, comparing the location of the main peak with those predicted from Maynooth's optical modeling, one calculates the average translation and rotation of the focal plane with respect to ideality. It finally shows a focal plane map of the Moon images that shows the Moon at the center of the image for all TES. In the cases where it is not right at the center, then we need to understand the reasons that could include wring labeling of some TES (w.r.t. wiring scheme) or undetected Moon.\n",
    "\n",
    "So the idea here is to be able to: \n",
    "- perform the analysis first with the ideal locations of the focal plane\n",
    "- calculate the updated corresponding calibration file\n",
    "- redo the analysis with the updated calibration file\n",
    "- check that the new translation / rotation is compatible with identity\n",
    "- the non satisfying TES will need to be studied in details.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba3282b-e67d-4c49-8cad-10a95ad53f6c",
   "metadata": {},
   "source": [
    "## Imports and notebook configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad6b710-7a26-423b-a78e-a5c387fa8c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config InlineBackend.figure_format='retina'\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))\n",
    "\n",
    "\n",
    "\n",
    "### General imports\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from importlib import reload\n",
    "from datetime import datetime\n",
    "from joblib import Parallel, delayed\n",
    "from multiprocessing import Manager, Lock\n",
    "from scipy.signal import medfilt\n",
    "from scipy.interpolate import interp1d\n",
    "import healpy as hp\n",
    "\n",
    "\n",
    "plt.rc('figure',figsize=(20,12))\n",
    "plt.rc('font',size=12)\n",
    "\n",
    "### Astropy configuration\n",
    "from astropy.visualization import astropy_mpl_style, quantity_support\n",
    "quantity_support()\n",
    "import astropy.units as u\n",
    "from astropy.time import Time\n",
    "from astropy.coordinates import SkyCoord, EarthLocation, AltAz, get_moon, get_sun\n",
    "\n",
    "\n",
    "\n",
    "#### QUBIC IMPORT\n",
    "from qubicpack.utilities import Qubic_DataDir\n",
    "from qubicpack.qubicfp import qubicfp\n",
    "from qubicpack.pix2tes import pix2tes, tes2pix\n",
    "\n",
    "from qubic.lib.Calibration import Qfiber\n",
    "from qubic.lib.Calibration import Qselfcal\n",
    "from qubic.lib.Qutilities import find_file, progress_bar\n",
    "from qubic.lib.QdataHandling import display_healpix_map, identify_scans\n",
    "from qubic.lib import Qdictionary \n",
    "from qubic.lib.Instrument import Qinstrument\n",
    "\n",
    "\n",
    "def iQS2iQP(indexQS):\n",
    "    qpnumi, qpasici = qp.pix2tes.pix2tes(indexQS+1)\n",
    "    return qpnumi+(qpasici-1)*128-1\n",
    "\n",
    "def iQP2iQS(indexQP):\n",
    "    QStesnum = qp.pix2tes.tes2pix(indexQP%128+1, indexQP//128+1)\n",
    "    return QStesnum-1\n",
    "\n",
    "d = Qdictionary.qubicDict()\n",
    "dictfilename = '/dicts/global_source_oneDet.dict'\n",
    "d.read_from_file(dictfilename)\n",
    "q = Qinstrument.QubicInstrument(d)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c73ed166-f4b3-4f69-ae1b-3b21bc0a59ed",
   "metadata": {},
   "source": [
    "### Temporary update of the path \n",
    "in order to be able to load libraries that are still in development and not yet in the QUBIC path. This will have to be removed when the relevant libraries are finalized and integrated into QubicSoft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79fb2181-c183-4c1c-9ad2-b418e10cd733",
   "metadata": {},
   "outputs": [],
   "source": [
    "dirtemplibs = [os.environ['QUBIC_DATADIR']+'scripts/DiversJC/CalibSalta/']\n",
    "for rep in dirtemplibs:     \n",
    "    if rep not in sys.path:\n",
    "        sys.path.append(rep)\n",
    "\n",
    "#### Local files that will need to be installed in the Qubic Libs\n",
    "import fitting as fit\n",
    "import time_domain_tools as tdt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa3a1f1a-c5fe-4b0a-8019-627ad4692928",
   "metadata": {},
   "source": [
    "## A number of functions that will be used throughout this notebook\n",
    "They should be ultimately well commented and integrated into actual libraries in QubicSoft of course."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c3d6ef-3fbc-4b40-a048-7333d5a5fa1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def healpix_map(azt, elt, tod, flags=None, flaglimit=0, nside=128, countcut=0, unseen_val=hp.UNSEEN):\n",
    "    if flags is None:\n",
    "        flags = np.zeros(len(azt))\n",
    "    \n",
    "    ok = flags <= flaglimit \n",
    "    return healpix_map_(azt[ok], elt[ok], tod[ok], nside=nside, countcut=countcut, unseen_val=unseen_val)\n",
    "\n",
    "\n",
    "def healpix_map_(azt, elt, tod, nside=128, countcut=0, unseen_val=hp.UNSEEN):\n",
    "    ips = hp.ang2pix(nside, azt, elt, lonlat=True)\n",
    "    mymap = np.zeros(12*nside**2)\n",
    "    mapcount = np.zeros(12*nside**2)\n",
    "    for i in range(len(azt)):\n",
    "        mymap[ips[i]] += tod[i]\n",
    "        mapcount[ips[i]] += 1\n",
    "    unseen = mapcount <= countcut\n",
    "    mymap[unseen] = unseen_val\n",
    "    mapcount[unseen] = unseen_val\n",
    "    mymap[~unseen] = mymap[~unseen] / mapcount[~unseen]\n",
    "    return mymap, mapcount\n",
    "\n",
    "def display_one(mapsb, anatype='', sub=(1,1,1), nlo=3, nhi=3, reso=12, rot=[0,50]):\n",
    "    unseen = (mapsb == hp.UNSEEN)\n",
    "    mm, ss = Qfiber.meancut(mapsb[~unseen], 3)\n",
    "    hp.gnomview(mapsb, rot=rot, reso=reso, sub=sub, title=anatype+'\\n Both scans $\\sigma$ = {0:5.3g}'.format(ss), min=-nlo*ss, max=nhi*ss)\n",
    "\n",
    "\n",
    "def do_display_all(mapsb, mapsb_pos, mapsb_neg, mapav, mapdiff, mapdiff2, rot=[0,50], anatype='', reso=12, myrange=None, TESNum = None):\n",
    "    unseen = (mapsb == hp.UNSEEN) | (mapsb_pos == hp.UNSEEN) | (mapsb_neg == hp.UNSEEN)\n",
    "    mm, ss = Qfiber.meancut(mapsb[~unseen], 3)\n",
    "    \n",
    "    if myrange is None:\n",
    "        mini = -3*ss\n",
    "        maxi = 3*ss\n",
    "    else:\n",
    "        mini = myrange[0]\n",
    "        maxi = myrange[1]\n",
    "        \n",
    "    if TESNum != None:\n",
    "        anatype += '\\n TES# {}'.format(TESNum)\n",
    "\n",
    "    plt.figure()\n",
    "    hp.gnomview(mapsb, rot=rot, reso=reso, sub=(2,3,1), title=anatype+'\\n Both scans $\\sigma$ = {0:5.4g}'.format(ss), min=mini, max=maxi)\n",
    "    mmp, ssp = Qfiber.meancut(mapsb_pos[~unseen], 3)\n",
    "    hp.gnomview(mapsb_pos, rot=rot, reso=reso, sub=(2,3,2), title=anatype+'\\n Pos scans $\\sigma$ = {0:5.4g}'.format(ssp), min=mini, max=maxi)\n",
    "    mmn, ssn = Qfiber.meancut(mapsb_neg[~unseen], 3)\n",
    "    hp.gnomview(mapsb_neg, rot=rot, reso=reso, sub=(2,3,3), title=anatype+'\\n Neg scans $\\sigma$ = {0:5.4g}'.format(ssn), min=mini, max=maxi)\n",
    "    mma, ssa = Qfiber.meancut(mapav[~unseen], 3)\n",
    "    hp.gnomview(mapav, rot=rot, reso=reso, sub=(2,3,4), title=anatype+'\\n Av of Both scans $\\sigma$ = {0:5.4g}'.format(ssa), min=mini, max=maxi)\n",
    "    mmd, ssd = Qfiber.meancut(mapdiff[~unseen], 3)\n",
    "    hp.gnomview(mapdiff, rot=rot, reso=reso, sub=(2,3,5), title=anatype+'\\n Diff of both scans $\\sigma$ = {0:5.4g}'.format(ssd), min=mini/ss*ssd, max=maxi/ss*ssd)\n",
    "    mmd2, ssd2 = Qfiber.meancut(mapdiff2[~unseen], 3)\n",
    "    hp.gnomview(mapdiff2, rot=rot, reso=reso, sub=(2,3,6), title=anatype+'\\n Both - Av $\\sigma$ = {0:5.4g}'.format(ssd2), min=mini/ss**ssd, max=maxi/ss*ssd)\n",
    "    \n",
    "\n",
    "def display_all(mapsb, mapsb_pos, mapsb_neg, anatype='', rot=[0,50], highcontrast=False, reso=12, myrange=None, TESNum=None):\n",
    "    unseen = (mapsb == hp.UNSEEN) | (mapsb_pos == hp.UNSEEN) | (mapsb_neg == hp.UNSEEN)\n",
    "\n",
    "    ### Average of back and Forth\n",
    "    mapav = (mapsb_pos + mapsb_neg)/2\n",
    "    mapav[unseen] = hp.UNSEEN\n",
    "\n",
    "    ### Difference of back and Forth\n",
    "    mapdiff = (mapsb_pos - mapsb_neg)\n",
    "    mapdiff[unseen] = hp.UNSEEN\n",
    "\n",
    "    ### Difference of All and Av\n",
    "    mapdiff2 = (mapav - mapsb)\n",
    "    mapdiff2[unseen] = hp.UNSEEN\n",
    "    \n",
    "    if highcontrast:\n",
    "        myrange = [-np.max(mapsb[~unseen])/10, np.max(mapsb[~unseen])*0.8]\n",
    "        \n",
    "    do_display_all(mapsb, mapsb_pos, mapsb_neg, mapav, mapdiff, mapdiff2, rot=rot, anatype=anatype, reso=reso, myrange=myrange, TESNum=TESNum)\n",
    "    \n",
    "def remove_offset_scan(mytod, scantype, method='meancut', apply_to_bad = True):\n",
    "    ### We remove offsets for each good scan but we also need to remove a coomparable offset for the scantype==0 reggiions in order to keep coninuity \n",
    "    ### This si donee by apply_to_bad=True\n",
    "    \n",
    "    indices = np.arange(len(mytod))\n",
    "    last_index = 0\n",
    "    myoffsetn = 0\n",
    "    myoffsetp = 0\n",
    "    donefirst = 0\n",
    "    \n",
    "    nscans = np.max(np.abs(scantype))\n",
    "    for n in range(1, nscans+1):\n",
    "        # scan +\n",
    "        ok = scantype == n\n",
    "        if method == 'meancut':\n",
    "            myoffsetp, _ = Qfiber.meancut(mytod[ok], 3)\n",
    "        elif method == 'median':\n",
    "            myoffsetp = np.median(mytod[ok])\n",
    "        elif method == 'mode':\n",
    "            myoffsetp = tdt.get_mode(mytod[ok])\n",
    "        else:\n",
    "            break\n",
    "        mytod[ok] -= myoffsetp        \n",
    "        if apply_to_bad:\n",
    "            first_index = np.min(indices[ok])\n",
    "            if (n==1) & (donefirst==0): myoffsetn = myoffsetp ### deal with first region\n",
    "            vals_offsets = myoffsetn + np.linspace(0,1, first_index-last_index-1)*(myoffsetp-myoffsetn)\n",
    "            mytod[last_index+1:first_index] -= vals_offsets\n",
    "            last_index = np.max(indices[ok])\n",
    "            donefirst = 1\n",
    "        \n",
    "        \n",
    "        # scan -\n",
    "        ok = scantype == (-n)\n",
    "        if method == 'meancut':\n",
    "            myoffsetn, _ = Qfiber.meancut(mytod[ok], 3)\n",
    "        elif method == 'median':\n",
    "            myoffsetn = np.median(mytod[ok])\n",
    "        elif method == 'mode':\n",
    "            myoffsetn = tdt.get_mode(mytod[ok])\n",
    "        else:\n",
    "            break\n",
    "        mytod[ok] -= myoffsetn\n",
    "        if apply_to_bad:\n",
    "            first_index = np.min(indices[ok])\n",
    "            if (n==1) & (donefirst==0): myoffsetp = myoffsetn ### deal with first region\n",
    "            vals_offsets = myoffsetp + np.linspace(0,1, first_index-last_index-1)*(myoffsetn-myoffsetp)\n",
    "            mytod[last_index+1:first_index] -= vals_offsets\n",
    "            last_index = np.max(indices[ok])\n",
    "            donefirst = 1\n",
    "    \n",
    "    return mytod\n",
    "\n",
    "\n",
    "def decorel_azimuth(mytod, azt, scantype, degree=2, doplot=True):\n",
    "    ### Profiling in Azimuth\n",
    "    okall = np.abs(scantype) > 0 \n",
    "    okpos = scantype > 0 \n",
    "    okneg = scantype < 0 \n",
    "    oks = [okpos, okneg]\n",
    "    oks_names = ['+ scans', '- scans']\n",
    "    polys = []\n",
    "    if doplot:\n",
    "        figure()\n",
    "    for i in range(len(oks)):\n",
    "        ok = oks[i]\n",
    "        minaz = np.min(azt[ok])\n",
    "        maxaz = np.max(azt[ok])\n",
    "        xc, yc, dx, dy, _ = Qfiber.profile(azt[ok], mytod[ok], rng=[minaz, maxaz], nbins=25, mode=True, dispersion=True, plot=False)\n",
    "        z = polyfit(xc, yc, degree, w=1./dy)\n",
    "        p = np.poly1d(z)\n",
    "        polys.append(p)\n",
    "        xaz = np.linspace(minaz, maxaz, 100)\n",
    "        if doplot:\n",
    "            pl = errorbar(xc, yc, yerr=dy, xerr=dx, fmt='o')\n",
    "            plot(xaz, p(xaz), label=oks_names[i], color=pl[0].get_color())\n",
    "    if doplot:\n",
    "        xlabel('Azimuth [deg]')\n",
    "        ylabel('Mode of TOD')\n",
    "        legend()\n",
    "\n",
    "    ### Removing the azimuthal effect\n",
    "    ok = scantype >= 0\n",
    "    mytod[ok] -= polys[0](azt[ok])\n",
    "    ok = scantype < 0\n",
    "    mytod[ok] -= polys[1](azt[ok])\n",
    "    \n",
    "    return mytod\n",
    "\n",
    "def get_chunks(mytod, scantype, value):\n",
    "    ### returns chunks corresponding to a given value\n",
    "    current_chunk = []\n",
    "    chunk_idx = []\n",
    "    inchunk = 0\n",
    "    chunknum = 0\n",
    "    for i in range(len(scantype)):\n",
    "        if scantype[i]==value:\n",
    "            inchunk = 1\n",
    "            current_chunk.append(i)\n",
    "        else:\n",
    "            if inchunk == 1:\n",
    "                chunknum += 1\n",
    "                chunk_idx.append([current_chunk[0], current_chunk[len(current_chunk)-1]])\n",
    "                current_chunk = []\n",
    "                inchunk = 0\n",
    "    if inchunk == 1:\n",
    "        chunk_idx.append([current_chunk[0], current_chunk[len(current_chunk)-1]])\n",
    "    return chunk_idx\n",
    "\n",
    "\n",
    "def linear_rescale_chunks(mytod, chunks, sz=1000):\n",
    "    for i in range(len(chunks)):\n",
    "        thechunk = chunks[i]\n",
    "        chunklen = thechunk[1] - thechunk[0]+1\n",
    "        if thechunk[0] == 0:\n",
    "            # this is the starting index => just the average\n",
    "            vals = np.zeros(chunklen) + np.median(mytod[thechunk[1]+1: thechunk[1]+sz]) + np.median(mytod[thechunk[0]:thechunk[1]])\n",
    "            mytod[thechunk[0]:thechunk[1]+1] -= vals\n",
    "        elif thechunk[1]==(len(mytod)-1):\n",
    "            # this is the last one => just the average\n",
    "            vals = np.zeros(chunklen) + np.median(mytod[thechunk[0]-1-sz: thechunk[0]-1]) + np.median(mytod[thechunk[0]:thechunk[1]])\n",
    "            mytod[thechunk[0]:thechunk[1]+1] -= vals\n",
    "        else:\n",
    "            left = np.median(mytod[thechunk[0]-1-sz: thechunk[0]-1])\n",
    "            right = np.median(mytod[thechunk[1]+1: thechunk[1]+sz])\n",
    "            vals = left + np.linspace(0,1, chunklen)*(right-left)\n",
    "            mytod[thechunk[0]:thechunk[1]+1] -= np.median(mytod[thechunk[0]:thechunk[1]+1]) - vals\n",
    "            \n",
    "    return mytod\n",
    "\n",
    "def decorel_azel(mytod, azt, elt, scantype, doplot=True, nbins=50, n_el=20, degree=None, nbspl=10):\n",
    "    ### Profiling in Azimuth and elevation\n",
    "    el_lims = np.linspace(np.min(elt)-0.0001, np.max(elt)+0.0001, n_el+1)\n",
    "    el_av = 0.5 * (el_lims[1:] + el_lims[:-1])\n",
    "\n",
    "    okall = np.abs(scantype) > 0 \n",
    "    okpos = scantype > 0 \n",
    "    okneg = scantype < 0 \n",
    "    oks = [okpos, okneg]\n",
    "    oks_names = ['+ scans', '- scans']\n",
    "    minaz = np.min(azt[okall])\n",
    "    maxaz = np.max(azt[okall])\n",
    "    xaz = np.linspace(minaz, maxaz, 100)\n",
    "    \n",
    "    ### Use polynomials or spline fitting to remove drifts and large features\n",
    "    if degree != None:\n",
    "        coefficients = np.zeros((2, n_el, degree+1))\n",
    "    else:\n",
    "        coefficients = np.zeros((2, n_el, nbspl))\n",
    "\n",
    "    if doplot: \n",
    "        plt.figure()\n",
    "    for i in range(len(oks)):\n",
    "        if doplot: \n",
    "            plt.subplot(1,2,i+1)\n",
    "            plt.xlabel('Az')\n",
    "            plt.ylabel('TOD')\n",
    "            plt.title(oks_names[i])\n",
    "        for j in range(n_el):\n",
    "            ok = oks[i] & (elt >= el_lims[j]) & (elt < el_lims[j+1])\n",
    "            if np.sum(ok)==0:\n",
    "                break\n",
    "            xc, yc, dx, dy, _ = Qfiber.profile(azt[ok], mytod[ok], rng=[minaz, maxaz], nbins=nbins, mode=True, dispersion=True, plot=False)\n",
    "\n",
    "            if degree != None:\n",
    "                ### Polynomial Fitting\n",
    "                z = polyfit(xc, yc, degree, w=1./dy)\n",
    "                coefficients[i,j,:] = z\n",
    "                p = np.poly1d(z)\n",
    "                fitted = p(xaz)\n",
    "            else:\n",
    "                ### Spline Fitting\n",
    "                splfit = tdt.MySplineFitting(xc, yc, dy, nbspl)\n",
    "                coefficients[i,j,:] = splfit.alpha\n",
    "                fitted = splfit(xaz)\n",
    "            if doplot:\n",
    "                pl = plt.errorbar(xc, yc, yerr=dy, xerr=dx, fmt='o')\n",
    "                plt.plot(xaz, fitted, color=pl[0].get_color(), label = oks_names[i] + ' - El = {0:5.1f}'.format(np.mean(elt[ok])))\n",
    "    #if doplot: legend()\n",
    "\n",
    "    ### Now interpolate this to remove it to the data\n",
    "    nscans = np.max(np.abs(scantype))\n",
    "    for i in range(1, nscans+1):\n",
    "        okp = scantype == i\n",
    "        okn = scantype == (-i)\n",
    "        for ok in [okp, okn]:\n",
    "            the_el = np.median(elt[ok])\n",
    "            if degree != None:\n",
    "                myp = np.poly1d([np.interp(the_el, el_av, coefficients[0,:,i]) for i in np.arange(degree+1)])\n",
    "                mytod[ok] -= myp(azt[ok])\n",
    "            else:\n",
    "                myalpha = [np.interp(the_el, el_av, coefficients[0,:,i]) for i in np.arange(nbspl)]\n",
    "                mytod[ok] -= splfit.with_alpha(azt[ok], myalpha)\n",
    "                    \n",
    "                    \n",
    "    ### And interpolate for scantype==0 regions\n",
    "    bad_chunks = get_chunks(mytod, scantype, 0)\n",
    "    mytod = linear_rescale_chunks(mytod, bad_chunks, sz=100)\n",
    "    return mytod"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78dea8e8-3a91-46ba-849e-145a88930ea5",
   "metadata": {},
   "source": [
    "## Dataset and Observing site\n",
    "in the case of the July 2022 Moon observations, they were from Salta CNEA Regional and the UTC offset was -3 hours."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "426ffa6f-ce22-4c91-bb7f-45890d4f354e",
   "metadata": {},
   "source": [
    "### Location of the raw TOD files\n",
    "Beware this will have to be changed for each one's configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d5a805-b453-4e65-bc4c-326a0a249abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "mydatadir = '/Users/hamilton/Qubic/Data/CommissioningTD/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc48d8a-b3d8-4d55-829e-95d6c4b1fcf1",
   "metadata": {},
   "source": [
    "### Observation date and corresponding file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "726dca13-4fc1-457c-ac84-f7a918edfdcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ObsDate = '2022-07-14'\n",
    "ObsSession = 0\n",
    "dirs = glob.glob(mydatadir + '/' + ObsDate + '/*')\n",
    "print(dirs)\n",
    "datadir = dirs[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4184ec64-ad92-4c3a-ba5b-2e24081ac012",
   "metadata": {},
   "source": [
    "### Observing Site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb5142e-d43d-436c-b6e5-1abe7964240b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Salta_CNEA = {'lat':-24.731358*u.deg,\n",
    "              'lon':-65.409535*u.deg,\n",
    "              'height':1152*u.m,\n",
    "              'UTC_Offset':-3*u.hour}\n",
    "Obs_Site = Salta_CNEA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6212b290-4e58-4e7e-b436-57d2d44ee08d",
   "metadata": {},
   "source": [
    "## Now the big loop on the TESs to make coadded images of the Moon data.\n",
    "Here we make coadded maps in a \"local\" coordinate system that follows the Azimuth and Elevation of the Moon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3907cdf-2fc7-4bb9-bc6a-6022cdf316a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(datadir, remove_t0=True):\n",
    "    \"\"\"\n",
    "    Reads QUBIC raw data: time and TOD, as well azimuth, elevation and \n",
    "    their corresponding time\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    datadir : string\n",
    "        Full path of the directory where the raw data is stored\n",
    "        ex/ '/Volumes/QubicData/Calibration/2022-07-14/\n",
    "    remove_t0 : bool\n",
    "        subtracts the time of the first sample to the time vector, by default True.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tt : time for TOD\n",
    "    tod : the TODs for all detectors\n",
    "    thk : time for housekeeping data\n",
    "    az : azimuth of the mount\n",
    "    el : elevation of the mount\n",
    "    \"\"\"\n",
    "    \n",
    "    a = qubicfp()\n",
    "    a.read_qubicstudio_dataset(datadir)\n",
    "    tt, alltod = a.tod()\n",
    "    az = a.azimuth()\n",
    "    el = a.elevation()\n",
    "    thk = a.timeaxis(datatype='hk')\n",
    "    if remove_t0:\n",
    "        ### We remove tt[0]\n",
    "        tinit = tt[0]\n",
    "        tt -= tinit\n",
    "        thk -= tinit\n",
    "    del(a)\n",
    "    return tt, alltod, thk, az, el, tinit\n",
    "\n",
    "def get_azel_moon(ObsSite, tt, tinit, doplot=True):\n",
    "    MySite = EarthLocation(lat=ObsSite['lat'], lon=ObsSite['lon'], height=ObsSite['height'])\n",
    "    utcoffset =ObsSite['UTC_Offset']\n",
    "\n",
    "    dt0 = datetime.utcfromtimestamp(int((tt+tinit)[0]))\n",
    "    print(dt0)\n",
    "\n",
    "    nbtime = 100\n",
    "    tt_hours_loc = tt/3600\n",
    "    delta_time = np.linspace(np.min(tt_hours_loc), np.max(tt_hours_loc), nbtime)*u.hour\n",
    "\n",
    "    alltimes = Time(dt0) + delta_time\n",
    "\n",
    "    ### Local coordinates\n",
    "    frame_Site = AltAz(obstime=alltimes, location=MySite)\n",
    "\n",
    "    ### Source\n",
    "    moon_Site = get_moon(alltimes)\n",
    "    moonaltazs_Site = moon_Site.transform_to(frame_Site)  \n",
    "\n",
    "    myazmoon = moonaltazs_Site.az.value\n",
    "    myelmoon = moonaltazs_Site.alt.value\n",
    "\n",
    "    azmoon = np.interp(tt_hours_loc, delta_time/u.hour, myazmoon)\n",
    "    elmoon = np.interp(tt_hours_loc, delta_time/u.hour, myelmoon)\n",
    "    if doplot:\n",
    "        plt.figure()\n",
    "        plt.plot(myazmoon, myelmoon, 'ro')\n",
    "        plt.plot(azmoon, elmoon)    \n",
    "    return azmoon, elmoon\n",
    "\n",
    "\n",
    "def make_coadded_maps(datadir, ObsSite, allTESNum, data=None, speedmin=0.05, \n",
    "                      doplot=True, nside=256, az_qubic=0, parallel=False):\n",
    "    ### First read the data from disk if needed\n",
    "    if data is None:\n",
    "        print('Reading data from disk: '+datadir)\n",
    "        tt, alltod, thk, az, el, tinit = read_data(datadir, remove_t0=True)\n",
    "        az += az_qubic\n",
    "        data = [tt, alltod, thk, az, el, tinit]\n",
    "    else:\n",
    "        print('Using data already stored in memory - not read from disk')\n",
    "        tt, alltod, thk, az, el, tinit = data\n",
    "\n",
    "    ### Azimuth and Elevation of the Moon at the same timestamps from the observing site\n",
    "    azmoon, elmoon = get_azel_moon(ObsSite, tt, tinit, doplot=doplot)\n",
    "    \n",
    "    ### Identify scan types and numbers\n",
    "    scantype_hk, azt, elt, scantype, vmean = identify_scans(thk, az, el, \n",
    "                                                                tt=tt, doplot=doplot, \n",
    "                                                                plotrange=[0,2000], \n",
    "                                                                thr_speedmin=speedmin)\n",
    "\n",
    "    ### Loop over TES to do the maps\n",
    "    print('\\nLooping coaddition mapmaking over selected TES')\n",
    "    print('nside = ',nside)\n",
    "    start_time = time.perf_counter()\n",
    "    if parallel is False:\n",
    "        print('Using sequential loop')\n",
    "        allmaps = np.zeros((len(allTESNum), 12*nside**2))\n",
    "        for i in range(len(allTESNum)):\n",
    "            TESNum = allTESNum[i]\n",
    "            print('TES# {}'.format(TESNum), end=\" \")\n",
    "            tod = alltod[TESNum-1,:]\n",
    "            allmaps[i,:], mapscounts = make_coadded_maps_TES(tt, tod, azt, elt, scantype, azmoon, elmoon,\n",
    "                                                             nside=nside, \n",
    "                                                             doplot=doplot, tesnum=TESNum)\n",
    "            print('OK', flush=True)\n",
    "    else:\n",
    "        print('using a parallel loop : no output will be given while processing... be patient...')\n",
    "        ### Note that this code has been generated using ChatGPT\n",
    "        def process_TES(i, TESNum, allmaps, alltod, tt, azt, elt, scantype, azmoon, elmoon, nside, doplot):\n",
    "            # Create a lock for each process to ensure safe access to shared memory\n",
    "            lock = Lock()\n",
    "            \n",
    "            tod = alltod[TESNum - 1, :]\n",
    "            map_result, mapscounts = make_coadded_maps_TES(tt, tod, azt, elt, scantype, azmoon, elmoon,\n",
    "                                                           nside=nside, \n",
    "                                                           doplot=doplot, tesnum=TESNum)\n",
    "        \n",
    "            # Use lock to ensure safe access to shared memory inside the inner function\n",
    "            with lock:\n",
    "                # Directly assign the result to the correct index in allmaps\n",
    "                # allmaps is a list of numpy arrays, so we can use allmaps[i] directly\n",
    "                allmaps[i] = map_result\n",
    "        \n",
    "        def parallel_coadded_maps(allTESNum, alltod, tt, azt, elt, scantype, azmoon, elmoon, nside, doplot):\n",
    "            # Use Manager to create a shared list that will be modified by parallel processes\n",
    "            with Manager() as manager:\n",
    "                # Create a list of NumPy arrays initialized to zeros\n",
    "                allmaps = manager.list([np.zeros(12 * nside ** 2) for _ in range(len(allTESNum))])\n",
    "        \n",
    "                # Run the parallel processing with the correct arguments\n",
    "                Parallel(n_jobs=-1)(delayed(process_TES)(i, allTESNum[i], allmaps, alltod, tt, azt, elt, scantype, azmoon, elmoon, nside, doplot)\n",
    "                                    for i in range(len(allTESNum)))\n",
    "        \n",
    "                # Convert the manager list back to a NumPy array (this ensures allmaps is a numpy array of arrays)\n",
    "                allmaps_np = np.array([np.array(allmaps[i]) for i in range(len(allTESNum))])\n",
    "        \n",
    "            return allmaps_np\n",
    "\n",
    "        allmaps = parallel_coadded_maps(allTESNum, alltod, tt, azt, elt, \n",
    "                                        scantype, azmoon, elmoon, nside, doplot)\n",
    "    \n",
    "    end_time = time.perf_counter()\n",
    "\n",
    "    elapsed_time = end_time - start_time\n",
    "    print(f\"Elapsed time: {elapsed_time:.4f} seconds => average of {(elapsed_time/len(allTESNum)):.4f} per TES\")    \n",
    "        \n",
    "\n",
    "    # Get central Az and El from pointing\n",
    "    newazt = (azt - azmoon) * np.cos(np.radians(elt))\n",
    "    newelt = -(elt - elmoon)\n",
    "    center=[np.mean(newazt), np.mean(newelt)]\n",
    "    return allmaps, data, center\n",
    "\n",
    "def make_coadded_maps_TES(tt, tod, azt, elt, scantype, azmoon, elmoon, nside=256, doplot=True, tesnum=None):\n",
    "    ###### Pipeline:\n",
    "    # 1. Remove a slow spline to the data\n",
    "    tod = tdt.remove_drifts_spline(tt, tod, nsplines=20, doplot=doplot)\n",
    "\n",
    "    # 2. Offset removal scan by scan using median \n",
    "    #    (here we just want to have all scans at the same level before \n",
    "    #    decorrelating from azimuth)\n",
    "    mytod = -tod.copy()\n",
    "    mytod = remove_offset_scan(mytod, scantype, method='median')\n",
    "\n",
    "    # 3. Remove azimuth correlation\n",
    "    # 3.c : splines\n",
    "    mytod = decorel_azel(mytod, azt, elt, scantype, doplot=doplot, nbins=50, n_el=50, nbspl=5)\n",
    "\n",
    "    # 4. remove offsets again but this time with mode method as it appears to be less affected \n",
    "    #    by the presence of the peaks (no underestimation of the offset resultingg is shadow around the peaks)\n",
    "    mytod = remove_offset_scan(mytod, scantype, method='mode')\n",
    "\n",
    "    # Map-making\n",
    "    newazt = (azt - azmoon) * np.cos(np.radians(elt))\n",
    "    newelt = -(elt - elmoon)\n",
    "\n",
    "    # Calculate center of maps from pointing w.r.t. Moon\n",
    "    center=[np.mean(newazt), np.mean(newelt)]\n",
    "    \n",
    "    mapsb, mapcount = healpix_map(newazt[scantype != 0], newelt[scantype != 0], mytod[scantype != 0], nside=nside)\n",
    "    \n",
    "    return mapsb, mapcount\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e8b4d5-135e-47f1-b152-6193135099ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(tdt)\n",
    "nside = 340\n",
    "azqubic = 116.4\n",
    "\n",
    "### Check if the data has already been read from disk or not\n",
    "try:\n",
    "    data\n",
    "except NameError:\n",
    "    data = None\n",
    "    \n",
    "\n",
    "allTESNum = [152]\n",
    "allmaps, data, center = make_coadded_maps(datadir, Obs_Site, allTESNum, data=data, \n",
    "                                       nside=nside, doplot=True, az_qubic=azqubic, parallel=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b1e54d-c07a-4190-ad4b-980c8e580241",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rc('figure',figsize=(20,20))\n",
    "plt.rc('font',size=12)\n",
    "n0 = 2\n",
    "for i in range(len(allTESNum)):\n",
    "    ok = allmaps[i,:] != hp.UNSEEN\n",
    "    if (i%(n0**2))==0: \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        plt.figure()\n",
    "    mm = np.zeros(12*nside**2)+ hp.UNSEEN\n",
    "    mm[ok] = allmaps[i,ok]-tdt.get_mode(allmaps[i,ok])\n",
    "    mm[~ok] = hp.UNSEEN\n",
    "    hp.gnomview(mm, reso=10, sub=(n0,n0,(i%(n0**2))+1), min=-5e3, max=1.2e4, \n",
    "                title=allTESNum[i], rot=center)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f674f34-5cfa-42d4-ba48-52ff4ae91c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(tdt)\n",
    "nside = 340\n",
    "azqubic = 116.4\n",
    "\n",
    "### Check if the data has already been read from disk or not\n",
    "try:\n",
    "    data\n",
    "except NameError:\n",
    "    data = None\n",
    "    \n",
    "\n",
    "# allTESNum = [22, 26, 27, 28, 49, 50, 51, 52]\n",
    "allTESNum = np.arange(256)+1\n",
    "allmaps, data, center = make_coadded_maps(datadir, Obs_Site, allTESNum, data=data, \n",
    "                                       nside=nside, doplot=False, az_qubic=azqubic, parallel=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599ba3c2-a410-4cff-9a1a-5f25a2becc5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.rc('figure',figsize=(20,20))\n",
    "plt.rc('font',size=12)\n",
    "n0 = 8\n",
    "for i in range(len(allTESNum)):\n",
    "    ok = allmaps[i,:] != hp.UNSEEN\n",
    "    if (i%(n0**2))==0: \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        plt.figure()\n",
    "    mm = np.zeros(12*nside**2)+ hp.UNSEEN\n",
    "    mm[ok] = allmaps[i,ok]-tdt.get_mode(allmaps[i,ok])\n",
    "    mm[~ok] = hp.UNSEEN\n",
    "    hp.gnomview(mm, reso=10, sub=(n0,n0,(i%(n0**2))+1), min=-5e3, max=2.5e4, \n",
    "                title=allTESNum[i], rot=center)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1696028-e0b7-48da-a303-99f482dca49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_healpix_map(allmaps, center, q, reso=10, min=-5e3, max=2.5e4, savepdf='allmoons_2024.pdf')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b222309-f47c-4285-afed-17ff6528edc7",
   "metadata": {},
   "source": [
    "### We save the maps into a pickle file for subesquent usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14acc632-cf80-4fdb-b37a-be67517cadee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump( [allTESNum, allmaps], open( \"NEW2024-allmaps-July14-2022.pkl\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aadaff1a-59be-4e19-ad32-d05cfdac7775",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1633f4dc-2c21-4adc-8513-d5a46474991d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "19919284-010f-49b8-a453-cfdd81810109",
   "metadata": {},
   "source": [
    "## Now apply Az/El calibration (from Moon-FWHM-Offsets.ipynb)\n",
    "The point here is to have each TES directly pointing in the right direction.\n",
    "\n",
    "What we have done here:\n",
    "\n",
    "add azqubic=116.4 to the raw file azimuth\n",
    "work in Moon coordinates:\n",
    "    newazt = (azt - azmoon) * np.cos(np.radians(elt))\n",
    "    newelt = -(elt - elmoon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e341d5-6f92-421f-b761-6d54d977ffb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotate_translate_scale_2d(xin, theta, center, scale):\n",
    "    rotmat = np.array([[np.cos(theta), -np.sin(theta)],[np.sin(theta), np.cos(theta)]])\n",
    "    return scale * np.dot(rotmat, (xin-center).T).T\n",
    "\n",
    "def rot_trans_scale_pts(x, pars):\n",
    "    pts = np.reshape(x, (len(x)//2, 2))\n",
    "    return np.ravel(rotate_translate_scale_2d(pts, np.radians(pars[0]), np.array([pars[1],pars[2]]), pars[3]))\n",
    "\n",
    "def make_coadded_maps_TES(tt, tod, azt, elt, scantype, azmoon, elmoon, nside=256, doplot=True, tesnum=None):\n",
    "    ###### Pipeline:\n",
    "    # 1. Remove a slow spline to the data\n",
    "    tod = tdt.remove_drifts_spline(tt, tod, nsplines=20, doplot=doplot)\n",
    "\n",
    "    # 2. Offset removal scan by scan using median \n",
    "    #    (here we just want to have all scans at the same level before \n",
    "    #    decorrelating from azimuth)\n",
    "    mytod = -tod.copy()\n",
    "    mytod = remove_offset_scan(mytod, scantype, method='median')\n",
    "\n",
    "    # 3. Remove azimuth correlation\n",
    "    # 3.c : splines\n",
    "    mytod = decorel_azel(mytod, azt, elt, scantype, doplot=doplot, nbins=50, n_el=50, nbspl=5)\n",
    "\n",
    "    # 4. remove offsets again but this time with mode method as it appears to be less affected \n",
    "    #    by the presence of the peaks (no underestimation of the offset resultingg is shadow around the peaks)\n",
    "    mytod = remove_offset_scan(mytod, scantype, method='mode')\n",
    "\n",
    "    # Map-making\n",
    "    newazt = (azt - azmoon) * np.cos(np.radians(elt))\n",
    "    newelt = -(elt - elmoon)\n",
    "\n",
    "\n",
    "    ### The file with offsets from Créidhe\n",
    "    offsets = pickle.load( open( 'pointing_offsets_fixed_hole.pickle', 'rb') )\n",
    "    offsets_corr = offsets[:,[1,0]]\n",
    "\n",
    "    #### Fit from Moon-FWHM-Offsets\n",
    "    fitted_values = np.array([5.048008260655892, -4.551730470265961, 0.6611216259908902, 1.003122495004602])\n",
    "    ### there is an apparent inversion in this file that is corrected below\n",
    "    new_offsets = np.reshape(rot_trans_scale_pts(np.ravel(offsets_corr), fitted_values), (256, 2))\n",
    "\n",
    "    \n",
    "    # plt.rc('figure',figsize=(16,8))\n",
    "    # plt.rc('font',size=12)\n",
    "    # plt.subplot(1,2,1).set_aspect(1)\n",
    "    # plt.plot(offsets_corr[:,0], offsets_corr[:,1],'bo', alpha=0.2, label='Offsets from Créidhe')\n",
    "    # plt.plot(new_offsets[:,0], new_offsets[:,1],'ro', alpha=0.2, label='Offest with Moon-fitted correction')\n",
    "    # plt.legend()\n",
    "    # plt.xlabel('$\\Delta_{az}$ [deg.]')\n",
    "    # plt.ylabel('$\\Delta_{el}$ [deg.]')\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    mytesn = tesnum\n",
    "    if np.isfinite(np.sum(new_offsets[mytesn-1,:])):\n",
    "        newazt = newazt + new_offsets[mytesn-1,0]\n",
    "        newelt = newelt - new_offsets[mytesn-1,1]   #### The minus sign is not understood !\n",
    "\n",
    "    # Calculate center of maps from pointing w.r.t. Moon\n",
    "    center=[np.mean(newazt), np.mean(newelt)]\n",
    "    \n",
    "    mapsb, mapcount = healpix_map(newazt[scantype != 0], newelt[scantype != 0], mytod[scantype != 0], nside=nside)\n",
    "    \n",
    "    return mapsb, mapcount\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a0526d4-1e0e-4c81-acc1-ae59d14db3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "allTESNum = np.arange(256)+1\n",
    "# allTESNum = [96, 136, 80]\n",
    "# allTESNum = [22, 26, 27, 28, 49]\n",
    "allmaps, data, center = make_coadded_maps(datadir, Obs_Site, allTESNum, data=data, \n",
    "                                       nside=nside, doplot=False, az_qubic=azqubic, parallel=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd0ca8e0-41d8-4921-a4be-74f9b0088fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rc('figure',figsize=(20,20))\n",
    "plt.rc('font',size=12)\n",
    "n0 = 8\n",
    "for i in range(len(allTESNum)):\n",
    "    ok = allmaps[i,:] != hp.UNSEEN\n",
    "    if (i%(n0**2))==0: \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        plt.figure()\n",
    "    mm = np.zeros(12*nside**2)+ hp.UNSEEN\n",
    "    mm[ok] = allmaps[i,ok]-tdt.get_mode(allmaps[i,ok])\n",
    "    mm[~ok] = hp.UNSEEN\n",
    "    hp.gnomview(mm, reso=3, sub=(n0,n0,(i%(n0**2))+1), min=-5e3, max=2.5e4, \n",
    "                title=allTESNum[i])#, rot=center)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f532c0e2-52ff-4f92-b43f-1a3cbb209282",
   "metadata": {},
   "outputs": [],
   "source": [
    "good = np.array([94, 95, 96])-1\n",
    "display_healpix_map(allmaps, [0,0], q, reso=3, min=-5e3, max=2.5e4, good=good, savepdf='essai.pdf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b640101b-5b2c-43e6-9162-e8a60ef24efc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a951818-f2ec-4d46-84a1-1e3b363151cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "### These are the Offsets from Créidhe tht were used for calibrating the focal plane orientation with the Moon (see above)\n",
    "offsets = pickle.load( open( 'pointing_offsets_fixed_hole.pickle', 'rb') )\n",
    "offsets_corr = offsets[:,[1,0]] ### apparent inversion found in Notebook Moon-FWHM-Offsets-2024\n",
    "\n",
    "#### Fit from Moon-FWHM-Offsets\n",
    "fitted_values = np.array([5.048008260655892, -4.551730470265961, 0.6611216259908902, 1.003122495004602])\n",
    "### there is an apparent inversion in this file that is corrected below\n",
    "new_offsets = np.reshape(rot_trans_scale_pts(np.ravel(offsets_corr), fitted_values), (256, 2))\n",
    "\n",
    "\n",
    "### This si in xy coordinates with x=Δaz and y=Δel\n",
    "p = plt.plot(offsets_corr[:,0], offsets_corr[:,1], 'o', label='Maynooth File')\n",
    "p = plt.plot(new_offsets[:,0], new_offsets[:,1], 'o', label='Maynooth File Moon rotated')\n",
    "plt.legend()\n",
    "\n",
    "### For a nice plot we need to go to polar coordinates where theta will be the radial distance\n",
    "rth = np.sqrt(offsets_corr[:,0]**2 + offsets_corr[:,1]**2)\n",
    "ph = np.arctan2(offsets_corr[:,1], offsets_corr[:,0])\n",
    "newrth = np.sqrt(new_offsets[:,0]**2 + new_offsets[:,1]**2)\n",
    "newph = np.arctan2(new_offsets[:,1], new_offsets[:,0])\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(subplot_kw={'projection': 'polar'})\n",
    "plt.plot(ph, rth, 'o', label='Maynooth file')\n",
    "plt.plot(newph, newrth, 'o', label='Maynooth file Moon rotated')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12324fd5-fbf9-40da-8efe-fd5c56efed0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### These are files found in the calfiles directry of QubicSoft.\n",
    "#### They should contain the synthesized beam related informations:\n",
    "#### - peak positions and amplitude as a function of frequency for all detectors and for 150 and 220 GHz\n",
    "#### => they apparently contain mosly crap... this is weird and needs to be fixed.\n",
    "\n",
    "plt.rc('figure',figsize=(10,6))\n",
    "plt.rc('font',size=12)\n",
    "\n",
    "from qubic.lib.Calibration.Qcalibration import QubicCalibration\n",
    "newd = d.copy()\n",
    "\n",
    "newd['synthbeam'] = 'CalQubic_Synthbeam_Analytical_220_FI.fits'              ## (992, 9)\n",
    "# newd['synthbeam'] = 'CalQubic_Synthbeam_Analytical_Multifreq_MJW_FI.fits'       ## (11, 992, 9)\n",
    "# newd['synthbeam'] = 'CalQubic_Synthbeam_Calibrated_JCH_FI.fits'                 ## (10, 9)\n",
    "# newd['synthbeam'] = 'CalQubic_Synthbeam_Calibrated_Multifreq_FI.fits'           ## (15, 10, 9)\n",
    "# newd['synthbeam'] = 'CalQubic_Synthbeam_Maynooth_220_FI.fits'                   ## (992, 9)\n",
    "\n",
    "\n",
    "print(newd['synthbeam'])\n",
    "c = QubicCalibration(newd)\n",
    "thetafits,phifits,valfits,freqs, mheader = c.get('synthbeam')\n",
    "print('\\n Thetafits:', thetafits.shape)\n",
    "print('\\n Phifits:', phifits.shape)\n",
    "print('\\n Valfits:', valfits.shape)\n",
    "print('\\n freqs', np.shape(freqs), '\\n', freqs)\n",
    "print('\\n mheader\\n', mheader)\n",
    "print()\n",
    "print(c.nu)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(subplot_kw={'projection': 'polar'})\n",
    "for idet in range(256):\n",
    "    col = None\n",
    "    for ipk in range(4,5):\n",
    "        if (idet+ipk) == 0:\n",
    "            lab = newd['synthbeam']\n",
    "        else:\n",
    "            lab = None\n",
    "        # p = plt.plot(phifits[:, idet, ipk], np.degrees(thetafits[:, idet, ipk]), 'o', color=col)\n",
    "        p = plt.plot(phifits[idet, ipk], np.degrees(thetafits[idet, ipk]), 'o', color=col, label=lab)\n",
    "        # highpeak = np.argmax(valfits[idet,:])\n",
    "        # p = plt.plot(phifits[idet, highpeak], np.degrees(thetafits[idet, highpeak]), 'o', color=col)\n",
    "        col = p[0].get_color()\n",
    "plt.grid(True)\n",
    "plt.plot(ph, rth, 'x', label='Maynooth file')\n",
    "plt.plot(newph, newrth, 'x', label='Maynooth file Moon Rotated')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33265cb1-fed6-49ec-a07c-f4d07b30465d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# It does not look totally absurd, but I guess in the calfiles, we're not taking the L.O.S. detectors but the first one in the list... \n",
    "# Also there seem to be rotation..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4145c615-bfa4-4319-82fc-af7d4467f658",
   "metadata": {},
   "outputs": [],
   "source": [
    "### now let's calculate L.O.S. for all detectors from their focal plane position (this is what is used in principle by default in the software if no calfile is used)\n",
    "\n",
    "import numexpr as ne\n",
    "position = q.detector.center\n",
    "myposition =  -position / np.sqrt(np.sum(position**2, axis=-1))[..., None]\n",
    "local_dict = {'nx': myposition[:, 0, None], 'ny': myposition[:, 1, None]}\n",
    "thlos = ne.evaluate('arcsin(sqrt(nx**2 + ny**2))',\n",
    "            local_dict=local_dict)\n",
    "phlos = ne.evaluate('arctan2(ny, nx)', local_dict=local_dict)\n",
    "\n",
    "fig, ax = plt.subplots(subplot_kw={'projection': 'polar'})\n",
    "for idet in range(256):\n",
    "    col = None\n",
    "    for ipk in range(1):\n",
    "        if (idet+ipk) == 0:\n",
    "            lab = newd['synthbeam']\n",
    "        else:\n",
    "            lab = None\n",
    "        # p = plt.plot(phifits[:, idet, ipk], np.degrees(thetafits[:, idet, ipk]), 'o', color=col)\n",
    "        p = plt.plot(phifits[idet, ipk], np.degrees(thetafits[idet, ipk]), 'o', color=col, label=lab)\n",
    "        # highpeak = np.argmax(valfits[idet,:])\n",
    "        # p = plt.plot(phifits[idet, highpeak], np.degrees(thetafits[idet, highpeak]), 'o', color=col)\n",
    "        col = p[0].get_color()\n",
    "plt.grid(True)\n",
    "plt.plot(ph, rth, 'x', color='r', label='Maynooth file')\n",
    "plt.plot(newph, newrth, 'x', label='Maynooth file Moon Rotated')\n",
    "plt.plot(phlos, np.degrees(thlos), '+', color='b', label='QubicSoft')\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "864defb9-25cc-4fcb-acbb-073b9830a4a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "### So it's a real mess... we have to figure that out !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f87d2cc0-3eed-4c46-9ba2-d23630542552",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
