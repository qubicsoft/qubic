{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4645de5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config InlineBackend.figure_format='retina'\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))\n",
    "\n",
    "rc('figure',figsize=(16,8))\n",
    "rc('font',size=12)\n",
    "\n",
    "from scipy.signal import medfilt\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "from qubicpack.qubicfp import qubicfp\n",
    "from qubic import fibtools as ft\n",
    "\n",
    "from importlib import reload\n",
    "import healpy as hp\n",
    "\n",
    "import time_domain_tools as tdt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db4441d",
   "metadata": {},
   "source": [
    "# Trying with QUBIC data from Salta\n",
    "\n",
    "We use a Synthesized Beam scanning performed on April 16th 2022 in Salta (CalSrc at 140 GHz): \n",
    "`2022-04-16_12.37.59__ScanMap_Speed_VE14_FastNoMod`\n",
    "\n",
    "Or alternatively, a scan a 170 GHz on April 14th:\n",
    "`2022-04-14_13.17.33__ScanMap_Speed_VE14_FastNoMod`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88f1566",
   "metadata": {},
   "outputs": [],
   "source": [
    "mydatadir = '/Users/hamilton/Qubic/Calib-TD/'\n",
    "thedate = '2022-04-16'\n",
    "thedata = '2022-04-16_12.37.59__ScanMap_Speed_VE14_FastNoMod'\n",
    "FreqSrc = 140.\n",
    "\n",
    "# mydatadir = '/Users/hamilton/Qubic/Calib-TD/'\n",
    "# thedate = '2022-04-14'\n",
    "# thedata = '2022-04-14_13.17.33__ScanMap_Speed_VE14_FastNoMod'\n",
    "# FreqSrc = 170.\n",
    "\n",
    "\n",
    "filename = mydatadir + '/' + thedate + '/' + thedata\n",
    "\n",
    "### Read data\n",
    "a = qubicfp()\n",
    "a.read_qubicstudio_dataset(filename)\n",
    "\n",
    "tt, tod = a.tod()\n",
    "\n",
    "az = a.azimuth()\n",
    "el = a.elevation()\n",
    "thk = a.timeaxis(datatype='hk')\n",
    "\n",
    "TESnum = 33\n",
    "tod = tod[TESnum-1,:]\n",
    "del(a)\n",
    "\n",
    "### We remove tt[0]\n",
    "tinit = tt[0]\n",
    "tt -= tinit\n",
    "thk -= tinit\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2988e11",
   "metadata": {},
   "source": [
    "### First just a glimpse at the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e3d928e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rc('figure',figsize=(16,8))\n",
    "rc('font',size=12)\n",
    "\n",
    "\n",
    "subplot(2,2,1)\n",
    "plot(tt, tod)\n",
    "xlabel('t')\n",
    "ylabel('TOD')\n",
    "\n",
    "subplot(2,2,2)\n",
    "plot(az, el)\n",
    "xlabel('az')\n",
    "ylabel('el')\n",
    "\n",
    "subplot(2,2,3)\n",
    "plot(thk, az)\n",
    "xlabel('t')\n",
    "ylabel('az')\n",
    "\n",
    "subplot(2,2,4)\n",
    "plot(thk, el)\n",
    "xlabel('t')\n",
    "ylabel('el')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dd8fb3f",
   "metadata": {},
   "source": [
    "### Identifying scans\n",
    "For the mapmaking and for many purposes, it will be very useeful to identify each scan:\n",
    "- a numbering for each back & forth scan\n",
    "- a region to remove at the end of each scan (bad data due to FLL reset, slowingg down of the moiunt, possibly HWP rotation\n",
    "- is the scan back or forth ?\n",
    "\n",
    "The function `identify_scans()` from `time_domain_tools.py` is intended as a first version of this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "009fa917",
   "metadata": {},
   "outputs": [],
   "source": [
    "rc('figure',figsize=(20,12))\n",
    "rc('font',size=12)\n",
    "reload(tdt)\n",
    "\n",
    "### Identify scan types and numbers\n",
    "scantype_hk, azt, elt, scantype = tdt.identify_scans(thk, az, el, tt=tt, doplot=True, plotrange=[0,2000], thr_speedmin=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "827023fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def healpix_map(azt, elt, tod, flags=None, flaglimit=0, nside=128, countcut=0, unseen_val=hp.UNSEEN):\n",
    "    if flags is None:\n",
    "        flags = np.zeros(len(azt))\n",
    "    \n",
    "    ok = flags <= flaglimit \n",
    "    return healpix_map_(azt[ok], elt[ok], tod[ok], nside=nside, countcut=countcut, unseen_val=unseen_val)\n",
    "\n",
    "\n",
    "def healpix_map_(azt, elt, tod, nside=128, countcut=0, unseen_val=hp.UNSEEN):\n",
    "    ips = hp.ang2pix(nside, azt, elt, lonlat=True)\n",
    "    mymap = np.zeros(12*nside**2)\n",
    "    mapcount = np.zeros(12*nside**2)\n",
    "    for i in range(len(azt)):\n",
    "        mymap[ips[i]] += tod[i]\n",
    "        mapcount[ips[i]] += 1\n",
    "    unseen = mapcount <= countcut\n",
    "    mymap[unseen] = unseen_val\n",
    "    mapcount[unseen] = unseen_val\n",
    "    mymap[~unseen] = mymap[~unseen] / mapcount[~unseen]\n",
    "    return mymap, mapcount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f7bfec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mode(y, nbinsmin=51):\n",
    "    mm, ss = ft.meancut(y, 4)\n",
    "    hh = np.histogram(y, bins=int(np.min([len(y) / 30, nbinsmin])), range=[mm - 5 * ss, mm + 5 * ss])\n",
    "    idmax = np.argmax(hh[0])\n",
    "    mymode = 0.5 * (hh[1][idmax + 1] + hh[1][idmax])\n",
    "    return mymode\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e41ddd80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_one(mapsb, anatype='', sub=(1,1,1), nlo=3, nhi=3, reso=12):\n",
    "    unseen = (mapsb == hp.UNSEEN)\n",
    "    mm, ss = ft.meancut(mapsb[~unseen], 3)\n",
    "    hp.gnomview(mapsb, rot=[0,50], reso=reso, sub=sub, title=anatype+'\\n Both scans $\\sigma$ = {0:5.3g}'.format(ss), min=-nlo*ss, max=nhi*ss)\n",
    "\n",
    "\n",
    "def display_all(mapsb, mapsb_pos, mapsb_neg, anatype=''):\n",
    "    unseen = (mapsb == hp.UNSEEN) | (mapsb_pos == hp.UNSEEN) | (mapsb_neg == hp.UNSEEN)\n",
    "\n",
    "    ### Average of back and Forth\n",
    "    mapav = (mapsb_pos + mapsb_neg)/2\n",
    "    mapav[unseen] = hp.UNSEEN\n",
    "\n",
    "    ### Difference of back and Forth\n",
    "    mapdiff = (mapsb_pos - mapsb_neg)\n",
    "    mapdiff[unseen] = hp.UNSEEN\n",
    "\n",
    "    ### Difference of All and Av\n",
    "    mapdiff2 = (mapav - mapsb)\n",
    "    mapdiff2[unseen] = hp.UNSEEN\n",
    "\n",
    "    nlo = 3\n",
    "    nhi = 3\n",
    "    reso = 12\n",
    "    mm, ss = ft.meancut(mapsb[~unseen], 3)\n",
    "    hp.gnomview(mapsb, rot=[0,50], reso=reso, sub=(2,3,1), title=anatype+'\\n Both scans $\\sigma$ = {0:5.3g}'.format(ss), min=-nlo*ss, max=nhi*ss)\n",
    "    mmp, ssp = ft.meancut(mapsb_pos[~unseen], 3)\n",
    "    hp.gnomview(mapsb_pos, rot=[0,50], reso=reso, sub=(2,3,2), title=anatype+'\\n Pos scans $\\sigma$ = {0:5.3g}'.format(ssp), min=-nlo*ss, max=nhi*ss)\n",
    "    mmn, ssn = ft.meancut(mapsb_neg[~unseen], 3)\n",
    "    hp.gnomview(mapsb_neg, rot=[0,50], reso=reso, sub=(2,3,3), title=anatype+'\\n Neg scans $\\sigma$ = {0:5.3g}'.format(ssn), min=-nlo*ss, max=nhi*ss)\n",
    "    mma, ssa = ft.meancut(mapav[~unseen], 3)\n",
    "    hp.gnomview(mapav, rot=[0,50], reso=reso, sub=(2,3,4), title=anatype+'\\n Av of Both scans $\\sigma$ = {0:5.3g}'.format(ssa), min=-nlo*ss, max=nhi*ss)\n",
    "    mmd, ssd = ft.meancut(mapdiff[~unseen], 3)\n",
    "    hp.gnomview(mapdiff, rot=[0,50], reso=reso, sub=(2,3,5), title=anatype+'\\n Diff of both scans $\\sigma$ = {0:5.3g}'.format(ssd), min=-nlo*ssd, max=nlo*ssd)\n",
    "    mmd2, ssd2 = ft.meancut(mapdiff2[~unseen], 3)\n",
    "    hp.gnomview(mapdiff2, rot=[0,50], reso=reso, sub=(2,3,6), title=anatype+'\\n Both - Av $\\sigma$ = {0:5.3g}'.format(ssd2), min=-nlo*ssd, max=nlo*ssd)\n",
    "\n",
    "\n",
    "    figure()\n",
    "    mini = -np.max(mapsb[~unseen])/10\n",
    "    maxi = np.max(mapsb[~unseen])*0.8\n",
    "\n",
    "    mm, ss = ft.meancut(mapsb[~unseen], 3)\n",
    "    hp.gnomview(mapsb, rot=[0,50], reso=reso, sub=(2,3,1), title=anatype+'\\n Both scans $\\sigma$ = {0:5.3g}'.format(ss), min=mini, max=maxi)\n",
    "    mmp, ssp = ft.meancut(mapsb_pos[~unseen], 3)\n",
    "    hp.gnomview(mapsb_pos, rot=[0,50], reso=reso, sub=(2,3,2), title=anatype+'\\n Pos scans $\\sigma$ = {0:5.3g}'.format(ssp), min=mini, max=maxi)\n",
    "    mmn, ssn = ft.meancut(mapsb_neg[~unseen], 3)\n",
    "    hp.gnomview(mapsb_neg, rot=[0,50], reso=reso, sub=(2,3,3), title=anatype+'\\n Neg scans $\\sigma$ = {0:5.3g}'.format(ssn), min=mini, max=maxi)\n",
    "    mma, ssa = ft.meancut(mapav[~unseen], 3)\n",
    "    hp.gnomview(mapav, rot=[0,50], reso=reso, sub=(2,3,4), title=anatype+'\\n Av of Both scans $\\sigma$ = {0:5.3g}'.format(ssa), min=mini, max=maxi)\n",
    "    mmd, ssd = ft.meancut(mapdiff[~unseen], 3)\n",
    "    hp.gnomview(mapdiff, rot=[0,50], reso=reso, sub=(2,3,5), title=anatype+'\\n Diff of both scans $\\sigma$ = {0:5.3g}'.format(ssd), min=mini, max=maxi)\n",
    "    mmd2, ssd2 = ft.meancut(mapdiff2[~unseen], 3)\n",
    "    hp.gnomview(mapdiff2, rot=[0,50], reso=reso, sub=(2,3,6), title=anatype+'\\n Both - Av $\\sigma$ = {0:5.3g}'.format(ssd2), min=mini, max=maxi)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fea6d91",
   "metadata": {},
   "source": [
    "### Simple map-making: just removing median from TOD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "508b5fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "anatype = 'Raw'\n",
    "reload(tdt)\n",
    "###### Pipeline:\n",
    "# Identify scan types and numbers\n",
    "scantype_hk, azt, elt, scantype = identify_scans(thk, az, el, tt=tt, doplot=False, thr_speedmin=0.1)\n",
    "\n",
    "# # remove jumps\n",
    "# mytod, flags = tdt.jumps_correction(tod)\n",
    "# Median Scan offset removal\n",
    "mytod = -tod - np.median(-tod[scantype != 0])\n",
    "\n",
    "# Map-making\n",
    "nside = 256\n",
    "mapsb, mapcount = healpix_map(azt[scantype != 0], elt[scantype != 0], mytod[scantype != 0], nside=nside)\n",
    "mapsb_pos, _ = healpix_map(azt[scantype > 0], elt[scantype > 0], mytod[scantype > 0], nside=nside)\n",
    "mapsb_neg, _ = healpix_map(azt[scantype < 0], elt[scantype < 0], mytod[scantype < 0], nside=nside)\n",
    "\n",
    "# Display Results\n",
    "display_all(mapsb, mapsb_pos, mapsb_neg, anatype=anatype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0630bf7b",
   "metadata": {},
   "source": [
    "There are obvious issues:\n",
    "1. significant elevation stripes in the maps: \n",
    "     - we need to equalize the average of each back & forth scan offset\n",
    "2. a clear effect towards the right of the map: likely some \"ground pickup\" as we see it with the same pattern in the back and forth scans and absent in the subtraction of both.\n",
    "    - we need to filter the signal in order to remove this or to measure a pattern in azimuth, common to all elevations.\n",
    "    - It could also be seen with details in thee \"no source\" scans.\n",
    "3. Synthesized beeam appears displaced between the back and forth scans:\n",
    "    - we need to account for time constants\n",
    "    - a shift in the timestamps has been identified beetween the mount az,el and the data... this is likely the main effect. It is eestimated to be 0.191 seconds (very preliminary)\n",
    "    \n",
    "Let's first apply this eempirical timeshift between Mount and TOD (it is a priority to solve this major issue).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fcf673c",
   "metadata": {},
   "outputs": [],
   "source": [
    "anatype = 'TimeShift corrected'\n",
    "deltaT= 0.191\n",
    "\n",
    "###### Pipeline:\n",
    "# Identify scan types and numbers\n",
    "scantype_hk, azt, elt, scantype = identify_scans(thk, az, el, tt=tt-deltaT, doplot=False, thr_speedmin=0.1)\n",
    "# Median Scan offset removal\n",
    "mytod = -tod - np.median(-tod[scantype != 0])\n",
    "\n",
    "# Map-making\n",
    "nside = 256\n",
    "mapsb, mapcount = healpix_map(azt[scantype != 0], elt[scantype != 0], mytod[scantype != 0], nside=nside)\n",
    "mapsb_pos, _ = healpix_map(azt[scantype > 0], elt[scantype > 0], mytod[scantype > 0], nside=nside)\n",
    "mapsb_neg, _ = healpix_map(azt[scantype < 0], elt[scantype < 0], mytod[scantype < 0], nside=nside)\n",
    "\n",
    "# Display Results\n",
    "display_all(mapsb, mapsb_pos, mapsb_neg, anatype=anatype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce1100e2",
   "metadata": {},
   "source": [
    "Most of the difference between two scans has disappeared (not we still DID NOT correct for time-constants)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a900872a",
   "metadata": {},
   "source": [
    "### Destriping scan by scan\n",
    "Probably not good enough and will not help for \"ground pickup\" effect, but very easy to implement. We will just remove a clipped mean or median or the mode from each back and forth scan.\n",
    "\n",
    "One can play with those options below (and try others), but for now the median leaves some features around the bright peaks and the modee seems unstable. We'll start with the clipped mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91672340",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_offset_scan(mytod, scantype, method='meancut', apply_to_bad = True):\n",
    "    ### We remove offsets for each good scan but we also need to remove a coomparable offset for the scantype==0 reggiions in order to keep coninuity \n",
    "    ### This si donee by apply_to_bad=True\n",
    "    \n",
    "    indices = np.arange(len(mytod))\n",
    "    last_index = 0\n",
    "    myoffsetn = 0\n",
    "    myoffsetp = 0\n",
    "    donefirst = 0\n",
    "    \n",
    "    nscans = np.max(np.abs(scantype))\n",
    "    for n in range(1, nscans+1):\n",
    "        # scan +\n",
    "        ok = scantype == n\n",
    "        if method == 'meancut':\n",
    "            myoffsetp, _ = ft.meancut(mytod[ok], 3)\n",
    "        elif method == 'median':\n",
    "            myoffsetp = np.median(mytod[ok])\n",
    "        elif method == 'mode':\n",
    "            myoffsetp = get_mode(mytod[ok])\n",
    "        else:\n",
    "            break\n",
    "        mytod[ok] -= myoffsetp        \n",
    "        if apply_to_bad:\n",
    "            first_index = np.min(indices[ok])\n",
    "            if (n==1) & (donefirst==0): myoffsetn = myoffsetp ### deal with first region\n",
    "            vals_offsets = myoffsetn + np.linspace(0,1, first_index-last_index-1)*(myoffsetp-myoffsetn)\n",
    "            mytod[last_index+1:first_index] -= vals_offsets\n",
    "            last_index = np.max(indices[ok])\n",
    "            donefirst = 1\n",
    "        \n",
    "        \n",
    "        # scan -\n",
    "        ok = scantype == (-n)\n",
    "        if method == 'meancut':\n",
    "            myoffsetn, _ = ft.meancut(mytod[ok], 3)\n",
    "        elif method == 'median':\n",
    "            myoffsetn = np.median(mytod[ok])\n",
    "        elif method == 'mode':\n",
    "            myoffsetn = get_mode(mytod[ok])\n",
    "        else:\n",
    "            break\n",
    "        mytod[ok] -= myoffsetn\n",
    "        if apply_to_bad:\n",
    "            first_index = np.min(indices[ok])\n",
    "            if (n==1) & (donefirst==0): myoffsetp = myoffsetn ### deal with first region\n",
    "            vals_offsets = myoffsetp + np.linspace(0,1, first_index-last_index-1)*(myoffsetn-myoffsetp)\n",
    "            mytod[last_index+1:first_index] -= vals_offsets\n",
    "            last_index = np.max(indices[ok])\n",
    "            donefirst = 1\n",
    "    \n",
    "    return mytod\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "978f9d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "anatype = 'TS corr - Az Destriped'\n",
    "\n",
    "###### Pipelinee:\n",
    "# 1. Identify scan types and numbers\n",
    "scantype_hk, azt, elt, scantype = identify_scans(thk, az, el, tt=tt-deltaT, doplot=False, thr_speedmin=0.1)\n",
    "nscans = np.max(np.abs(scantype))\n",
    "# 2. Offset removal scan by scan using meancut\n",
    "mytod = -tod.copy()\n",
    "mytod = remove_offset_scan(mytod, scantype, method='meancut')\n",
    "\n",
    "# Map-Making\n",
    "mapsb, mapcount = healpix_map(azt[scantype != 0], elt[scantype != 0], mytod[scantype != 0], nside=nside)\n",
    "mapsb_pos, _ = healpix_map(azt[scantype > 0], elt[scantype > 0], mytod[scantype > 0], nside=nside)\n",
    "mapsb_neg, _ = healpix_map(azt[scantype < 0], elt[scantype < 0], mytod[scantype < 0], nside=nside)\n",
    "\n",
    "# Display Results\n",
    "display_all(mapsb, mapsb_pos, mapsb_neg, anatype=anatype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "466737e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See how the clean TOD looks\n",
    "plot(tt[scantype>0], mytod[scantype>0], '.', label='Scan +')\n",
    "plot(tt[scantype<0], mytod[scantype<0], '.', label='Scan -')\n",
    "plot(tt[scantype==0], mytod[scantype==0], '.', label='Bad')\n",
    "xlim(0,1000)\n",
    "ylim(-30000, 30000)\n",
    "legend()\n",
    "show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ea5450",
   "metadata": {},
   "source": [
    "As expected, it does not affect the ground pickup, but does a good job equalizing scans. We can try to remove a pattern in azimuth, common to all elevations.\n",
    "\n",
    "(some striping seems still visible and is likely to be due to some 1/f noise - not constant within a scan - that will be reemoved with filtering later on).\n",
    "\n",
    "### Lets build the \"azimuth pattern\":\n",
    "- first we make a profile of the data as a function of azimuth, using the \"mode\" method. This meeans than in each azimuth bin, the program returns thee mode (maxiimum of thee distribution) of the TOD value for all elevations in this bin. Using the mode is quite powerful for neglecting the contribution from the bright signal peaks.\n",
    "- then one fits this law with a degree 2 polynomial\n",
    "- We see below that the profile is slightly different for positive and negative scans, so we do it separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ebb12b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decorel_azimuth(mytod, azt, scantype, doplot=True):\n",
    "    ### Profiling in Azimuth\n",
    "    okall = np.abs(scantype) > 0 \n",
    "    okpos = scantype > 0 \n",
    "    okneg = scantype < 0 \n",
    "    oks = [okpos, okneg]\n",
    "    oks_names = ['+ scans', '- scans']\n",
    "    polys = []\n",
    "    if doplot:\n",
    "        figure()\n",
    "    for i in range(len(oks)):\n",
    "        ok = oks[i]\n",
    "        minaz = np.min(azt[ok])\n",
    "        maxaz = np.max(azt[ok])\n",
    "        xc, yc, dx, dy, _ = ft.profile(azt[ok], mytod[ok], rng=[minaz, maxaz], nbins=25, mode=True, dispersion=True, plot=False)\n",
    "        z = polyfit(xc, yc, 2, w=1./dy)\n",
    "        p = np.poly1d(z)\n",
    "        polys.append(p)\n",
    "        xaz = np.linspace(minaz, maxaz, 100)\n",
    "        if doplot:\n",
    "            pl = errorbar(xc, yc, yerr=dy, xerr=dx, fmt='o')\n",
    "            plot(xaz, p(xaz), label=oks_names[i], color=pl[0].get_color())\n",
    "    if doplot:\n",
    "        xlabel('Azimuth [deg]')\n",
    "        ylabel('Mode of TOD')\n",
    "        legend()\n",
    "\n",
    "    ### Removing the azimuthal effect\n",
    "    ok = scantype >= 0\n",
    "    mytod[ok] -= polys[0](azt[ok])\n",
    "    ok = scantype < 0\n",
    "    mytod[ok] -= polys[1](azt[ok])\n",
    "    \n",
    "    return mytod\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b724ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "anatype = 'TS, Az Corrected'\n",
    "\n",
    "\n",
    "###### Pipeline:\n",
    "# 1. Identify scan types and numbers\n",
    "scantype_hk, azt, elt, scantype = identify_scans(thk, az, el, tt=tt-deltaT, doplot=False, thr_speedmin=0.1)\n",
    "nscans = np.max(np.abs(scantype))\n",
    "\n",
    "# 2. Offset removal scan by scan using median \n",
    "#    (here we just want to have all scans at the same level before decorrelating from azimuth)\n",
    "mytod = -tod.copy()\n",
    "mytod = remove_offset_scan(mytod, scantype, method='median')\n",
    "\n",
    "# 3. Remove azimuth correlation\n",
    "mytod = decorel_azimuth(mytod, azt, scantype, doplot=True)\n",
    "\n",
    "    \n",
    "# 4. remove offsets again but this time with mode method as it appears to be less affected \n",
    "#    by the presence of the peaks (no underestimation of the offset resultingg is shadow around the peaks)\n",
    "mytod = remove_offset_scan(mytod, scantype, method='mode')\n",
    "\n",
    "\n",
    "### Then make the maps\n",
    "mapsb, mapcount = healpix_map(azt[scantype != 0], elt[scantype != 0], mytod[scantype != 0], nside=nside)\n",
    "mapsb_pos, _ = healpix_map(azt[scantype > 0], elt[scantype > 0], mytod[scantype > 0], nside=nside)\n",
    "mapsb_neg, _ = healpix_map(azt[scantype < 0], elt[scantype < 0], mytod[scantype < 0], nside=nside)\n",
    "\n",
    "# Display Results\n",
    "figure()\n",
    "display_all(mapsb, mapsb_pos, mapsb_neg, anatype=anatype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6634088",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Look at cleaned TOD\n",
    "figure()\n",
    "plot(tt[scantype>0], mytod[scantype>0], '.', label='Scan +')\n",
    "plot(tt[scantype<0], mytod[scantype<0], '.', label='Scan +')\n",
    "plot(tt[scantype==0], mytod[scantype==0], '.', label='Bad')\n",
    "xlim(0,1000)\n",
    "ylim(-30000, 30000)\n",
    "legend()\n",
    "show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a86916",
   "metadata": {},
   "source": [
    "So one can see significant improvement: RMS of the background reduces from ~1.3e4 to 2.8e3.\n",
    "\n",
    "However, the simplistic \"Azimuth pattern\" we fitted now appears to be insufficient. It seems that it also evolves with elevation... so we could measure it by elevation bins and get something better.\n",
    "So there is still significant room for improvement.\n",
    "\n",
    "We can also test filtering, but we'll have to avoid signal harmonics, and the \"Az/el\" bacckground pattern will also be ein those harmonics. Also for this wee'll need to fill the `scantype==0` regions with a constrained realization of noise in order to avoid FFT bouncing. This will be donee in a second time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d7a014",
   "metadata": {},
   "source": [
    "### Improving on azimuth/elevation background pattern\n",
    "There are various ways for investigating this (and what I discuss here is surely not exhaustive):\n",
    "- Trying to avoid signal with thiis TES and see how this changes with elevation.\n",
    "- Use a dataset where the calibration source is off and cheeck how the pattern changes from one TES to another (important as it might give us some information on the optical or magnetic origin of this effect).\n",
    "- With a single dataset we could also use multiple TES and make some median in order to avoid the signal as it will not be present on all TES at the same az/el...\n",
    "\n",
    "For now, let's try the simplest approach: using a single TES."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18542cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_chunks(mytod, scantype, value):\n",
    "    ### returns chunks corresponding to a given value\n",
    "    current_chunk = []\n",
    "    chunk_idx = []\n",
    "    inchunk = 0\n",
    "    chunknum = 0\n",
    "    for i in range(len(scantype)):\n",
    "        if scantype[i]==value:\n",
    "            inchunk = 1\n",
    "            current_chunk.append(i)\n",
    "        else:\n",
    "            if inchunk == 1:\n",
    "                chunknum += 1\n",
    "                chunk_idx.append([current_chunk[0], current_chunk[len(current_chunk)-1]])\n",
    "                current_chunk = []\n",
    "                inchunk = 0\n",
    "    if inchunk == 1:\n",
    "        chunk_idx.append([current_chunk[0], current_chunk[len(current_chunk)-1]])\n",
    "    return chunk_idx\n",
    "\n",
    "\n",
    "def linear_rescale_chunks(mytod, chunks, sz=1000):\n",
    "    for i in range(len(chunks)):\n",
    "        thechunk = chunks[i]\n",
    "        chunklen = thechunk[1] - thechunk[0]+1\n",
    "        if thechunk[0] == 0:\n",
    "            # this is the starting index => just the average\n",
    "            vals = np.zeros(chunklen) + np.median(mytod[thechunk[1]+1: thechunk[1]+sz]) + np.median(mytod[thechunk[0]:thechunk[1]])\n",
    "            mytod[thechunk[0]:thechunk[1]+1] -= vals\n",
    "        elif thechunk[1]==(len(mytod)-1):\n",
    "            # this is the last one => just the average\n",
    "            vals = np.zeros(chunklen) + np.median(mytod[thechunk[0]-1-sz: thechunk[0]-1]) + np.median(mytod[thechunk[0]:thechunk[1]])\n",
    "            mytod[thechunk[0]:thechunk[1]+1] -= vals\n",
    "        else:\n",
    "            left = np.median(mytod[thechunk[0]-1-sz: thechunk[0]-1])\n",
    "            right = np.median(mytod[thechunk[1]+1: thechunk[1]+sz])\n",
    "            vals = left + np.linspace(0,1, chunklen)*(right-left)\n",
    "            mytod[thechunk[0]:thechunk[1]+1] -= np.median(mytod[thechunk[0]:thechunk[1]+1]) - vals\n",
    "            \n",
    "    return mytod\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b974a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decorel_azel(mytod, azt, elt, scantype, doplot=True, n_el=20, degree=3):\n",
    "    ### Profiling in Azimuth and elevation\n",
    "    el_lims = np.linspace(np.min(el)-0.0001, np.max(el)+0.0001, n_el+1)\n",
    "    el_av = 0.5 * (el_lims[1:] + el_lims[:-1])\n",
    "\n",
    "    okall = np.abs(scantype) > 0 \n",
    "    okpos = scantype > 0 \n",
    "    okneg = scantype < 0 \n",
    "    oks = [okpos, okneg]\n",
    "    oks_names = ['+ scans', '- scans']\n",
    "    minaz = np.min(azt[okall])\n",
    "    maxaz = np.max(azt[okall])\n",
    "    xaz = np.linspace(minaz, maxaz, 100)\n",
    "\n",
    "    if doplot:\n",
    "        figure()\n",
    "        xlabel('Azimuth [deg]')\n",
    "        ylabel('Mode of TOD')\n",
    "    \n",
    "    coefficients = np.zeros((2, n_el, degree+1))\n",
    "    for i in range(len(oks)):\n",
    "        if doplot: subplot(1,2,i+1)\n",
    "        for j in range(n_el):\n",
    "            ok = oks[i] & (elt >= el_lims[j]) & (elt < el_lims[j+1])\n",
    "            xc, yc, dx, dy, _ = ft.profile(azt[ok], mytod[ok], rng=[minaz, maxaz], nbins=50, mode=True, dispersion=True, plot=False)\n",
    "            z = polyfit(xc, yc, degree, w=1./dy)\n",
    "            p = np.poly1d(z)\n",
    "            coefficients[i,j,:] = z\n",
    "            if doplot:\n",
    "                pl = errorbar(xc, yc, yerr=dy, xerr=dx, fmt='o')\n",
    "                plot(xaz, p(xaz), color=pl[0].get_color(), label = oks_names[i] + ' - El = {0:5.1f}'.format(np.mean(elt[ok])))\n",
    "    if doplot: legend()\n",
    "\n",
    "    ### Now interpolate this to remove it to the data\n",
    "    nscans = np.max(np.abs(scantype))\n",
    "    for i in range(1, nscans+1):\n",
    "        okp = scantype == i\n",
    "        okn = scantype == (-i)\n",
    "        for ok in [okp, okn]:\n",
    "            the_el = np.median(elt[ok])\n",
    "            myp = np.poly1d([np.interp(the_el, el_av, coefficients[0,:,i]) for i in arange(degree+1)])\n",
    "            mytod[ok] -= myp(azt[ok])\n",
    "    ### And interpolate for scantype==0 regions\n",
    "    bad_chunks = get_chunks(mytod, scantype, 0)\n",
    "    mytod = linear_rescale_chunks(mytod, bad_chunks, sz=100)\n",
    "    return mytod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae563a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "anatype = 'TS, Az/El Corrected'\n",
    "\n",
    "###### Pipeline:\n",
    "# 1. Identify scan types and numbers\n",
    "scantype_hk, azt, elt, scantype = identify_scans(thk, az, el, tt=tt-deltaT, doplot=False, thr_speedmin=0.1)\n",
    "nscans = np.max(np.abs(scantype))\n",
    "\n",
    "# 2. Offset removal scan by scan using median \n",
    "#    (here we just want to have all scans at the same level before decorrelating from azimuth)\n",
    "mytod = -tod.copy()\n",
    "mytod = remove_offset_scan(mytod, scantype, method='median')\n",
    "\n",
    "# 3. Remove azimuth and elevation correlation\n",
    "mytod = decorel_azel(mytod, azt, elt, scantype, doplot=True)\n",
    "\n",
    "    \n",
    "# 4. remove offsets again but this time with mode method as it appears to be less affected \n",
    "#    by the presence of the peaks (no underestimation of the offset resultingg is shadow around the peaks)\n",
    "mytod = remove_offset_scan(mytod, scantype, method='mode')\n",
    "\n",
    "\n",
    "### Then make the maps\n",
    "mapsb, mapcount = healpix_map(azt[scantype != 0], elt[scantype != 0], mytod[scantype != 0], nside=nside)\n",
    "mapsb_pos, _ = healpix_map(azt[scantype > 0], elt[scantype > 0], mytod[scantype > 0], nside=nside)\n",
    "mapsb_neg, _ = healpix_map(azt[scantype < 0], elt[scantype < 0], mytod[scantype < 0], nside=nside)\n",
    "\n",
    "# Display Results\n",
    "figure()\n",
    "display_all(mapsb, mapsb_pos, mapsb_neg, anatype=anatype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "793c7a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Look at cleaned TOD\n",
    "figure()\n",
    "plot(tt[scantype>0], mytod[scantype>0], '.', label='Scan +')\n",
    "plot(tt[scantype<0], mytod[scantype<0], '.', label='Scan +')\n",
    "plot(tt[scantype==0], mytod[scantype==0], '.', label='Bad')\n",
    "xlim(0,1000)\n",
    "ylim(-30000, 30000)\n",
    "legend()\n",
    "show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "210f7085",
   "metadata": {},
   "source": [
    "## Filtering\n",
    "Wee have significantly improved things by decorrelating w.r.t. aziimuth and elevation patterns. However, it is clear that the map is still heavily striped. The source signal is sufficiently strong for these stripes to be unlikely to limit strongly our knowledge of the synthesized beam.  Nevertheless it is a good thing too try to improve further our baselines knowledge.\n",
    "\n",
    "\n",
    "In a realistic scanning strategy on the sky we would benefit from scanning with many angles for each pixel and this would be a powerful tool for reducingg striping (with optimal mapmaking for instance, but also through other means). Heere by definition wee only in azimuth/elevation  and do not beenefit from sky roation. So we have to deal without this extra-information.\n",
    "\n",
    "Our pipeline is now:\n",
    "1. Scans identification\n",
    "2. Median Scan offset removal\n",
    "3. Remove Azimuth/Elevation correltion\n",
    "4. Mode scan offset removal\n",
    "\n",
    "\n",
    "We will try to improve things using Filtering at the end of the pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "025d36c7",
   "metadata": {},
   "source": [
    "The first step here is to identify which are the frequencies (in the TOD domain) that are relevant for the signal we are about to reconstruct. Our signal is the synthesized beam which does not have features smaller that the peak width (around 1 degree FWHM on the sky for the TD, 0.39 degrees for the FI). So this corresponds to features (in terms of sigma) in azimuth of:\n",
    "$$1 deg  / 2.35 / \\cos(50) = 0.66~deg~(el=50)$$\n",
    "\n",
    "As a consequence we do not want to remove any feature in the TOD larger than this (and this is just a rough approximmation as we span 30-70 degrees).\n",
    "\n",
    "The angular velocity here is 0.75 degree/sec in azimuth, so this corresponds to 0.88 seconds, or 1.1 Hertz.\n",
    "\n",
    "This means that we expect no signal beyond 1 Hertz, we can then filter these modes out.\n",
    "\n",
    "#### However it is better to check this with an actual simulation\n",
    "We take the theoretical synthesized beam and scan it with out scanning strategy and have a look at the expected TOD for the source alone. We take the theoretical map with a large nside in order to have a good sampling in TOD domain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "602fd025",
   "metadata": {},
   "outputs": [],
   "source": [
    "import qubic\n",
    "from qubicpack.utilities import Qubic_DataDir\n",
    "# Repository for dictionary and input maps\n",
    "global_dir = Qubic_DataDir(datafile='instrument.py', datadir='../')\n",
    "dictfilename = global_dir + '/dicts/pipeline_demo.dict'\n",
    "d = qubic.qubicdict.qubicDict()\n",
    "d.read_from_file(dictfilename)\n",
    "d['config'] = 'TD'\n",
    "d['nside'] = 1024\n",
    "\n",
    "s = qubic.QubicScene(d)\n",
    "q = qubic.QubicMultibandInstrument(d)\n",
    "sb = q[0].get_synthbeam(s, idet=154)   # this is the QubicSoft number for TES #33 I think...\n",
    "\n",
    "### and now we rotathe this map to elevation 50\n",
    "rot_custom = hp.Rotator(rot=[180, 90-50], inv=True)\n",
    "rot_custom(0,0, lonlat=True)\n",
    "sbrot = rot_custom.rotate_map_alms(sb)\n",
    "\n",
    "#sbrot[hp.ud_grade(mapsb, d['nside'])==hp.UNSEEN] = hp.UNSEEN\n",
    "hp.gnomview(mapsb, rot=[0, 50], reso=12, sub=(2,2,1), title='Measured SB')\n",
    "hp.gnomview(sbrot, rot=[0, 50], reso=12, sub=(2,2,2), title='Theoretical SB')\n",
    "\n",
    "#### Now we scan it with the scanning strategy\n",
    "# index of pixels for each time sample\n",
    "ips = hp.ang2pix(d['nside'], np.radians(90-elt), np.radians(azt))\n",
    "tod_th = -sbrot[ips]/np.max(sbrot)\n",
    "\n",
    "### Put both at the same scale and baseline\n",
    "tod_th = tod_th * (np.max(tod)-np.min(tod)) + np.median(tod)\n",
    "\n",
    "subplot(2,1,2)\n",
    "plot(tt, tod, label='Raw TOD')\n",
    "plot(tt, tod_th, label='Theoretical TOD')\n",
    "legend()\n",
    "xlabel('Time')\n",
    "ylabel('ADU')\n",
    "legend()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c80f3f1f",
   "metadata": {},
   "source": [
    "Now let's look at the power spectrum of the signal alone, and compare to that of the data.\n",
    "\n",
    "This confirms the above reasonning: we expect no signal beyond 1 Hz, even a bit lower - typically 0.6 Hz.\n",
    "\n",
    "We also clearly see a few important things:\n",
    "- there is signal at very low frequency: this si bad news as it means that if we highpass the data, we will loose some signal... So 1/f features are going to be really annoying. We may have to live with them...\n",
    "- The real data shows a very strong peak at the scanning frequency 0.0063 Hz (calculated below from the data). This IS NOT signal, it is the scan-synchronous spurious signal (correlation with azimuth and elevation) that therefore has to be reduced down to the typical size of the theoretical signal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dafa6d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "mytod = -tod.copy()\n",
    "p0, ff = ft.power_spectrum(tt, tod, rebin=True)\n",
    "pth, ff = ft.power_spectrum(tt, tod_th, rebin=True)\n",
    "\n",
    "plot(ff, p0, label='Raw')\n",
    "plot(ff, pth, label='Expected signal')\n",
    "xscale('log')\n",
    "yscale('log')\n",
    "xlabel('Frequency [Hz]')\n",
    "ylabel('PSD')\n",
    "\n",
    "# scanning period\n",
    "scanper = np.min(tt[scantype==60])-np.min(tt[scantype==59])\n",
    "scanfreq = 1./scanper\n",
    "axvline(x=scanfreq, ls=':', color='k', label='Scanning Frequency ~{0:5.2g} Hz'.format(scanfreq))\n",
    "\n",
    "legend()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b436c0d",
   "metadata": {},
   "source": [
    "### Let's try filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b8785e",
   "metadata": {},
   "outputs": [],
   "source": [
    "anatype = 'TS, Az/El Corrected + Filtering'\n",
    "\n",
    "###### Pipeline:\n",
    "# 1. Identify scan types and numbers\n",
    "scantype_hk, azt, elt, scantype = identify_scans(thk, az, el, tt=tt-deltaT, doplot=False, thr_speedmin=0.1)\n",
    "nscans = np.max(np.abs(scantype))\n",
    "\n",
    "# 2. Offset removal scan by scan using median \n",
    "#    (here we just want to have all scans at the same level before decorrelating from azimuth)\n",
    "mytod = -tod.copy()\n",
    "p0, ff = ft.power_spectrum(tt, mytod, rebin=True)\n",
    "mytod = remove_offset_scan(mytod, scantype, method='median')\n",
    "p2, ff = ft.power_spectrum(tt, mytod, rebin=True)\n",
    "\n",
    "# 3. Remove azimuth and elevation correlation\n",
    "mytod = decorel_azel(mytod, azt, elt, scantype, doplot=False)\n",
    "p3, ff = ft.power_spectrum(tt, mytod, rebin=True)\n",
    "\n",
    "# 4. remove offsets again but this time with mode method as it appears to be less affected \n",
    "#    by the presence of the peaks (no underestimation of the offset resultingg is shadow around the peaks)\n",
    "mytod = remove_offset_scan(mytod, scantype, method='mode')\n",
    "p4, ff = ft.power_spectrum(tt, mytod, rebin=True)\n",
    "\n",
    "\n",
    "### Look at cleaned TOD\n",
    "figure()\n",
    "plot(tt[scantype>0], mytod[scantype>0], '.', label='Scan +')\n",
    "plot(tt[scantype<0], mytod[scantype<0], '.', label='Scan +')\n",
    "plot(tt[scantype==0], mytod[scantype==0], '.', label='Bad')\n",
    "xlim(0,1000)\n",
    "ylim(-30000, 30000)\n",
    "legend()\n",
    "title('TOD Before')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43366bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def fft_filter(signal_in, sampling, pars, filter_fct, divide=False):\n",
    "    freqs = np.fft.fftfreq(len(signal_in)) * sampling\n",
    "    myft = np.fft.fft(signal_in)\n",
    "    myfilter = filter_fct(freqs, pars)\n",
    "    if divide:\n",
    "        myft /= myfilter\n",
    "    else:\n",
    "        myft *= myfilter\n",
    "    signal_out = np.real(np.fft.ifft(myft))\n",
    "    return signal_out\n",
    "\n",
    "def brute_force_lopass(ff, flopass):\n",
    "    myfilter = np.ones(len(ff))\n",
    "    myfilter[np.abs(ff) > flopass] = 0\n",
    "    return myfilter\n",
    "\n",
    "def brute_force_bandpass(ff, fcuts):\n",
    "    myfilter = np.ones(len(ff))\n",
    "    myfilter[np.abs(ff) < fcuts[0]] = 0\n",
    "    myfilter[np.abs(ff) > fcuts[1]] = 0\n",
    "    return myfilter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d712c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Low-pass filter the data\n",
    "sampling = 1./np.median(tt[1:]-tt[:-1])    # Sampling frequency\n",
    "fmin = sampling/len(tod)\n",
    "print('fmin = {0:5.2g}'.format(fmin))\n",
    "fcut = 6e-1 # Hz\n",
    "\n",
    "mytod_brute_LP = fft_filter(mytod, sampling, fcut, brute_force_lopass)\n",
    "p5_brute_LP, ff = ft.power_spectrum(tt, mytod_brute_LP, rebin=True)\n",
    "\n",
    "mytod_butter_LP = ft.butter_bandpass_filter(mytod, sampling/len(tod)/2, fcut, sampling, order=2)\n",
    "p5_butter_LP, ff = ft.power_spectrum(tt, mytod_butter_LP, rebin=True)\n",
    "\n",
    "fcuts = [1e-4, fcut]\n",
    "mytod_brute_BP = fft_filter(mytod, sampling, fcuts, brute_force_bandpass)\n",
    "p5_brute_BP, ff = ft.power_spectrum(tt, mytod_brute_BP, rebin=True)\n",
    "\n",
    "\n",
    "figure()\n",
    "plot(ff, pth, label='Theory')\n",
    "#plot(ff, p0, label='Raw')\n",
    "plot(ff, p2, label='After P2 (median scan)')\n",
    "plot(ff, p3, label='After P3 (Az/El Corr)')\n",
    "#plot(ff, p4, label='After P4 (Mode Scan)')\n",
    "plot(ff, p5_brute_LP, label='After P5 (Brute Force Lo-Pass)')\n",
    "plot(ff, p5_butter_LP, label='After P5 (Butterworth Lo-Pass)')\n",
    "plot(ff, p5_brute_BP, label='After P5 (Brute Force Band-Pass)')\n",
    "xscale('log')\n",
    "yscale('log')\n",
    "xlabel('Frequency [Hz]')\n",
    "ylabel('PSD')\n",
    "legend()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b02f73ad",
   "metadata": {},
   "source": [
    "### Let's remark that the azel correlation is very efficient in removing the scan-synchronous peak."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292e6103",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Then make the maps\n",
    "mapsb_brute_LP, mapcount = healpix_map(azt[scantype != 0], elt[scantype != 0], mytod_brute_LP[scantype != 0], nside=nside)\n",
    "mapsb_butter_LP, mapcount = healpix_map(azt[scantype != 0], elt[scantype != 0], mytod_butter_LP[scantype != 0], nside=nside)\n",
    "mapsb_brute_BP, mapcount = healpix_map(azt[scantype != 0], elt[scantype != 0], mytod_brute_BP[scantype != 0], nside=nside)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b9f42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display Results\n",
    "\n",
    "nlo = 3\n",
    "nhi = 3\n",
    "\n",
    "# nlo = 0.5\n",
    "# nhi = 100\n",
    "\n",
    "display_one(mapsb, anatype='TS, Az/El Corrected', sub=(2,3,1), nlo=nlo, nhi=nhi)\n",
    "display_one(mapsb_brute_LP, anatype='Brute LP', sub=(2,3,2), nlo=nlo, nhi=nhi)\n",
    "display_one(mapsb_butter_LP, anatype='Butter LP', sub=(2,3,3), nlo=nlo, nhi=nhi)\n",
    "display_one(mapsb_brute_BP, anatype='Brute BP', sub=(2,3,5), nlo=nlo, nhi=nhi)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e6cb96",
   "metadata": {},
   "source": [
    "We see that the gain is not huge. This is due to various effects:\n",
    "- the presence of the bright peaks. There are ways too overcome this, such as masking the regggions where the signal is strong in the TOD, then repacing them by some constrained noise realization, applying the filtering and putting the signal back. This is usually not too efficient unfortunately.\n",
    "- The stripes we would like to remove are actually medium-frequency (shorter than a scan but much longer that the HF cutoff we apply) so they are not well filtered by our method... Tiis is where redundancy becomes important. With CMB data, we will have much more crossings with various angles, a much lower signal to noise ratio (therefore no strong peak effect) so it will be much easier to filter. However,  one important thing about filter ing is that you always remove some of the signal with filtering. This has to be accounted for at Cl level by measuring the transfer function of the TOD pipeline and correcting the measured Cl accordingly.\n",
    "\n",
    "Let's also remark that as anticipated, Band-Pass alters the signal significantly because it has a low-frequency component...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a7e3e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
