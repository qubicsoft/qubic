{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b3550ef",
   "metadata": {},
   "source": [
    "# Tutorial for Component Map-Making (Written by Mathias Regnier)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dcbab0b",
   "metadata": {},
   "source": [
    "## Frequency point of view"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71effbdc",
   "metadata": {},
   "source": [
    "In this notebook, we will try to introduce some aspects of component map-making. In general, CMB experiments solve their inverse problems to reconstruct N frequency maps, then apply a component separation method to produce a final cosmological analysis. Here we will join the map-making and component separation steps.\n",
    "\n",
    "Our data can be described by : \n",
    "\n",
    "$$\\vec{d} = H \\cdot \\vec{s} + \\vec{n}$$\n",
    "\n",
    "where $H$ is the pointing matrix, $\\vec{s}$ is the input sky and $\\vec{n}$ a noise vector. The pointing matrix caracterising the full instrument and contains all the specificities. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98ebdcb8",
   "metadata": {},
   "source": [
    "## Component point of view"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d230e814",
   "metadata": {},
   "source": [
    "Now, we would like to think not about frequency maps, but component maps directly. A sky with mixed components can be written by :\n",
    "\n",
    "$$\\vec{s} = A \\cdot \\vec{c}$$\n",
    "\n",
    "where A is the mixing matrix and $\\vec{c}$ is the components. By replacing this equation in the first one, we have :\n",
    "\n",
    "$$\\vec{d} = H \\cdot A \\cdot \\vec{c} + \\vec{n}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a080e4c7",
   "metadata": {},
   "source": [
    "## QUBIC Operator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f838f29",
   "metadata": {},
   "source": [
    "The QUBIC operator was build to simulate the way that the instrument is taking data. You can see the code in the QUBIC soft in the `acquisiton.py` at the line 341. By doing that, you can write :\n",
    "\n",
    "$$\\vec{d} = H^{Q} (\\vec{x})$$\n",
    "\n",
    "where $\\vec{d}$ is a TOD, $H^{Q}$ is the QUBIC operator and $\\vec{x}$ a map in pixel space with shape (Npix, 3). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "743c0f86",
   "metadata": {},
   "source": [
    "##Â Python code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4404b15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import qubic\n",
    "import sys\n",
    "sys.path.append('/Users/mregnier/Desktop/PhD Regnier/mypackages')\n",
    "import Acquisition as acq\n",
    "import component_model as c\n",
    "import numpy as np\n",
    "from importlib import reload\n",
    "from pyoperators import *\n",
    "import matplotlib.pyplot as plt\n",
    "reload(acq)\n",
    "\n",
    "def get_dictionary(nsub, nside, pointing, band):\n",
    "    dictfilename = 'dicts/pipeline_demo.dict'\n",
    "    \n",
    "    # Read dictionary chosen\n",
    "    d = qubic.qubicdict.qubicDict()\n",
    "    d.read_from_file(dictfilename)\n",
    "    d['nf_recon'] = nsub\n",
    "    d['nf_sub'] = nsub\n",
    "    d['nside'] = nside\n",
    "    d['RA_center'] = 0\n",
    "    d['DEC_center'] = -57\n",
    "    center = qubic.equ2gal(d['RA_center'], d['DEC_center'])\n",
    "    d['effective_duration'] = 3\n",
    "    d['npointings'] = pointing\n",
    "    d['filter_nu'] = int(band*1e9)\n",
    "    d['photon_noise'] = False\n",
    "    d['config'] = 'FI'\n",
    "    d['MultiBand'] = True\n",
    "    \n",
    "    return d\n",
    "\n",
    "Nsub=2\n",
    "nside = 256\n",
    "pointing = 999\n",
    "\n",
    "d150 = get_dictionary(Nsub, nside, pointing, 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c11486",
   "metadata": {},
   "outputs": [],
   "source": [
    "comp = [c.CMB(), c.Dust(nu0=353, temp=20)]\n",
    "\n",
    "instance = acq.QubicIntegratedComponentsMapMaking(d150, Nsub=Nsub, comp=comp)\n",
    "H = instance.get_operator(np.array([1.54]), convolution=False, )\n",
    "print('*********************************************')\n",
    "print(f'\\nShapein = {H.shapein}, Shapeout = {H.shapeout}\\n')\n",
    "print('*********************************************')\n",
    "H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3dd4c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "components = instance.get_PySM_maps({'cmb':42, 'dust':'d0'}, r=0.01)\n",
    "\n",
    "d = H(components)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9eccadf",
   "metadata": {},
   "source": [
    "You should see that this H operator is taking as input maps with shape (Ncomp, Npix, 3) with Ncomp your number of components and Npix the number of pixels of your map. The output is your TOD with shape (Ndets*Nsamples). Now the model is defined based on component maps instead of frequency maps. \n",
    "\n",
    "If you look inside the operator, you should see few lines with `DenseOperator`. This line define the mixing matrix  which tells you how your components are mixing at a given frequency. Those numbers are calculating thanks to FG-Buster (PUT LINK) packages which provides foreground models.\n",
    "\n",
    "In the first lines, you should see a line with `DiagonalOperator` with numbers close to 1, those are the gain detector which are set to be very close to 1 at the beginning. During the convergence that we will see later, we will fit those numbers to marginalized over foregrounds and gain detectors.\n",
    "\n",
    "$$H(\\vec{s}) \\longrightarrow H(\\vec{c}, \\vec{\\beta}, \\vec{g})$$\n",
    "\n",
    "As expressed above, the new QUBIC operator is not longer depending of frequency maps but it depends on the components, the spectral indices and the detectors gain which will be a variable to marginalized over them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd431ceb",
   "metadata": {},
   "source": [
    "## Alternate PCG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cef74c3",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "For using this method, we used `PyOperators` written by Pierre Chanial (PUT LINK). In this package is define an iterative algorithm called Preconditionning Conjugate Gradient (PCG) which solved linear equation $A x = b$ iteratively. \n",
    "\n",
    "+ Choose an initial guess $x_0$\n",
    "+ Compute first residuals $r_0 = b - A x_0$\n",
    "+ Compute the first direction $d_0 = M^{-1} r_0$\n",
    "+ For each k-th step :\n",
    "    + Compute step size $\\alpha_i = \\frac{r_i^T M^{-1} r_i}{d_i^T A d_i}$\n",
    "    + Compute new maps $x_{i+1} = x_i + \\alpha_i d_i$\n",
    "    + Compute new residuals $r_{i+1} = r_i - \\alpha_i A d_i$\n",
    "    + Compute the next direction $d_{i+1} = M^{-1} r_{i+1}$\n",
    "    \n",
    "That algorithm is working by minimizing the residuals. For each iterations, it will propose a new solution and compute from that the direction in parameter space where the residuals are smaller than the previous step.\n",
    "\n",
    "If we go back to our problem, the main equation to solve is $A x = b$ where $x$ is the components. By defining $A = H^T \\cdot N^{-1} \\cdot H$ and $b = H^T \\cdot N^{-1} \\cdot \\vec{d}$, we can solve the inverse problem.\n",
    "\n",
    "The PCG is considering constant $H$ (so constant $A$ and $b$) during the convergence so we need to make an alternate PCG by apply the previous algorithm on few steps (no less than 10 due to the convergence step size) and update regularly the spectral indices and gain detectors. \n",
    "\n",
    "Our fitting scheme becomes :\n",
    "\n",
    "+ Define initial guess $\\vec{c}_0$, $\\vec{\\beta}_0$ and $\\vec{g}_0$\n",
    "\n",
    "+ for each k-th step :\n",
    "    + Define operator $H(\\vec{c}_k, \\vec{\\beta}_k, \\vec{g}_k)$\n",
    "    + Compute $A$ and $b$ term\n",
    "    + Let PCG converge by applying previous algorithm\n",
    "    + Fit gain detectors $\\vec{g}_{k+1}$\n",
    "    + Fit spectral indices $\\vec{\\beta}_{k+1}$\n",
    "    \n",
    "    + $\\vec{c}_{k} \\rightarrow \\vec{c}_{k+1}$\n",
    "    + $\\vec{g}_{k} \\rightarrow \\vec{g}_{k+1}$\n",
    "    + $\\vec{\\beta}_{k} \\rightarrow \\vec{\\beta}_{k+1}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9311ee5c",
   "metadata": {},
   "source": [
    "## How to fit our parameters ?\n",
    "\n",
    "### Gain detectors \n",
    "\n",
    "$$\\vec{d} = \\vec{g} \\cdot \\vec{d}_{\\text{intercalibrated}}$$\n",
    "\n",
    "\n",
    "\n",
    "$$\\chi^2 = (\\vec{d} - \\vec{d}_{intercalibrated})^T \\cdot (\\vec{d} - \\vec{d}_{intercalibrated})$$\n",
    "$$\\chi^2 = (\\vec{d} - g * H * c )^T \\cdot (\\vec{d} - g * H * c )$$\n",
    "$$\\chi^2 = \\vec{d}^T \\vec{d} - g^T H^T c^T \\vec{d} - \\vec{d} g H c + g^T H^T c^T c H g$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a2e27b5",
   "metadata": {},
   "source": [
    "We are looking for a solution which minimize the $\\chi^2$ on the gain, so we pose $\\frac{\\partial \\chi^2}{\\partial g^T} = 0$, so :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4adeab0",
   "metadata": {},
   "source": [
    "$$0 = - H^T c^T \\vec{d} + H^T c^T c H g$$\n",
    "$$H^T c^T \\vec{d} = H^T c^T c H g$$\n",
    "$$ g = \\frac{\\vec{d}}{H c}$$\n",
    "\n",
    "The gain of the detector can be find by compute the ratio between the observation data and the simulated data assuming $g_i = 1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ccf042",
   "metadata": {},
   "outputs": [],
   "source": [
    "def give_me_intercal(D, d):\n",
    "    return 1/np.sum(D[:]**2, axis=1) * np.sum(D[:] * d[:], axis=1)\n",
    "\n",
    "R = ReshapeOperator((992,999), 991008)\n",
    "\n",
    "g = np.random.randn(992) * 0.5 + 1\n",
    "\n",
    "G = DiagonalOperator(g, broadcast='rightward', shapein=R.shapein)\n",
    "\n",
    "Hp = G * R.T * H\n",
    "\n",
    "dp = Hp(components)\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.plot(R.T(d)[0])\n",
    "plt.plot(dp[0], alpha=0.4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2797c961",
   "metadata": {},
   "outputs": [],
   "source": [
    "grecon = give_me_intercal(R.T(d), dp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "964b452b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.scatter(g, grecon, s=5)\n",
    "plt.plot([0, 2], [0, 2], '--k')\n",
    "plt.xlabel(r'g', fontsize=12)\n",
    "plt.ylabel(r'$g_{recon}$', fontsize=12)\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.hist(g-grecon)\n",
    "\n",
    "plt.subplot(2, 2, (3, 4))\n",
    "plt.scatter(np.arange(0, 992, 1), g, color='blue', label='g', s=20)\n",
    "plt.scatter(np.arange(0, 992, 1), grecon, marker='x', color='red', s=10, label=r'$g_{recon}$')\n",
    "plt.xlabel(r'# of detector', fontsize=12)\n",
    "plt.ylabel(r'gain', fontsize=12)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "629e128a",
   "metadata": {},
   "source": [
    "### Spectral indices\n",
    "\n",
    "The more important fit we want to perform is the fit of the spectral indices which describe how the components evolving with respect to the frequency. New, the QUBIC operator is depending of those parameters. In other words, we have a way to simulate data parametrized by spectral indices, and on the other side we have data to compare with. We can apply a $\\chi^2$ minimizatioon like :\n",
    "\n",
    "$$\\chi^2 = (\\vec{d} - H(\\beta) \\cdot \\vec{c}_i)^T \\cdot (\\vec{d} - H(\\beta) \\cdot \\vec{c}_i)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe4e0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def myChi2(x):\n",
    "\n",
    "    H_i = instance.update_A(H, x)\n",
    "\n",
    "    fakedata = H_i(components)\n",
    "            \n",
    "    return np.sum((fakedata/fakedata.max() - d/d.max())**2)\n",
    "\n",
    "\n",
    "allbeta = np.linspace(1.5, 1.6, 100)\n",
    "allchi2 = np.zeros(allbeta.shape[0])\n",
    "for ii, i in enumerate(allbeta):\n",
    "    allchi2[ii] = myChi2(np.array([i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3cc7890",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(allbeta, allchi2)\n",
    "plt.axvline(allbeta[np.where(allchi2 == allchi2.min())[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb107073",
   "metadata": {},
   "outputs": [],
   "source": [
    "prob = np.exp(-allchi2)/allchi2\n",
    "plt.plot(allbeta, prob/prob.max())\n",
    "plt.xlim(1.5, 1.6)\n",
    "plt.xlabel(r'$\\beta$', fontsize=14)\n",
    "plt.ylabel(r'$P(\\beta)$', fontsize=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63707846",
   "metadata": {},
   "outputs": [],
   "source": [
    "allchi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f63d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "\n",
    "minimize(myChi2, x0=np.ones(1), method='L-BFGS-B', tol=1e-10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01f14b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pysm3\n",
    "import healpy as hp\n",
    "\n",
    "sky = pysm3.Sky(nside=256, preset_strings=['d1'])\n",
    "beta = np.array(sky.components[0].mbb_index)\n",
    "\n",
    "hp.mollview(beta, cmap='jet', min=1.4, max=1.65, title=f'Spectral Index - {beta.shape[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d88d5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46077f6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df94057",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67f4526",
   "metadata": {},
   "outputs": [],
   "source": [
    "hp.mollview(components[0, :, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70de218b",
   "metadata": {},
   "source": [
    "# Let's see what kind of results we have "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f124581d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import healpy as hp\n",
    "import os.path as op\n",
    "alm = hp.sphtfunc.map2alm(components[0].T, lmax=2*256)\n",
    "cl = hp.sphtfunc.alm2cl(alm)[:, 40:2*256]\n",
    "ell = np.arange(40, 2*256, 1)\n",
    "ell_true = np.arange(2, 4000, 1)\n",
    "\n",
    "def cl2dl(ell, cl):\n",
    "\n",
    "    dl=np.zeros(ell.shape[0])\n",
    "    for i in range(ell.shape[0]):\n",
    "        dl[i]=(ell[i]*(ell[i]+1)*cl[i])/(2*np.pi)\n",
    "    return dl\n",
    "\n",
    "CMB_CL_FILE = op.join('Cls_Planck2018_%s.fits')\n",
    "\n",
    "def _get_Cl_cmb(Alens, r):\n",
    "    power_spectrum = hp.read_cl(CMB_CL_FILE%'lensed_scalar')[:,:4000]\n",
    "    if Alens != 1.:\n",
    "        power_spectrum[2] *= Alens\n",
    "    if r:\n",
    "        power_spectrum += r * hp.read_cl(CMB_CL_FILE%'unlensed_scalar_and_tensor_r1')[:,:4000]\n",
    "    return power_spectrum\n",
    "\n",
    "dl = cl2dl(ell, cl[2])\n",
    "cl_true = _get_Cl_cmb(Alens=1, r=0.01)[2, :]\n",
    "dl_true = cl2dl(ell_true, cl_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a088a4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(ell, dl)\n",
    "plt.plot(ell_true, dl_true)\n",
    "plt.yscale('log')\n",
    "plt.ylim(1e-4, 1e-1)\n",
    "plt.xlim(30, 550)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4628f0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "class Spectra:\n",
    "    \n",
    "    def __init__(self, lmin, lmax, dl, r=0, Alens=1, icl=2, CMB_CL_FILE=None):\n",
    "        self.lmin = lmin\n",
    "        self.lmax = lmax\n",
    "        self.icl = icl\n",
    "        self.r = r\n",
    "        self.dl = dl\n",
    "        self.CMB_CL_FILE = CMB_CL_FILE\n",
    "        self.Alens = Alens\n",
    "        self.ell_theo = np.arange(2, self.lmax, 1)\n",
    "        self.cl_theo = self._get_Cl_cmb(r=r)[self.icl]\n",
    "        self.dl_theo = self._cl2dl(self.ell_theo, self.cl_theo)\n",
    "        self.ell_obs = np.arange(lmin, lmax, dl)\n",
    "        \n",
    "        \n",
    "    def _get_Cl_cmb(self, r):\n",
    "        power_spectrum = hp.read_cl(self.CMB_CL_FILE%'lensed_scalar')[:, :self.lmax]\n",
    "        if self.Alens != 1.:\n",
    "            power_spectrum[2] *= self.Alens\n",
    "        if r:\n",
    "            power_spectrum += r * hp.read_cl(self.CMB_CL_FILE%'unlensed_scalar_and_tensor_r1')[:, :self.lmax]\n",
    "        return power_spectrum\n",
    "    \n",
    "    def _cl2dl(self, ell, cl):\n",
    "        dl=np.zeros(ell.shape[0])\n",
    "        for i in range(ell.shape[0]):\n",
    "            dl[i]=(ell[i]*(ell[i]+1)*cl[i])/(2*np.pi)\n",
    "        return dl\n",
    "    \n",
    "    def binning(self, cl):\n",
    "        \n",
    "        nbins = len(self.ell_obs)\n",
    "        cl_binned = np.zeros(nbins)\n",
    "        for i in range(nbins):\n",
    "            cl_binned[i] = np.mean(cl[self.ell_obs[i]-int(self.dl/2) : self.ell_obs[i]+int(self.dl/2)])\n",
    "        return cl_binned\n",
    "    \n",
    "    def get_observed_spectra(self, s):\n",
    "        \n",
    "        alm = hp.sphtfunc.map2alm(s, lmax=self.lmax)\n",
    "        cl = hp.sphtfunc.alm2cl(alm)[self.icl, :]\n",
    "\n",
    "        #cl_binned = self.binning(cl)\n",
    "        #print(cl_binned)\n",
    "        dl_binned = self._cl2dl(self.ell_theo, cl)\n",
    "        \n",
    "        #print(dl_binned)\n",
    "        return dl_binned\n",
    "    \n",
    "    def chi2(self, r, dobs):\n",
    "        #print(r)\n",
    "        cl = self._get_Cl_cmb(r)[self.icl]\n",
    "        d = self._cl2dl(self.ell_theo, cl)#[np.array(self.ell_obs, dtype=int)]\n",
    "        #d = self._cl2dl(self.ell_theo, self.cl_theo)[np.array(self.ell_obs, dtype=int)]\n",
    "        #print(d)\n",
    "        #print(dobs)\n",
    "        return np.sum((d - dobs)**2)\n",
    "        \n",
    "    def give_rbias(self, cl_obs):\n",
    "        \n",
    "        cl_theo_binned = self.dl_theo.copy()#[np.array(self.ell_obs, dtype=int)]\n",
    "        s = minimize(self.chi2, x0=np.ones(1), args=(cl_obs), method='TNC', tol=1e-10, bounds=[(0, 1)])\n",
    "        return s.x[0] - self.r\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ee7ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = Spectra(40, 2*256, 35, r=0.01, Alens=1, icl=2)\n",
    "s.give_rbias(s.get_observed_spectra(components[0].T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84837a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(s.ell_theo, s.dl_theo)\n",
    "plt.plot(s.ell_theo, s.get_observed_spectra(components[0].T), '-k')\n",
    "plt.yscale('log')\n",
    "plt.xlim(20, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c1d467",
   "metadata": {},
   "outputs": [],
   "source": [
    "s.get_observed_spectra(components[0].T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f91a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import cm\n",
    "from matplotlib.colors import ListedColormap, LinearSegmentedColormap\n",
    "\n",
    "center = qubic.equ2gal(100, -157)\n",
    "N = 500\n",
    "vals = np.ones((N, 4))\n",
    "vals[:, 0] = np.linspace(90/256, 1, N)*0\n",
    "vals[:, 1] = np.linspace(39/256, 1, N)\n",
    "vals[:, 2] = np.linspace(41/256, 1, N)*0\n",
    "newcmp = ListedColormap(vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ac23c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 6))\n",
    "\n",
    "hp.gnomview(components[1, :, 0], cmap=None, min=0, max=50000, rot=center, reso=15, sub=(2, 2, 1), cbar=False, title='',\n",
    "           notext=True)\n",
    "hp.gnomview(components[1, :, 0], cmap=None, min=0, max=50000, rot=center, reso=15, sub=(2, 2, 2), cbar=False, title='',\n",
    "           notext=True)\n",
    "hp.gnomview(components[1, :, 0], cmap=None, min=0, max=50000, rot=center, reso=15, sub=(2, 2, 3), cbar=False, title='',\n",
    "           notext=True)\n",
    "hp.gnomview(components[1, :, 0], cmap=None, min=0, max=50000, rot=center, reso=15, sub=(2, 2, 4), cbar=False, title='',\n",
    "           notext=True)\n",
    "\n",
    "all_comp = [r'$CMB$', r'$A_d$']\n",
    "all_pol = [r'$I$', r'$Q$', r'$U$']\n",
    "\n",
    "for i in range(len(all_comp)):\n",
    "    plt.annotate(all_comp[i], xy=(0, 0), xytext=(1/len(all_comp) - 0.06, 1/(i+1) - 0.06), \n",
    "                 xycoords='figure fraction', fontsize=12, ha=\"center\", va=\"center\")\n",
    "\n",
    "    plt.annotate(all_pol[2], xy=(0, 0), xytext=(0.06, 1/(i+1) - 0.06), \n",
    "                xycoords='figure fraction', fontsize=12, ha=\"center\", va=\"center\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8600d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cl(m):\n",
    "    alm = hp.sphtfunc.map2alm(m, lmax=2*256)\n",
    "    cl = hp.sphtfunc.alm2cl(alm)[2]\n",
    "    return cl\n",
    "import pickle\n",
    "\n",
    "pkl_file = open('test_cl.pkl', 'rb')\n",
    "dataset = pickle.load(pkl_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55acbbb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(dataset['ell'], dataset['cl'][0])\n",
    "plt.plot(s.ell_theo, s.dl_theo)\n",
    "plt.yscale('log')\n",
    "plt.ylim(5e-6, 2e1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ae5d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cl = get_cl(np.random.randn(components[0].T.shape[0], components[0].T.shape[1])*1.1)\n",
    "dl = s._cl2dl(np.arange(0, 2*256, 1), cl)\n",
    "print(dataset['cl'].shape)\n",
    "print(dl.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f2afe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(dataset['ell'], dataset['cl'][0])\n",
    "plt.plot(np.arange(0, 2*256, 1)[12:], dl[12:])\n",
    "plt.plot(np.arange(0, 2*256, 1)[12:], dl[12:]-dataset['cl'][0])\n",
    "plt.plot(s.ell_theo, s.dl_theo)\n",
    "#plt.yscale('log')\n",
    "plt.ylim(-0.1, 0.3)#5e-6, 2e1)\n",
    "plt.xlim(0, 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b59bff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.randn(components[0].T.shape[0], components[0].T.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2344856",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,Rmd"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
